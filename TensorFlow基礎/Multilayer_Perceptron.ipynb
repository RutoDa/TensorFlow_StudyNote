{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "542412bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4a29b5",
   "metadata": {},
   "source": [
    "* 學習於[https://tf.wiki/zh_hans/basic/models.html](https://tf.wiki/zh_hans/basic/models.html)\n",
    "## Multilayer Perceptron(MLP)\n",
    "* 又可稱多層全連接神經網路\n",
    "* 步驟\n",
    "    1. 使用 **tf.keras.dataset** 獲得dataset並預處理\n",
    "    2. 使用 **tf.keras.Model** 和 **tf.keras,layers** 建構模型\n",
    "    3. 使用 **tf.keras.losses** 計算loss function\n",
    "    4. 使用 **tf.keras.optimizer** 優化模型\n",
    "    5. 使用 **tf.keras.metrics** 計算評估指標"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1564e625",
   "metadata": {},
   "source": [
    "### dataset與pre-process\n",
    "* 做一個簡單的 MNISTLoader class 來讀取 MNIST dataset\n",
    "<img src=\"https://tf.wiki/_images/mnist_0-9.png\">\n",
    "* 分別載入60000和10000張大小為28x28的手寫數字圖片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d70406",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTLoader():\n",
    "    def __init__(self):\n",
    "        mnist = tf.keras.datasets.mnist\n",
    "        (self.train_data, self.train_label), (self.test_data, self.test_label) = mnist.load_data()\n",
    "        # train_data.shape = (60000, 28, 28): 60000個28x28的input\n",
    "        # 將像素都坐正規化，並且增加一個維度存放channel數量(1,因為為灰階)\n",
    "        # 用astype()轉型\n",
    "        self.train_data = np.expand_dims(self.train_data.astype(np.float32)/255.0, axis=-1) #[60000,28,28,1]\n",
    "        self.test_data = np.expand_dims(self.test_data.astype(np.float32)/255.0, axis=-1) #[10000,28,28,1]\n",
    "        self.train_label = self.train_label.astype(np.int32) #[60000]\n",
    "        self.test_label = self.test_label.astype(np.int32) #[10000]\n",
    "        self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]\n",
    "        \n",
    "    def get_batch(self, batch_size):\n",
    "        # 從資料集中隨機存取batch_size個元素return\n",
    "        # index為存放的要挑選的index(一維陣列)\n",
    "        index = np.random.randint(0, self.num_train_data, batch_size)\n",
    "        return self.train_data[index, :], self.train_label[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e22f37e",
   "metadata": {},
   "source": [
    "### 模型構建\n",
    "* 使用 **tf.keras.Model** 和 **tf.keras.layers**\n",
    "* 該model輸入為一個向量(拉直的1x784)手寫數字圖片\n",
    "* 輸出10維的向量，分別代表0到9的機率\n",
    "\n",
    "#### Softmax\n",
    "* 我們希望輸出為每個 output label 的機率 => 一個10維離散機率\n",
    "    * 該向量中的每個元素均在 **[0,1]** 之間\n",
    "    * 該向量的所有元素之和為 **1**\n",
    "    <img src=\"img/softmax.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6b5951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Flatten層將除了第一維(batch_size)以外的維度攤平\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(units=100, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=10)\n",
    "    \n",
    "    def call(self, inputs):      # [batch_size, 28, 28, 1]\n",
    "        x = self.flatten(inputs) # [batch_size, 784]\n",
    "        x = self.dense1(x)       # [batch_size, 100]\n",
    "        x = self.dense2(x)       # [batch_size, 8]\n",
    "        output = tf.nn.softmax(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7388fa19",
   "metadata": {},
   "source": [
    "<img src=\"https://tf.wiki/_images/mlp.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd14b57",
   "metadata": {},
   "source": [
    "### 模型的訓練 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc1ec922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義一些模型的 hyper paremeter\n",
    "num_epochs = 5\n",
    "batch_size = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5785ac",
   "metadata": {},
   "source": [
    "### 優化器選擇\n",
    "參考[網站](https://medium.com/雞雞與兔兔的工程世界/機器學習ml-note-sgd-momentum-adagrad-adam-optimizer-f20568c968db)\n",
    "* SGD-準確率梯度下降法 (stochastic gradient decent)\n",
    "    * <img src=\"https://miro.medium.com/v2/resize:fit:1100/format:webp/1*C8PAvTAXukHZ2mZPItwIrg.png\">\n",
    "* Momentum\n",
    "    * 此優化器為模擬物理動量的概念，在同方向的維度上學習速度會變快，方向改變的時候學習速度會變慢\n",
    "    * <img src=\"https://miro.medium.com/v2/resize:fit:1100/format:webp/1*tbRXwsHwo9WPx5xTcZDX_A.png\">\n",
    "    * **Vt** 可以想像成 **方向速度**，會與上一次的更新有關，如果上一次的梯度與這次同方向的話，|Vt|(速度)會越來越大(表示梯度增強)，w參數的更新梯度便會越來越快\n",
    "    * **$\\beta$** 可以想像為空氣阻力或是地面摩擦力，通常設為0.9\n",
    "* AdaGrad(Adaptive)\n",
    "    * learning rate η 對優化器非常重要，太小會花費太多時間學習，太大可能會overfitting，無法正確學習\n",
    "    * AdaGrad會依照梯度去調整 η\n",
    "    * <img src=\"https://miro.medium.com/v2/resize:fit:1100/format:webp/1*203QdRb0FaCFNfIZayfUsw.png\">\n",
    "        * 其中 η 乘上 1/√(n+ϵ) 再做參數更新\n",
    "        * n為前面所有梯度值得平方和\n",
    "        * ϵ 為平滑值，加上 ϵ 的原因是為了不讓分母為0，ϵ 一般值為1e-8\n",
    "    * 特性\n",
    "        1. 前期梯度較小的時候，n較小，能夠放大學習率\n",
    "        2. 後期梯度較大的時候，n較大，能夠約束學習率\n",
    "* Adam\n",
    "    * Momentum 跟 AdaGrad這二種Optimizer做結合，為目前較常使用的Optimizer\n",
    "    * <img src=\"https://miro.medium.com/v2/resize:fit:1100/format:webp/1*HIrsnzAhkYsm1wCI6gUaug.png\">\n",
    "        * 像Momentum一樣保持了過去梯度的指數衰減平均值，像AdaGrad一樣存了過去梯度的平方衰減平均值\n",
    "    * <img src=\"https://miro.medium.com/v2/resize:fit:1100/format:webp/1*4b7GUhHlzoqum1U4PCTFWw.png\">\n",
    "        * 對mt跟vt做偏離校正\n",
    "    * <img src=\"https://miro.medium.com/v2/resize:fit:1100/format:webp/1*uhyuvY_h-NFYU_hmKwfaFQ.png\">\n",
    "        * Adam 保留了 Momentum 對過去梯度的方向做梯度速度調整與AdaGrad對過去梯度的平方值做learning rate的調整，再加上Adam有做參數的”偏離校正”，使得每一次的學習率都會有個確定的範圍，會讓參數的更新較為平穩 \n",
    "        \n",
    "### 總整理[參考網站](https://medium.com/雞雞與兔兔的工程世界/機器學習ml-note-sgd-momentum-adagrad-adam-optimizer-f20568c968db)\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/format:webp/1*U0IT4yJReyPibVI43j38cQ.png\">\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1240/1*SjtKOauOXFVjWRR7iCtHiA.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aac2280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 15:21:29.498420: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-26 15:21:29.498783: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = MLP()\n",
    "data_loader = MNISTLoader()\n",
    "# 選擇Adam作為優化器\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c7b10c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0: loss 2.3370795249938965\n",
      "batch 1: loss 2.287160873413086\n",
      "batch 2: loss 2.181264638900757\n",
      "batch 3: loss 2.0944173336029053\n",
      "batch 4: loss 1.989709734916687\n",
      "batch 5: loss 1.9161925315856934\n",
      "batch 6: loss 1.966715931892395\n",
      "batch 7: loss 1.8699395656585693\n",
      "batch 8: loss 1.7662453651428223\n",
      "batch 9: loss 1.6430126428604126\n",
      "batch 10: loss 1.5790722370147705\n",
      "batch 11: loss 1.697829246520996\n",
      "batch 12: loss 1.4866368770599365\n",
      "batch 13: loss 1.37369966506958\n",
      "batch 14: loss 1.3470656871795654\n",
      "batch 15: loss 1.2022373676300049\n",
      "batch 16: loss 1.3854176998138428\n",
      "batch 17: loss 1.2590304613113403\n",
      "batch 18: loss 1.443745493888855\n",
      "batch 19: loss 1.2901467084884644\n",
      "batch 20: loss 1.1727484464645386\n",
      "batch 21: loss 1.3447316884994507\n",
      "batch 22: loss 1.1882752180099487\n",
      "batch 23: loss 1.1394003629684448\n",
      "batch 24: loss 0.9043923020362854\n",
      "batch 25: loss 1.1118465662002563\n",
      "batch 26: loss 1.2136934995651245\n",
      "batch 27: loss 0.8705396056175232\n",
      "batch 28: loss 0.8899882435798645\n",
      "batch 29: loss 0.9700764417648315\n",
      "batch 30: loss 0.9089387059211731\n",
      "batch 31: loss 0.8785144090652466\n",
      "batch 32: loss 0.6651231050491333\n",
      "batch 33: loss 0.7760065197944641\n",
      "batch 34: loss 0.7077664732933044\n",
      "batch 35: loss 0.7702298760414124\n",
      "batch 36: loss 0.8863778710365295\n",
      "batch 37: loss 0.6860998272895813\n",
      "batch 38: loss 0.7415730357170105\n",
      "batch 39: loss 0.715804398059845\n",
      "batch 40: loss 0.5443186163902283\n",
      "batch 41: loss 0.6156588792800903\n",
      "batch 42: loss 0.6635907888412476\n",
      "batch 43: loss 0.7244158983230591\n",
      "batch 44: loss 0.6575396656990051\n",
      "batch 45: loss 0.6684696674346924\n",
      "batch 46: loss 0.7508015036582947\n",
      "batch 47: loss 0.6450168490409851\n",
      "batch 48: loss 0.6975092887878418\n",
      "batch 49: loss 0.8043010234832764\n",
      "batch 50: loss 0.5270041823387146\n",
      "batch 51: loss 0.5569922924041748\n",
      "batch 52: loss 0.5196078419685364\n",
      "batch 53: loss 0.49956774711608887\n",
      "batch 54: loss 0.6023998260498047\n",
      "batch 55: loss 0.3721936345100403\n",
      "batch 56: loss 0.5185711979866028\n",
      "batch 57: loss 0.4413611888885498\n",
      "batch 58: loss 0.48435622453689575\n",
      "batch 59: loss 0.5833806395530701\n",
      "batch 60: loss 0.5269960761070251\n",
      "batch 61: loss 0.5191661715507507\n",
      "batch 62: loss 0.7466082572937012\n",
      "batch 63: loss 0.724983274936676\n",
      "batch 64: loss 0.49563729763031006\n",
      "batch 65: loss 0.6587730050086975\n",
      "batch 66: loss 0.5347298979759216\n",
      "batch 67: loss 0.4207788109779358\n",
      "batch 68: loss 0.33840620517730713\n",
      "batch 69: loss 0.6744704842567444\n",
      "batch 70: loss 0.5287980437278748\n",
      "batch 71: loss 0.5353747606277466\n",
      "batch 72: loss 0.40020552277565\n",
      "batch 73: loss 0.47804173827171326\n",
      "batch 74: loss 0.31762105226516724\n",
      "batch 75: loss 0.5254190564155579\n",
      "batch 76: loss 0.49125152826309204\n",
      "batch 77: loss 0.3774482011795044\n",
      "batch 78: loss 0.4981549084186554\n",
      "batch 79: loss 0.355711430311203\n",
      "batch 80: loss 0.5649002194404602\n",
      "batch 81: loss 0.5490723848342896\n",
      "batch 82: loss 0.4864611327648163\n",
      "batch 83: loss 0.4887455999851227\n",
      "batch 84: loss 0.4785260558128357\n",
      "batch 85: loss 0.3262908160686493\n",
      "batch 86: loss 0.40009477734565735\n",
      "batch 87: loss 0.4996603727340698\n",
      "batch 88: loss 0.46154940128326416\n",
      "batch 89: loss 0.5001076459884644\n",
      "batch 90: loss 0.7662776112556458\n",
      "batch 91: loss 0.49888521432876587\n",
      "batch 92: loss 0.34769102931022644\n",
      "batch 93: loss 0.6146438121795654\n",
      "batch 94: loss 0.4403647184371948\n",
      "batch 95: loss 0.5103811621665955\n",
      "batch 96: loss 0.3690662980079651\n",
      "batch 97: loss 0.4002086818218231\n",
      "batch 98: loss 0.4867197275161743\n",
      "batch 99: loss 0.3005863428115845\n",
      "batch 100: loss 0.33945250511169434\n",
      "batch 101: loss 0.547822117805481\n",
      "batch 102: loss 0.47304821014404297\n",
      "batch 103: loss 0.3910664916038513\n",
      "batch 104: loss 0.41433432698249817\n",
      "batch 105: loss 0.3822239637374878\n",
      "batch 106: loss 0.5103775858879089\n",
      "batch 107: loss 0.5109954476356506\n",
      "batch 108: loss 0.4723067283630371\n",
      "batch 109: loss 0.2878660261631012\n",
      "batch 110: loss 0.37695884704589844\n",
      "batch 111: loss 0.38201195001602173\n",
      "batch 112: loss 0.2589135468006134\n",
      "batch 113: loss 0.6355665326118469\n",
      "batch 114: loss 0.3608638346195221\n",
      "batch 115: loss 0.41757532954216003\n",
      "batch 116: loss 0.5221642255783081\n",
      "batch 117: loss 0.35996317863464355\n",
      "batch 118: loss 0.3897000551223755\n",
      "batch 119: loss 0.4120553731918335\n",
      "batch 120: loss 0.6051304340362549\n",
      "batch 121: loss 0.6443148851394653\n",
      "batch 122: loss 0.38929542899131775\n",
      "batch 123: loss 0.2690374255180359\n",
      "batch 124: loss 0.28484487533569336\n",
      "batch 125: loss 0.4462229907512665\n",
      "batch 126: loss 0.35709869861602783\n",
      "batch 127: loss 0.6543571352958679\n",
      "batch 128: loss 0.25843167304992676\n",
      "batch 129: loss 0.5390507578849792\n",
      "batch 130: loss 0.359003484249115\n",
      "batch 131: loss 0.4271385967731476\n",
      "batch 132: loss 0.45584601163864136\n",
      "batch 133: loss 0.2852921187877655\n",
      "batch 134: loss 0.405579149723053\n",
      "batch 135: loss 0.2888469994068146\n",
      "batch 136: loss 0.3661929965019226\n",
      "batch 137: loss 0.3334130346775055\n",
      "batch 138: loss 0.35467827320098877\n",
      "batch 139: loss 0.4653882384300232\n",
      "batch 140: loss 0.36082926392555237\n",
      "batch 141: loss 0.40572389960289\n",
      "batch 142: loss 0.24514855444431305\n",
      "batch 143: loss 0.3022506833076477\n",
      "batch 144: loss 0.4406903386116028\n",
      "batch 145: loss 0.4220907390117645\n",
      "batch 146: loss 0.29361942410469055\n",
      "batch 147: loss 0.40818601846694946\n",
      "batch 148: loss 0.2165035754442215\n",
      "batch 149: loss 0.185953289270401\n",
      "batch 150: loss 0.433463990688324\n",
      "batch 151: loss 0.3375511169433594\n",
      "batch 152: loss 0.5371549129486084\n",
      "batch 153: loss 0.4613588750362396\n",
      "batch 154: loss 0.21626240015029907\n",
      "batch 155: loss 0.4930221438407898\n",
      "batch 156: loss 0.3627859055995941\n",
      "batch 157: loss 0.36134669184684753\n",
      "batch 158: loss 0.5433887839317322\n",
      "batch 159: loss 0.31954699754714966\n",
      "batch 160: loss 0.642155110836029\n",
      "batch 161: loss 0.3980625867843628\n",
      "batch 162: loss 0.16784124076366425\n",
      "batch 163: loss 0.27603408694267273\n",
      "batch 164: loss 0.45133644342422485\n",
      "batch 165: loss 0.39594465494155884\n",
      "batch 166: loss 0.4714958965778351\n",
      "batch 167: loss 0.4067583382129669\n",
      "batch 168: loss 0.39551442861557007\n",
      "batch 169: loss 0.45826706290245056\n",
      "batch 170: loss 0.35640203952789307\n",
      "batch 171: loss 0.24833285808563232\n",
      "batch 172: loss 0.3350004553794861\n",
      "batch 173: loss 0.34727194905281067\n",
      "batch 174: loss 0.3233930170536041\n",
      "batch 175: loss 0.34238386154174805\n",
      "batch 176: loss 0.2756122946739197\n",
      "batch 177: loss 0.25858181715011597\n",
      "batch 178: loss 0.325833797454834\n",
      "batch 179: loss 0.3342132568359375\n",
      "batch 180: loss 0.4524517059326172\n",
      "batch 181: loss 0.26867911219596863\n",
      "batch 182: loss 0.5221565961837769\n",
      "batch 183: loss 0.279559850692749\n",
      "batch 184: loss 0.21553798019886017\n",
      "batch 185: loss 0.38623884320259094\n",
      "batch 186: loss 0.24800711870193481\n",
      "batch 187: loss 0.37408193945884705\n",
      "batch 188: loss 0.33988723158836365\n",
      "batch 189: loss 0.3532262444496155\n",
      "batch 190: loss 0.42566928267478943\n",
      "batch 191: loss 0.26108095049858093\n",
      "batch 192: loss 0.22801822423934937\n",
      "batch 193: loss 0.23914413154125214\n",
      "batch 194: loss 0.21936443448066711\n",
      "batch 195: loss 0.46865546703338623\n",
      "batch 196: loss 0.46939781308174133\n",
      "batch 197: loss 0.39617422223091125\n",
      "batch 198: loss 0.2314290553331375\n",
      "batch 199: loss 0.472746342420578\n",
      "batch 200: loss 0.2850097715854645\n",
      "batch 201: loss 0.2895810306072235\n",
      "batch 202: loss 0.18644967675209045\n",
      "batch 203: loss 0.39311715960502625\n",
      "batch 204: loss 0.435790479183197\n",
      "batch 205: loss 0.5444058775901794\n",
      "batch 206: loss 0.5361577868461609\n",
      "batch 207: loss 0.3267374336719513\n",
      "batch 208: loss 0.2795270085334778\n",
      "batch 209: loss 0.34572044014930725\n",
      "batch 210: loss 0.3428053557872772\n",
      "batch 211: loss 0.6964712142944336\n",
      "batch 212: loss 0.12470662593841553\n",
      "batch 213: loss 0.49032485485076904\n",
      "batch 214: loss 0.5279439687728882\n",
      "batch 215: loss 0.39049941301345825\n",
      "batch 216: loss 0.3812791407108307\n",
      "batch 217: loss 0.38316047191619873\n",
      "batch 218: loss 0.3790516257286072\n",
      "batch 219: loss 0.1957922726869583\n",
      "batch 220: loss 0.29752442240715027\n",
      "batch 221: loss 0.3106841444969177\n",
      "batch 222: loss 0.34752845764160156\n",
      "batch 223: loss 0.2938095033168793\n",
      "batch 224: loss 0.3675031065940857\n",
      "batch 225: loss 0.4219341278076172\n",
      "batch 226: loss 0.43910107016563416\n",
      "batch 227: loss 0.24831153452396393\n",
      "batch 228: loss 0.16495844721794128\n",
      "batch 229: loss 0.157145157456398\n",
      "batch 230: loss 0.18981674313545227\n",
      "batch 231: loss 0.3721536695957184\n",
      "batch 232: loss 0.25028321146965027\n",
      "batch 233: loss 0.31440889835357666\n",
      "batch 234: loss 0.18593531847000122\n",
      "batch 235: loss 0.37703245878219604\n",
      "batch 236: loss 0.27419546246528625\n",
      "batch 237: loss 0.45768797397613525\n",
      "batch 238: loss 0.37542852759361267\n",
      "batch 239: loss 0.33505308628082275\n",
      "batch 240: loss 0.3472639322280884\n",
      "batch 241: loss 0.3454771339893341\n",
      "batch 242: loss 0.4660819172859192\n",
      "batch 243: loss 0.5744838118553162\n",
      "batch 244: loss 0.54228276014328\n",
      "batch 245: loss 0.34649747610092163\n",
      "batch 246: loss 0.24516749382019043\n",
      "batch 247: loss 0.395210325717926\n",
      "batch 248: loss 0.19794504344463348\n",
      "batch 249: loss 0.542485237121582\n",
      "batch 250: loss 0.19855254888534546\n",
      "batch 251: loss 0.21862977743148804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 252: loss 0.21521815657615662\n",
      "batch 253: loss 0.3988133668899536\n",
      "batch 254: loss 0.21556247770786285\n",
      "batch 255: loss 0.2677079141139984\n",
      "batch 256: loss 0.34553390741348267\n",
      "batch 257: loss 0.16768860816955566\n",
      "batch 258: loss 0.5390146374702454\n",
      "batch 259: loss 0.26769259572029114\n",
      "batch 260: loss 0.3008610010147095\n",
      "batch 261: loss 0.21756117045879364\n",
      "batch 262: loss 0.452384889125824\n",
      "batch 263: loss 0.3166040778160095\n",
      "batch 264: loss 0.14949947595596313\n",
      "batch 265: loss 0.3611223101615906\n",
      "batch 266: loss 0.29933077096939087\n",
      "batch 267: loss 0.19630639255046844\n",
      "batch 268: loss 0.5219059586524963\n",
      "batch 269: loss 0.49085530638694763\n",
      "batch 270: loss 0.21292737126350403\n",
      "batch 271: loss 0.30116796493530273\n",
      "batch 272: loss 0.35086944699287415\n",
      "batch 273: loss 0.2902015149593353\n",
      "batch 274: loss 0.2660571038722992\n",
      "batch 275: loss 0.23285678029060364\n",
      "batch 276: loss 0.4210340678691864\n",
      "batch 277: loss 0.28089237213134766\n",
      "batch 278: loss 0.2126895636320114\n",
      "batch 279: loss 0.2748216688632965\n",
      "batch 280: loss 0.7307579517364502\n",
      "batch 281: loss 0.29547426104545593\n",
      "batch 282: loss 0.21215863525867462\n",
      "batch 283: loss 0.4057248532772064\n",
      "batch 284: loss 0.7073448300361633\n",
      "batch 285: loss 0.18792448937892914\n",
      "batch 286: loss 0.19389106333255768\n",
      "batch 287: loss 0.1869836449623108\n",
      "batch 288: loss 0.29398059844970703\n",
      "batch 289: loss 0.2597786486148834\n",
      "batch 290: loss 0.4644884467124939\n",
      "batch 291: loss 0.3343759775161743\n",
      "batch 292: loss 0.4117088317871094\n",
      "batch 293: loss 0.21760600805282593\n",
      "batch 294: loss 0.22259441018104553\n",
      "batch 295: loss 0.3088083267211914\n",
      "batch 296: loss 0.19985955953598022\n",
      "batch 297: loss 0.37619316577911377\n",
      "batch 298: loss 0.3676951825618744\n",
      "batch 299: loss 0.20134860277175903\n",
      "batch 300: loss 0.2709622383117676\n",
      "batch 301: loss 0.279615581035614\n",
      "batch 302: loss 0.4139832854270935\n",
      "batch 303: loss 0.130634605884552\n",
      "batch 304: loss 0.4642389714717865\n",
      "batch 305: loss 0.42304420471191406\n",
      "batch 306: loss 0.24490080773830414\n",
      "batch 307: loss 0.3504847586154938\n",
      "batch 308: loss 0.3346356153488159\n",
      "batch 309: loss 0.15261539816856384\n",
      "batch 310: loss 0.30526649951934814\n",
      "batch 311: loss 0.1909008026123047\n",
      "batch 312: loss 0.26431113481521606\n",
      "batch 313: loss 0.28973695635795593\n",
      "batch 314: loss 0.1689918041229248\n",
      "batch 315: loss 0.6437829732894897\n",
      "batch 316: loss 0.22098296880722046\n",
      "batch 317: loss 0.262222558259964\n",
      "batch 318: loss 0.3043974041938782\n",
      "batch 319: loss 0.26968374848365784\n",
      "batch 320: loss 0.3842633068561554\n",
      "batch 321: loss 0.33882638812065125\n",
      "batch 322: loss 0.3619751036167145\n",
      "batch 323: loss 0.4840410649776459\n",
      "batch 324: loss 0.3379846215248108\n",
      "batch 325: loss 0.39880144596099854\n",
      "batch 326: loss 0.23664063215255737\n",
      "batch 327: loss 0.22794747352600098\n",
      "batch 328: loss 0.22587214410305023\n",
      "batch 329: loss 0.32955053448677063\n",
      "batch 330: loss 0.2900891900062561\n",
      "batch 331: loss 0.44902586936950684\n",
      "batch 332: loss 0.42016029357910156\n",
      "batch 333: loss 0.15522822737693787\n",
      "batch 334: loss 0.2017877697944641\n",
      "batch 335: loss 0.11948291212320328\n",
      "batch 336: loss 0.32073864340782166\n",
      "batch 337: loss 0.238084614276886\n",
      "batch 338: loss 0.15882107615470886\n",
      "batch 339: loss 0.18451139330863953\n",
      "batch 340: loss 0.24268463253974915\n",
      "batch 341: loss 0.2662544548511505\n",
      "batch 342: loss 0.5094289779663086\n",
      "batch 343: loss 0.4466911852359772\n",
      "batch 344: loss 0.28805819153785706\n",
      "batch 345: loss 0.3973311483860016\n",
      "batch 346: loss 0.22403179109096527\n",
      "batch 347: loss 0.2659420669078827\n",
      "batch 348: loss 0.19127681851387024\n",
      "batch 349: loss 0.20298559963703156\n",
      "batch 350: loss 0.2162904292345047\n",
      "batch 351: loss 0.24827532470226288\n",
      "batch 352: loss 0.139449805021286\n",
      "batch 353: loss 0.24651163816452026\n",
      "batch 354: loss 0.3205033540725708\n",
      "batch 355: loss 0.12169793993234634\n",
      "batch 356: loss 0.26981332898139954\n",
      "batch 357: loss 0.14247138798236847\n",
      "batch 358: loss 0.11714963614940643\n",
      "batch 359: loss 0.2614240348339081\n",
      "batch 360: loss 0.3631174862384796\n",
      "batch 361: loss 0.15753701329231262\n",
      "batch 362: loss 0.2721760869026184\n",
      "batch 363: loss 0.4057101309299469\n",
      "batch 364: loss 0.2943505048751831\n",
      "batch 365: loss 0.2609115540981293\n",
      "batch 366: loss 0.24922272562980652\n",
      "batch 367: loss 0.1896655559539795\n",
      "batch 368: loss 0.27623406052589417\n",
      "batch 369: loss 0.3439675569534302\n",
      "batch 370: loss 0.26222360134124756\n",
      "batch 371: loss 0.35032615065574646\n",
      "batch 372: loss 0.45473089814186096\n",
      "batch 373: loss 0.38271617889404297\n",
      "batch 374: loss 0.2856689691543579\n",
      "batch 375: loss 0.16344815492630005\n",
      "batch 376: loss 0.14953476190567017\n",
      "batch 377: loss 0.4854602813720703\n",
      "batch 378: loss 0.44500765204429626\n",
      "batch 379: loss 0.46144285798072815\n",
      "batch 380: loss 0.45652663707733154\n",
      "batch 381: loss 0.4505878984928131\n",
      "batch 382: loss 0.1987607479095459\n",
      "batch 383: loss 0.3589710295200348\n",
      "batch 384: loss 0.09010372310876846\n",
      "batch 385: loss 0.248575821518898\n",
      "batch 386: loss 0.4128434956073761\n",
      "batch 387: loss 0.21540607511997223\n",
      "batch 388: loss 0.302754670381546\n",
      "batch 389: loss 0.15653032064437866\n",
      "batch 390: loss 0.17165708541870117\n",
      "batch 391: loss 0.12964680790901184\n",
      "batch 392: loss 0.11863858997821808\n",
      "batch 393: loss 0.38553953170776367\n",
      "batch 394: loss 0.28356796503067017\n",
      "batch 395: loss 0.5003337860107422\n",
      "batch 396: loss 0.2780338525772095\n",
      "batch 397: loss 0.2753150165081024\n",
      "batch 398: loss 0.3702404201030731\n",
      "batch 399: loss 0.2833007276058197\n",
      "batch 400: loss 0.35639968514442444\n",
      "batch 401: loss 0.29537642002105713\n",
      "batch 402: loss 0.32667407393455505\n",
      "batch 403: loss 0.2429327368736267\n",
      "batch 404: loss 0.3601763844490051\n",
      "batch 405: loss 0.4453190565109253\n",
      "batch 406: loss 0.16270005702972412\n",
      "batch 407: loss 0.45684587955474854\n",
      "batch 408: loss 0.3813718259334564\n",
      "batch 409: loss 0.3502865135669708\n",
      "batch 410: loss 0.3346591591835022\n",
      "batch 411: loss 0.20871585607528687\n",
      "batch 412: loss 0.20661962032318115\n",
      "batch 413: loss 0.2668723165988922\n",
      "batch 414: loss 0.31259289383888245\n",
      "batch 415: loss 0.08267693221569061\n",
      "batch 416: loss 0.3452082872390747\n",
      "batch 417: loss 0.31125664710998535\n",
      "batch 418: loss 0.26019278168678284\n",
      "batch 419: loss 0.15658704936504364\n",
      "batch 420: loss 0.14661838114261627\n",
      "batch 421: loss 0.12643495202064514\n",
      "batch 422: loss 0.22628238797187805\n",
      "batch 423: loss 0.18330611288547516\n",
      "batch 424: loss 0.14532636106014252\n",
      "batch 425: loss 0.14961585402488708\n",
      "batch 426: loss 0.2011551558971405\n",
      "batch 427: loss 0.3392793834209442\n",
      "batch 428: loss 0.34582680463790894\n",
      "batch 429: loss 0.25681912899017334\n",
      "batch 430: loss 0.21029826998710632\n",
      "batch 431: loss 0.37646380066871643\n",
      "batch 432: loss 0.3615526854991913\n",
      "batch 433: loss 0.16892972588539124\n",
      "batch 434: loss 0.2938724458217621\n",
      "batch 435: loss 0.20175929367542267\n",
      "batch 436: loss 0.25147292017936707\n",
      "batch 437: loss 0.5187680721282959\n",
      "batch 438: loss 0.14256510138511658\n",
      "batch 439: loss 0.14191745221614838\n",
      "batch 440: loss 0.2013465315103531\n",
      "batch 441: loss 0.22608201205730438\n",
      "batch 442: loss 0.2777792513370514\n",
      "batch 443: loss 0.2811184525489807\n",
      "batch 444: loss 0.13064581155776978\n",
      "batch 445: loss 0.43119096755981445\n",
      "batch 446: loss 0.0684409961104393\n",
      "batch 447: loss 0.1777951419353485\n",
      "batch 448: loss 0.19824132323265076\n",
      "batch 449: loss 0.1658378690481186\n",
      "batch 450: loss 0.18009468913078308\n",
      "batch 451: loss 0.12349263578653336\n",
      "batch 452: loss 0.3266567885875702\n",
      "batch 453: loss 0.21656978130340576\n",
      "batch 454: loss 0.47764959931373596\n",
      "batch 455: loss 0.1655724048614502\n",
      "batch 456: loss 0.5627139806747437\n",
      "batch 457: loss 0.25004836916923523\n",
      "batch 458: loss 0.2710266411304474\n",
      "batch 459: loss 0.3415641784667969\n",
      "batch 460: loss 0.22784657776355743\n",
      "batch 461: loss 0.1967172771692276\n",
      "batch 462: loss 0.15489840507507324\n",
      "batch 463: loss 0.2415100783109665\n",
      "batch 464: loss 0.17541983723640442\n",
      "batch 465: loss 0.20308265089988708\n",
      "batch 466: loss 0.29458898305892944\n",
      "batch 467: loss 0.23949801921844482\n",
      "batch 468: loss 0.1494353711605072\n",
      "batch 469: loss 0.1305052936077118\n",
      "batch 470: loss 0.34154897928237915\n",
      "batch 471: loss 0.1881992369890213\n",
      "batch 472: loss 0.1548606902360916\n",
      "batch 473: loss 0.16375786066055298\n",
      "batch 474: loss 0.242226704955101\n",
      "batch 475: loss 0.36962875723838806\n",
      "batch 476: loss 0.17440325021743774\n",
      "batch 477: loss 0.5935565233230591\n",
      "batch 478: loss 0.23296897113323212\n",
      "batch 479: loss 0.21499663591384888\n",
      "batch 480: loss 0.22224824130535126\n",
      "batch 481: loss 0.3091939091682434\n",
      "batch 482: loss 0.32834914326667786\n",
      "batch 483: loss 0.23207446932792664\n",
      "batch 484: loss 0.25647494196891785\n",
      "batch 485: loss 0.3799128532409668\n",
      "batch 486: loss 0.316826730966568\n",
      "batch 487: loss 0.4522422254085541\n",
      "batch 488: loss 0.2954314649105072\n",
      "batch 489: loss 0.23314811289310455\n",
      "batch 490: loss 0.2757386267185211\n",
      "batch 491: loss 0.20645879209041595\n",
      "batch 492: loss 0.21767745912075043\n",
      "batch 493: loss 0.17486704885959625\n",
      "batch 494: loss 0.310054212808609\n",
      "batch 495: loss 0.18044371902942657\n",
      "batch 496: loss 0.19952115416526794\n",
      "batch 497: loss 0.2679581940174103\n",
      "batch 498: loss 0.3216833472251892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 499: loss 0.20532234013080597\n",
      "batch 500: loss 0.7155076265335083\n",
      "batch 501: loss 0.16050133109092712\n",
      "batch 502: loss 0.10372867435216904\n",
      "batch 503: loss 0.4076671600341797\n",
      "batch 504: loss 0.09948620945215225\n",
      "batch 505: loss 0.4464510679244995\n",
      "batch 506: loss 0.17921182513237\n",
      "batch 507: loss 0.14739641547203064\n",
      "batch 508: loss 0.29852885007858276\n",
      "batch 509: loss 0.4577837884426117\n",
      "batch 510: loss 0.21631889045238495\n",
      "batch 511: loss 0.3443073332309723\n",
      "batch 512: loss 0.2657000422477722\n",
      "batch 513: loss 0.17890074849128723\n",
      "batch 514: loss 0.2537586987018585\n",
      "batch 515: loss 0.1849393993616104\n",
      "batch 516: loss 0.3671322464942932\n",
      "batch 517: loss 0.3183537721633911\n",
      "batch 518: loss 0.19231656193733215\n",
      "batch 519: loss 0.26052072644233704\n",
      "batch 520: loss 0.2900692820549011\n",
      "batch 521: loss 0.2156733125448227\n",
      "batch 522: loss 0.18374092876911163\n",
      "batch 523: loss 0.31591278314590454\n",
      "batch 524: loss 0.28520914912223816\n",
      "batch 525: loss 0.16423122584819794\n",
      "batch 526: loss 0.38088446855545044\n",
      "batch 527: loss 0.2078695446252823\n",
      "batch 528: loss 0.1483142077922821\n",
      "batch 529: loss 0.17333292961120605\n",
      "batch 530: loss 0.08984147757291794\n",
      "batch 531: loss 0.07850480824708939\n",
      "batch 532: loss 0.2851737439632416\n",
      "batch 533: loss 0.2675180733203888\n",
      "batch 534: loss 0.1601511538028717\n",
      "batch 535: loss 0.20805543661117554\n",
      "batch 536: loss 0.2109893560409546\n",
      "batch 537: loss 0.19553788006305695\n",
      "batch 538: loss 0.13303515315055847\n",
      "batch 539: loss 0.29074349999427795\n",
      "batch 540: loss 0.10362478345632553\n",
      "batch 541: loss 0.21053330600261688\n",
      "batch 542: loss 0.24148739874362946\n",
      "batch 543: loss 0.18359656631946564\n",
      "batch 544: loss 0.23071718215942383\n",
      "batch 545: loss 0.2736722230911255\n",
      "batch 546: loss 0.13935798406600952\n",
      "batch 547: loss 0.4434890151023865\n",
      "batch 548: loss 0.419259250164032\n",
      "batch 549: loss 0.2309747189283371\n",
      "batch 550: loss 0.25072968006134033\n",
      "batch 551: loss 0.2802985906600952\n",
      "batch 552: loss 0.2123626470565796\n",
      "batch 553: loss 0.1966601014137268\n",
      "batch 554: loss 0.1267232447862625\n",
      "batch 555: loss 0.16793565452098846\n",
      "batch 556: loss 0.1606570929288864\n",
      "batch 557: loss 0.32332929968833923\n",
      "batch 558: loss 0.2555534541606903\n",
      "batch 559: loss 0.08620093762874603\n",
      "batch 560: loss 0.3433570861816406\n",
      "batch 561: loss 0.36175429821014404\n",
      "batch 562: loss 0.28900566697120667\n",
      "batch 563: loss 0.2931089401245117\n",
      "batch 564: loss 0.1376098245382309\n",
      "batch 565: loss 0.17495079338550568\n",
      "batch 566: loss 0.19116507470607758\n",
      "batch 567: loss 0.15911121666431427\n",
      "batch 568: loss 0.11433102935552597\n",
      "batch 569: loss 0.12006137520074844\n",
      "batch 570: loss 0.43928205966949463\n",
      "batch 571: loss 0.12528634071350098\n",
      "batch 572: loss 0.15072079002857208\n",
      "batch 573: loss 0.10444702208042145\n",
      "batch 574: loss 0.22766803205013275\n",
      "batch 575: loss 0.3820532262325287\n",
      "batch 576: loss 0.28266531229019165\n",
      "batch 577: loss 0.23910918831825256\n",
      "batch 578: loss 0.060695912688970566\n",
      "batch 579: loss 0.12024372071027756\n",
      "batch 580: loss 0.17326846718788147\n",
      "batch 581: loss 0.1892080456018448\n",
      "batch 582: loss 0.265505850315094\n",
      "batch 583: loss 0.2720557749271393\n",
      "batch 584: loss 0.15930263698101044\n",
      "batch 585: loss 0.2035815417766571\n",
      "batch 586: loss 0.21436217427253723\n",
      "batch 587: loss 0.2865513265132904\n",
      "batch 588: loss 0.266739159822464\n",
      "batch 589: loss 0.07893650233745575\n",
      "batch 590: loss 0.2233143001794815\n",
      "batch 591: loss 0.22442540526390076\n",
      "batch 592: loss 0.1894168108701706\n",
      "batch 593: loss 0.36693641543388367\n",
      "batch 594: loss 0.19666367769241333\n",
      "batch 595: loss 0.24783611297607422\n",
      "batch 596: loss 0.3202994465827942\n",
      "batch 597: loss 0.30647483468055725\n",
      "batch 598: loss 0.3059937655925751\n",
      "batch 599: loss 0.10331960767507553\n",
      "batch 600: loss 0.18282252550125122\n",
      "batch 601: loss 0.2977692782878876\n",
      "batch 602: loss 0.13518913090229034\n",
      "batch 603: loss 0.1605307161808014\n",
      "batch 604: loss 0.2609342932701111\n",
      "batch 605: loss 0.3630252480506897\n",
      "batch 606: loss 0.2900998890399933\n",
      "batch 607: loss 0.3428083658218384\n",
      "batch 608: loss 0.4286406636238098\n",
      "batch 609: loss 0.28290626406669617\n",
      "batch 610: loss 0.15451018512248993\n",
      "batch 611: loss 0.25352197885513306\n",
      "batch 612: loss 0.3273852467536926\n",
      "batch 613: loss 0.24961818754673004\n",
      "batch 614: loss 0.16884247958660126\n",
      "batch 615: loss 0.2557325065135956\n",
      "batch 616: loss 0.39194613695144653\n",
      "batch 617: loss 0.2941890060901642\n",
      "batch 618: loss 0.16853399574756622\n",
      "batch 619: loss 0.1398068517446518\n",
      "batch 620: loss 0.09464776515960693\n",
      "batch 621: loss 0.17832519114017487\n",
      "batch 622: loss 0.180805042386055\n",
      "batch 623: loss 0.252989262342453\n",
      "batch 624: loss 0.20729003846645355\n",
      "batch 625: loss 0.3774212598800659\n",
      "batch 626: loss 0.1273716241121292\n",
      "batch 627: loss 0.4012438952922821\n",
      "batch 628: loss 0.20814231038093567\n",
      "batch 629: loss 0.18082073330879211\n",
      "batch 630: loss 0.12023215740919113\n",
      "batch 631: loss 0.37971359491348267\n",
      "batch 632: loss 0.2604522705078125\n",
      "batch 633: loss 0.16758525371551514\n",
      "batch 634: loss 0.3031119704246521\n",
      "batch 635: loss 0.35169360041618347\n",
      "batch 636: loss 0.13288547098636627\n",
      "batch 637: loss 0.30848219990730286\n",
      "batch 638: loss 0.11582730710506439\n",
      "batch 639: loss 0.13766072690486908\n",
      "batch 640: loss 0.10596203804016113\n",
      "batch 641: loss 0.17091979086399078\n",
      "batch 642: loss 0.34606197476387024\n",
      "batch 643: loss 0.23302216827869415\n",
      "batch 644: loss 0.3520795404911041\n",
      "batch 645: loss 0.22021958231925964\n",
      "batch 646: loss 0.25611647963523865\n",
      "batch 647: loss 0.3630383610725403\n",
      "batch 648: loss 0.15629389882087708\n",
      "batch 649: loss 0.1401357799768448\n",
      "batch 650: loss 0.13592584431171417\n",
      "batch 651: loss 0.26582545042037964\n",
      "batch 652: loss 0.23649947345256805\n",
      "batch 653: loss 0.2891933023929596\n",
      "batch 654: loss 0.22621628642082214\n",
      "batch 655: loss 0.4544033408164978\n",
      "batch 656: loss 0.1507631540298462\n",
      "batch 657: loss 0.11560695618391037\n",
      "batch 658: loss 0.14741143584251404\n",
      "batch 659: loss 0.2372806817293167\n",
      "batch 660: loss 0.25957897305488586\n",
      "batch 661: loss 0.18646059930324554\n",
      "batch 662: loss 0.24129344522953033\n",
      "batch 663: loss 0.20544511079788208\n",
      "batch 664: loss 0.24278078973293304\n",
      "batch 665: loss 0.11622335016727448\n",
      "batch 666: loss 0.31243038177490234\n",
      "batch 667: loss 0.27266913652420044\n",
      "batch 668: loss 0.49963587522506714\n",
      "batch 669: loss 0.1723620593547821\n",
      "batch 670: loss 0.23050977289676666\n",
      "batch 671: loss 0.17388738691806793\n",
      "batch 672: loss 0.23810924589633942\n",
      "batch 673: loss 0.20143428444862366\n",
      "batch 674: loss 0.18696820735931396\n",
      "batch 675: loss 0.16211816668510437\n",
      "batch 676: loss 0.15590547025203705\n",
      "batch 677: loss 0.19203893840312958\n",
      "batch 678: loss 0.169245183467865\n",
      "batch 679: loss 0.45320308208465576\n",
      "batch 680: loss 0.1659604161977768\n",
      "batch 681: loss 0.12177268415689468\n",
      "batch 682: loss 0.06481657922267914\n",
      "batch 683: loss 0.18228887021541595\n",
      "batch 684: loss 0.09477172791957855\n",
      "batch 685: loss 0.255374550819397\n",
      "batch 686: loss 0.1779344379901886\n",
      "batch 687: loss 0.09795571863651276\n",
      "batch 688: loss 0.10635124146938324\n",
      "batch 689: loss 0.07512443512678146\n",
      "batch 690: loss 0.3123983144760132\n",
      "batch 691: loss 0.24405576288700104\n",
      "batch 692: loss 0.32027384638786316\n",
      "batch 693: loss 0.11617576330900192\n",
      "batch 694: loss 0.20399247109889984\n",
      "batch 695: loss 0.2378527820110321\n",
      "batch 696: loss 0.09130023419857025\n",
      "batch 697: loss 0.4148258864879608\n",
      "batch 698: loss 0.1583031564950943\n",
      "batch 699: loss 0.4337290823459625\n",
      "batch 700: loss 0.08170083910226822\n",
      "batch 701: loss 0.1599908322095871\n",
      "batch 702: loss 0.11722170561552048\n",
      "batch 703: loss 0.25372961163520813\n",
      "batch 704: loss 0.3249568045139313\n",
      "batch 705: loss 0.5181201696395874\n",
      "batch 706: loss 0.1559760570526123\n",
      "batch 707: loss 0.3737890124320984\n",
      "batch 708: loss 0.042445238679647446\n",
      "batch 709: loss 0.1510024219751358\n",
      "batch 710: loss 0.11880650371313095\n",
      "batch 711: loss 0.25063472986221313\n",
      "batch 712: loss 0.12281148880720139\n",
      "batch 713: loss 0.40747976303100586\n",
      "batch 714: loss 0.42805004119873047\n",
      "batch 715: loss 0.23086032271385193\n",
      "batch 716: loss 0.10498613119125366\n",
      "batch 717: loss 0.19651466608047485\n",
      "batch 718: loss 0.20714133977890015\n",
      "batch 719: loss 0.06735944747924805\n",
      "batch 720: loss 0.29880717396736145\n",
      "batch 721: loss 0.264162540435791\n",
      "batch 722: loss 0.1623162478208542\n",
      "batch 723: loss 0.235954150557518\n",
      "batch 724: loss 0.15368612110614777\n",
      "batch 725: loss 0.29357099533081055\n",
      "batch 726: loss 0.2138521671295166\n",
      "batch 727: loss 0.18643687665462494\n",
      "batch 728: loss 0.08759348839521408\n",
      "batch 729: loss 0.43569743633270264\n",
      "batch 730: loss 0.08675698935985565\n",
      "batch 731: loss 0.16437628865242004\n",
      "batch 732: loss 0.08342590183019638\n",
      "batch 733: loss 0.20590271055698395\n",
      "batch 734: loss 0.23781397938728333\n",
      "batch 735: loss 0.3878144323825836\n",
      "batch 736: loss 0.2795945107936859\n",
      "batch 737: loss 0.2157108187675476\n",
      "batch 738: loss 0.49365365505218506\n",
      "batch 739: loss 0.11341658979654312\n",
      "batch 740: loss 0.2502889633178711\n",
      "batch 741: loss 0.09972008317708969\n",
      "batch 742: loss 0.14166241884231567\n",
      "batch 743: loss 0.2129085510969162\n",
      "batch 744: loss 0.22100818157196045\n",
      "batch 745: loss 0.4337880611419678\n",
      "batch 746: loss 0.14871716499328613\n",
      "batch 747: loss 0.13486209511756897\n",
      "batch 748: loss 0.3825298547744751\n",
      "batch 749: loss 0.20576545596122742\n",
      "batch 750: loss 0.3214922547340393\n",
      "batch 751: loss 0.16728395223617554\n",
      "batch 752: loss 0.30161574482917786\n",
      "batch 753: loss 0.29235854744911194\n",
      "batch 754: loss 0.1902100294828415\n",
      "batch 755: loss 0.25914543867111206\n",
      "batch 756: loss 0.1295572966337204\n",
      "batch 757: loss 0.18157847225666046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 758: loss 0.2842966616153717\n",
      "batch 759: loss 0.20970191061496735\n",
      "batch 760: loss 0.32217949628829956\n",
      "batch 761: loss 0.15411075949668884\n",
      "batch 762: loss 0.102567158639431\n",
      "batch 763: loss 0.23558032512664795\n",
      "batch 764: loss 0.10985280573368073\n",
      "batch 765: loss 0.21874557435512543\n",
      "batch 766: loss 0.11989489942789078\n",
      "batch 767: loss 0.4594474732875824\n",
      "batch 768: loss 0.22298561036586761\n",
      "batch 769: loss 0.16461536288261414\n",
      "batch 770: loss 0.2969748377799988\n",
      "batch 771: loss 0.22994393110275269\n",
      "batch 772: loss 0.0861022099852562\n",
      "batch 773: loss 0.19118236005306244\n",
      "batch 774: loss 0.11846795678138733\n",
      "batch 775: loss 0.3656146824359894\n",
      "batch 776: loss 0.1644221395254135\n",
      "batch 777: loss 0.2079099863767624\n",
      "batch 778: loss 0.07584474980831146\n",
      "batch 779: loss 0.263822466135025\n",
      "batch 780: loss 0.16324229538440704\n",
      "batch 781: loss 0.03529270738363266\n",
      "batch 782: loss 0.242379829287529\n",
      "batch 783: loss 0.2420186996459961\n",
      "batch 784: loss 0.11078204959630966\n",
      "batch 785: loss 0.13609179854393005\n",
      "batch 786: loss 0.1582057923078537\n",
      "batch 787: loss 0.08938121795654297\n",
      "batch 788: loss 0.11971248686313629\n",
      "batch 789: loss 0.11380530893802643\n",
      "batch 790: loss 0.2255302369594574\n",
      "batch 791: loss 0.24686847627162933\n",
      "batch 792: loss 0.09469570219516754\n",
      "batch 793: loss 0.13956907391548157\n",
      "batch 794: loss 0.2004329264163971\n",
      "batch 795: loss 0.1228797659277916\n",
      "batch 796: loss 0.096803218126297\n",
      "batch 797: loss 0.15383541584014893\n",
      "batch 798: loss 0.1711832582950592\n",
      "batch 799: loss 0.1372436136007309\n",
      "batch 800: loss 0.13910439610481262\n",
      "batch 801: loss 0.10331310331821442\n",
      "batch 802: loss 0.1264110803604126\n",
      "batch 803: loss 0.10861502587795258\n",
      "batch 804: loss 0.2216666340827942\n",
      "batch 805: loss 0.43561747670173645\n",
      "batch 806: loss 0.07892991602420807\n",
      "batch 807: loss 0.2514415681362152\n",
      "batch 808: loss 0.16413749754428864\n",
      "batch 809: loss 0.16546905040740967\n",
      "batch 810: loss 0.21327468752861023\n",
      "batch 811: loss 0.10491163283586502\n",
      "batch 812: loss 0.12343742698431015\n",
      "batch 813: loss 0.20294372737407684\n",
      "batch 814: loss 0.08167596906423569\n",
      "batch 815: loss 0.23151317238807678\n",
      "batch 816: loss 0.21306493878364563\n",
      "batch 817: loss 0.22436489164829254\n",
      "batch 818: loss 0.10063917189836502\n",
      "batch 819: loss 0.09231264889240265\n",
      "batch 820: loss 0.16869479417800903\n",
      "batch 821: loss 0.19001656770706177\n",
      "batch 822: loss 0.1943017542362213\n",
      "batch 823: loss 0.21546100080013275\n",
      "batch 824: loss 0.13857018947601318\n",
      "batch 825: loss 0.10480388253927231\n",
      "batch 826: loss 0.2044554501771927\n",
      "batch 827: loss 0.1532544195652008\n",
      "batch 828: loss 0.16930855810642242\n",
      "batch 829: loss 0.12125673145055771\n",
      "batch 830: loss 0.18768341839313507\n",
      "batch 831: loss 0.13152550160884857\n",
      "batch 832: loss 0.19159770011901855\n",
      "batch 833: loss 0.13140399754047394\n",
      "batch 834: loss 0.3823433518409729\n",
      "batch 835: loss 0.1321997493505478\n",
      "batch 836: loss 0.24436037242412567\n",
      "batch 837: loss 0.1840762346982956\n",
      "batch 838: loss 0.22494882345199585\n",
      "batch 839: loss 0.22583246231079102\n",
      "batch 840: loss 0.0844123512506485\n",
      "batch 841: loss 0.11739570647478104\n",
      "batch 842: loss 0.2496345490217209\n",
      "batch 843: loss 0.19816821813583374\n",
      "batch 844: loss 0.16312755644321442\n",
      "batch 845: loss 0.15000180900096893\n",
      "batch 846: loss 0.21461084485054016\n",
      "batch 847: loss 0.11882810294628143\n",
      "batch 848: loss 0.15019337832927704\n",
      "batch 849: loss 0.06440900266170502\n",
      "batch 850: loss 0.13041281700134277\n",
      "batch 851: loss 0.17633084952831268\n",
      "batch 852: loss 0.2195269763469696\n",
      "batch 853: loss 0.15240104496479034\n",
      "batch 854: loss 0.26106736063957214\n",
      "batch 855: loss 0.1459001898765564\n",
      "batch 856: loss 0.32143211364746094\n",
      "batch 857: loss 0.15529842674732208\n",
      "batch 858: loss 0.22566001117229462\n",
      "batch 859: loss 0.16475656628608704\n",
      "batch 860: loss 0.23339514434337616\n",
      "batch 861: loss 0.23383592069149017\n",
      "batch 862: loss 0.22800616919994354\n",
      "batch 863: loss 0.22672080993652344\n",
      "batch 864: loss 0.17414839565753937\n",
      "batch 865: loss 0.1428203284740448\n",
      "batch 866: loss 0.10254018753767014\n",
      "batch 867: loss 0.2376159429550171\n",
      "batch 868: loss 0.10672274231910706\n",
      "batch 869: loss 0.18800969421863556\n",
      "batch 870: loss 0.2476196587085724\n",
      "batch 871: loss 0.25473886728286743\n",
      "batch 872: loss 0.2677200138568878\n",
      "batch 873: loss 0.13298271596431732\n",
      "batch 874: loss 0.2964170575141907\n",
      "batch 875: loss 0.11272874474525452\n",
      "batch 876: loss 0.21725301444530487\n",
      "batch 877: loss 0.09291758388280869\n",
      "batch 878: loss 0.2780848741531372\n",
      "batch 879: loss 0.19930091500282288\n",
      "batch 880: loss 0.15756916999816895\n",
      "batch 881: loss 0.13757659494876862\n",
      "batch 882: loss 0.14386244118213654\n",
      "batch 883: loss 0.33321383595466614\n",
      "batch 884: loss 0.10320961475372314\n",
      "batch 885: loss 0.06935244798660278\n",
      "batch 886: loss 0.42362117767333984\n",
      "batch 887: loss 0.10715676844120026\n",
      "batch 888: loss 0.08263642340898514\n",
      "batch 889: loss 0.24411815404891968\n",
      "batch 890: loss 0.20480437576770782\n",
      "batch 891: loss 0.11646899580955505\n",
      "batch 892: loss 0.2608097791671753\n",
      "batch 893: loss 0.13773439824581146\n",
      "batch 894: loss 0.2570250928401947\n",
      "batch 895: loss 0.2336876094341278\n",
      "batch 896: loss 0.07130163162946701\n",
      "batch 897: loss 0.13039328157901764\n",
      "batch 898: loss 0.2078254222869873\n",
      "batch 899: loss 0.10644171386957169\n",
      "batch 900: loss 0.10087735950946808\n",
      "batch 901: loss 0.20130160450935364\n",
      "batch 902: loss 0.17694492638111115\n",
      "batch 903: loss 0.24817757308483124\n",
      "batch 904: loss 0.19333508610725403\n",
      "batch 905: loss 0.09954174607992172\n",
      "batch 906: loss 0.31621313095092773\n",
      "batch 907: loss 0.11474520713090897\n",
      "batch 908: loss 0.2500482499599457\n",
      "batch 909: loss 0.278457909822464\n",
      "batch 910: loss 0.17355458438396454\n",
      "batch 911: loss 0.11544232815504074\n",
      "batch 912: loss 0.07551677525043488\n",
      "batch 913: loss 0.2537040412425995\n",
      "batch 914: loss 0.06249338388442993\n",
      "batch 915: loss 0.1961268037557602\n",
      "batch 916: loss 0.16509079933166504\n",
      "batch 917: loss 0.17408013343811035\n",
      "batch 918: loss 0.08877765387296677\n",
      "batch 919: loss 0.25935429334640503\n",
      "batch 920: loss 0.17434382438659668\n",
      "batch 921: loss 0.25109127163887024\n",
      "batch 922: loss 0.1786128431558609\n",
      "batch 923: loss 0.13857650756835938\n",
      "batch 924: loss 0.2899568974971771\n",
      "batch 925: loss 0.0927000567317009\n",
      "batch 926: loss 0.10939044505357742\n",
      "batch 927: loss 0.27224090695381165\n",
      "batch 928: loss 0.24990908801555634\n",
      "batch 929: loss 0.08829835802316666\n",
      "batch 930: loss 0.0855347216129303\n",
      "batch 931: loss 0.17148670554161072\n",
      "batch 932: loss 0.26507270336151123\n",
      "batch 933: loss 0.10978887230157852\n",
      "batch 934: loss 0.07334490865468979\n",
      "batch 935: loss 0.3459750711917877\n",
      "batch 936: loss 0.2541852295398712\n",
      "batch 937: loss 0.1300644874572754\n",
      "batch 938: loss 0.1461169272661209\n",
      "batch 939: loss 0.15558277070522308\n",
      "batch 940: loss 0.301555871963501\n",
      "batch 941: loss 0.13631676137447357\n",
      "batch 942: loss 0.46040046215057373\n",
      "batch 943: loss 0.16016116738319397\n",
      "batch 944: loss 0.16305679082870483\n",
      "batch 945: loss 0.12813425064086914\n",
      "batch 946: loss 0.13737058639526367\n",
      "batch 947: loss 0.40691953897476196\n",
      "batch 948: loss 0.20148272812366486\n",
      "batch 949: loss 0.23227378726005554\n",
      "batch 950: loss 0.2977380156517029\n",
      "batch 951: loss 0.22417910397052765\n",
      "batch 952: loss 0.24402472376823425\n",
      "batch 953: loss 0.28687530755996704\n",
      "batch 954: loss 0.19851191341876984\n",
      "batch 955: loss 0.29350122809410095\n",
      "batch 956: loss 0.2213449627161026\n",
      "batch 957: loss 0.0844658613204956\n",
      "batch 958: loss 0.057891491800546646\n",
      "batch 959: loss 0.4207566976547241\n",
      "batch 960: loss 0.0940091609954834\n",
      "batch 961: loss 0.10783334821462631\n",
      "batch 962: loss 0.351938396692276\n",
      "batch 963: loss 0.10112062841653824\n",
      "batch 964: loss 0.13312962651252747\n",
      "batch 965: loss 0.09011838585138321\n",
      "batch 966: loss 0.14092157781124115\n",
      "batch 967: loss 0.16758506000041962\n",
      "batch 968: loss 0.12630042433738708\n",
      "batch 969: loss 0.13280004262924194\n",
      "batch 970: loss 0.09443344175815582\n",
      "batch 971: loss 0.2160116732120514\n",
      "batch 972: loss 0.21654585003852844\n",
      "batch 973: loss 0.13503575325012207\n",
      "batch 974: loss 0.24209097027778625\n",
      "batch 975: loss 0.12762120366096497\n",
      "batch 976: loss 0.25774192810058594\n",
      "batch 977: loss 0.11620420962572098\n",
      "batch 978: loss 0.20108428597450256\n",
      "batch 979: loss 0.10673646628856659\n",
      "batch 980: loss 0.1276121735572815\n",
      "batch 981: loss 0.11488182097673416\n",
      "batch 982: loss 0.08765685558319092\n",
      "batch 983: loss 0.10588671267032623\n",
      "batch 984: loss 0.07311331480741501\n",
      "batch 985: loss 0.09240463376045227\n",
      "batch 986: loss 0.33009031414985657\n",
      "batch 987: loss 0.31293776631355286\n",
      "batch 988: loss 0.06684251874685287\n",
      "batch 989: loss 0.3057705760002136\n",
      "batch 990: loss 0.07643862068653107\n",
      "batch 991: loss 0.14720888435840607\n",
      "batch 992: loss 0.28367921710014343\n",
      "batch 993: loss 0.2602238357067108\n",
      "batch 994: loss 0.3291895091533661\n",
      "batch 995: loss 0.20342159271240234\n",
      "batch 996: loss 0.25956016778945923\n",
      "batch 997: loss 0.2104647010564804\n",
      "batch 998: loss 0.20516398549079895\n",
      "batch 999: loss 0.20048700273036957\n",
      "batch 1000: loss 0.1527366191148758\n",
      "batch 1001: loss 0.06731890887022018\n",
      "batch 1002: loss 0.061398010700941086\n",
      "batch 1003: loss 0.10608851909637451\n",
      "batch 1004: loss 0.14941048622131348\n",
      "batch 1005: loss 0.21135656535625458\n",
      "batch 1006: loss 0.17080512642860413\n",
      "batch 1007: loss 0.1915917992591858\n",
      "batch 1008: loss 0.13954271376132965\n",
      "batch 1009: loss 0.25894784927368164\n",
      "batch 1010: loss 0.1040506437420845\n",
      "batch 1011: loss 0.09640299528837204\n",
      "batch 1012: loss 0.07963262498378754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1013: loss 0.09135940670967102\n",
      "batch 1014: loss 0.3697722554206848\n",
      "batch 1015: loss 0.2732320725917816\n",
      "batch 1016: loss 0.12711597979068756\n",
      "batch 1017: loss 0.1084197610616684\n",
      "batch 1018: loss 0.09602268040180206\n",
      "batch 1019: loss 0.17100539803504944\n",
      "batch 1020: loss 0.35996997356414795\n",
      "batch 1021: loss 0.17367111146450043\n",
      "batch 1022: loss 0.18135829269886017\n",
      "batch 1023: loss 0.20467212796211243\n",
      "batch 1024: loss 0.33018797636032104\n",
      "batch 1025: loss 0.24753817915916443\n",
      "batch 1026: loss 0.14725607633590698\n",
      "batch 1027: loss 0.15417304635047913\n",
      "batch 1028: loss 0.15562553703784943\n",
      "batch 1029: loss 0.09998609125614166\n",
      "batch 1030: loss 0.2256435751914978\n",
      "batch 1031: loss 0.14071819186210632\n",
      "batch 1032: loss 0.1354774683713913\n",
      "batch 1033: loss 0.06417471915483475\n",
      "batch 1034: loss 0.12619896233081818\n",
      "batch 1035: loss 0.0912032276391983\n",
      "batch 1036: loss 0.14519207179546356\n",
      "batch 1037: loss 0.1051141545176506\n",
      "batch 1038: loss 0.14408215880393982\n",
      "batch 1039: loss 0.20723624527454376\n",
      "batch 1040: loss 0.12817588448524475\n",
      "batch 1041: loss 0.22660838067531586\n",
      "batch 1042: loss 0.08681019395589828\n",
      "batch 1043: loss 0.15627145767211914\n",
      "batch 1044: loss 0.20587679743766785\n",
      "batch 1045: loss 0.25993821024894714\n",
      "batch 1046: loss 0.16539622843265533\n",
      "batch 1047: loss 0.10562331974506378\n",
      "batch 1048: loss 0.11254297941923141\n",
      "batch 1049: loss 0.46537747979164124\n",
      "batch 1050: loss 0.14397718012332916\n",
      "batch 1051: loss 0.09967158734798431\n",
      "batch 1052: loss 0.2710053324699402\n",
      "batch 1053: loss 0.1290511041879654\n",
      "batch 1054: loss 0.19510672986507416\n",
      "batch 1055: loss 0.08983147144317627\n",
      "batch 1056: loss 0.11334554105997086\n",
      "batch 1057: loss 0.17258912324905396\n",
      "batch 1058: loss 0.1198168620467186\n",
      "batch 1059: loss 0.2743541896343231\n",
      "batch 1060: loss 0.0847497507929802\n",
      "batch 1061: loss 0.0438203401863575\n",
      "batch 1062: loss 0.1373458057641983\n",
      "batch 1063: loss 0.13435444235801697\n",
      "batch 1064: loss 0.12071744352579117\n",
      "batch 1065: loss 0.21760882437229156\n",
      "batch 1066: loss 0.07088698446750641\n",
      "batch 1067: loss 0.29805439710617065\n",
      "batch 1068: loss 0.09630048274993896\n",
      "batch 1069: loss 0.16635333001613617\n",
      "batch 1070: loss 0.12184680998325348\n",
      "batch 1071: loss 0.25817105174064636\n",
      "batch 1072: loss 0.2639615535736084\n",
      "batch 1073: loss 0.2329951673746109\n",
      "batch 1074: loss 0.07483649998903275\n",
      "batch 1075: loss 0.1440161168575287\n",
      "batch 1076: loss 0.19698742032051086\n",
      "batch 1077: loss 0.16328974068164825\n",
      "batch 1078: loss 0.24690015614032745\n",
      "batch 1079: loss 0.12209415435791016\n",
      "batch 1080: loss 0.1099170669913292\n",
      "batch 1081: loss 0.1169726550579071\n",
      "batch 1082: loss 0.16708999872207642\n",
      "batch 1083: loss 0.11640717089176178\n",
      "batch 1084: loss 0.2767580449581146\n",
      "batch 1085: loss 0.15934012830257416\n",
      "batch 1086: loss 0.10971597582101822\n",
      "batch 1087: loss 0.13383102416992188\n",
      "batch 1088: loss 0.08570226281881332\n",
      "batch 1089: loss 0.11359287798404694\n",
      "batch 1090: loss 0.0928201675415039\n",
      "batch 1091: loss 0.13728012144565582\n",
      "batch 1092: loss 0.07438023388385773\n",
      "batch 1093: loss 0.19365271925926208\n",
      "batch 1094: loss 0.07601840049028397\n",
      "batch 1095: loss 0.22409522533416748\n",
      "batch 1096: loss 0.26796117424964905\n",
      "batch 1097: loss 0.15116022527217865\n",
      "batch 1098: loss 0.21085159480571747\n",
      "batch 1099: loss 0.08455926924943924\n",
      "batch 1100: loss 0.07171948999166489\n",
      "batch 1101: loss 0.11253510415554047\n",
      "batch 1102: loss 0.1268494874238968\n",
      "batch 1103: loss 0.403400182723999\n",
      "batch 1104: loss 0.1949358731508255\n",
      "batch 1105: loss 0.18942426145076752\n",
      "batch 1106: loss 0.4180143177509308\n",
      "batch 1107: loss 0.33532947301864624\n",
      "batch 1108: loss 0.11399951577186584\n",
      "batch 1109: loss 0.14995893836021423\n",
      "batch 1110: loss 0.0720713660120964\n",
      "batch 1111: loss 0.14135652780532837\n",
      "batch 1112: loss 0.14936745166778564\n",
      "batch 1113: loss 0.3158130645751953\n",
      "batch 1114: loss 0.1655135154724121\n",
      "batch 1115: loss 0.10085352510213852\n",
      "batch 1116: loss 0.26097485423088074\n",
      "batch 1117: loss 0.26869240403175354\n",
      "batch 1118: loss 0.07908953726291656\n",
      "batch 1119: loss 0.09312082082033157\n",
      "batch 1120: loss 0.20560075342655182\n",
      "batch 1121: loss 0.3181475102901459\n",
      "batch 1122: loss 0.09178687632083893\n",
      "batch 1123: loss 0.14098626375198364\n",
      "batch 1124: loss 0.4024122953414917\n",
      "batch 1125: loss 0.19833914935588837\n",
      "batch 1126: loss 0.0891583263874054\n",
      "batch 1127: loss 0.1143781766295433\n",
      "batch 1128: loss 0.24092429876327515\n",
      "batch 1129: loss 0.19098912179470062\n",
      "batch 1130: loss 0.09528154879808426\n",
      "batch 1131: loss 0.10175016522407532\n",
      "batch 1132: loss 0.11888954043388367\n",
      "batch 1133: loss 0.31515154242515564\n",
      "batch 1134: loss 0.06752941012382507\n",
      "batch 1135: loss 0.11333055049180984\n",
      "batch 1136: loss 0.2597840130329132\n",
      "batch 1137: loss 0.26858043670654297\n",
      "batch 1138: loss 0.2117699235677719\n",
      "batch 1139: loss 0.21836689114570618\n",
      "batch 1140: loss 0.1651272177696228\n",
      "batch 1141: loss 0.4221005141735077\n",
      "batch 1142: loss 0.044260576367378235\n",
      "batch 1143: loss 0.06209118664264679\n",
      "batch 1144: loss 0.1227499470114708\n",
      "batch 1145: loss 0.06703976541757584\n",
      "batch 1146: loss 0.14831095933914185\n",
      "batch 1147: loss 0.09245530515909195\n",
      "batch 1148: loss 0.17222221195697784\n",
      "batch 1149: loss 0.28827235102653503\n",
      "batch 1150: loss 0.20122741162776947\n",
      "batch 1151: loss 0.31971099972724915\n",
      "batch 1152: loss 0.2491988092660904\n",
      "batch 1153: loss 0.08884065598249435\n",
      "batch 1154: loss 0.27543097734451294\n",
      "batch 1155: loss 0.32855430245399475\n",
      "batch 1156: loss 0.21509191393852234\n",
      "batch 1157: loss 0.052726346999406815\n",
      "batch 1158: loss 0.1454872339963913\n",
      "batch 1159: loss 0.12735885381698608\n",
      "batch 1160: loss 0.1300038844347\n",
      "batch 1161: loss 0.14294447004795074\n",
      "batch 1162: loss 0.15700039267539978\n",
      "batch 1163: loss 0.22485816478729248\n",
      "batch 1164: loss 0.21228580176830292\n",
      "batch 1165: loss 0.21012233197689056\n",
      "batch 1166: loss 0.06888272613286972\n",
      "batch 1167: loss 0.2656089663505554\n",
      "batch 1168: loss 0.15085625648498535\n",
      "batch 1169: loss 0.0835144892334938\n",
      "batch 1170: loss 0.11544147878885269\n",
      "batch 1171: loss 0.06672811508178711\n",
      "batch 1172: loss 0.1457836925983429\n",
      "batch 1173: loss 0.11306823790073395\n",
      "batch 1174: loss 0.09774991869926453\n",
      "batch 1175: loss 0.10823222249746323\n",
      "batch 1176: loss 0.30274391174316406\n",
      "batch 1177: loss 0.1154073104262352\n",
      "batch 1178: loss 0.26570188999176025\n",
      "batch 1179: loss 0.06652908772230148\n",
      "batch 1180: loss 0.18494980037212372\n",
      "batch 1181: loss 0.12474796921014786\n",
      "batch 1182: loss 0.34864920377731323\n",
      "batch 1183: loss 0.21287891268730164\n",
      "batch 1184: loss 0.0894828513264656\n",
      "batch 1185: loss 0.2851565182209015\n",
      "batch 1186: loss 0.3171047270298004\n",
      "batch 1187: loss 0.15846329927444458\n",
      "batch 1188: loss 0.35439303517341614\n",
      "batch 1189: loss 0.29760488867759705\n",
      "batch 1190: loss 0.07849621027708054\n",
      "batch 1191: loss 0.1094013974070549\n",
      "batch 1192: loss 0.08280448615550995\n",
      "batch 1193: loss 0.059836287051439285\n",
      "batch 1194: loss 0.1283687800168991\n",
      "batch 1195: loss 0.2669691741466522\n",
      "batch 1196: loss 0.1601574867963791\n",
      "batch 1197: loss 0.1474784016609192\n",
      "batch 1198: loss 0.1378844827413559\n",
      "batch 1199: loss 0.08785159140825272\n",
      "batch 1200: loss 0.1466502696275711\n",
      "batch 1201: loss 0.36753952503204346\n",
      "batch 1202: loss 0.12788447737693787\n",
      "batch 1203: loss 0.09681933373212814\n",
      "batch 1204: loss 0.13888001441955566\n",
      "batch 1205: loss 0.09135162085294724\n",
      "batch 1206: loss 0.22550038993358612\n",
      "batch 1207: loss 0.10538160055875778\n",
      "batch 1208: loss 0.3492562770843506\n",
      "batch 1209: loss 0.13530071079730988\n",
      "batch 1210: loss 0.31821849942207336\n",
      "batch 1211: loss 0.17506501078605652\n",
      "batch 1212: loss 0.04424649104475975\n",
      "batch 1213: loss 0.18324065208435059\n",
      "batch 1214: loss 0.14567388594150543\n",
      "batch 1215: loss 0.26625052094459534\n",
      "batch 1216: loss 0.11561347544193268\n",
      "batch 1217: loss 0.11926957964897156\n",
      "batch 1218: loss 0.059754904359579086\n",
      "batch 1219: loss 0.14018861949443817\n",
      "batch 1220: loss 0.38134336471557617\n",
      "batch 1221: loss 0.15666432678699493\n",
      "batch 1222: loss 0.08732566982507706\n",
      "batch 1223: loss 0.15651558339595795\n",
      "batch 1224: loss 0.2021091729402542\n",
      "batch 1225: loss 0.12552471458911896\n",
      "batch 1226: loss 0.23048266768455505\n",
      "batch 1227: loss 0.08000445365905762\n",
      "batch 1228: loss 0.30349624156951904\n",
      "batch 1229: loss 0.26035913825035095\n",
      "batch 1230: loss 0.11965327709913254\n",
      "batch 1231: loss 0.06343595683574677\n",
      "batch 1232: loss 0.17190200090408325\n",
      "batch 1233: loss 0.24071654677391052\n",
      "batch 1234: loss 0.17572805285453796\n",
      "batch 1235: loss 0.07468602061271667\n",
      "batch 1236: loss 0.18394210934638977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1237: loss 0.1845332682132721\n",
      "batch 1238: loss 0.0708836242556572\n",
      "batch 1239: loss 0.17174415290355682\n",
      "batch 1240: loss 0.10859961062669754\n",
      "batch 1241: loss 0.15791679918766022\n",
      "batch 1242: loss 0.14291143417358398\n",
      "batch 1243: loss 0.1588432341814041\n",
      "batch 1244: loss 0.0917372852563858\n",
      "batch 1245: loss 0.14101609587669373\n",
      "batch 1246: loss 0.17643806338310242\n",
      "batch 1247: loss 0.07502073049545288\n",
      "batch 1248: loss 0.12737612426280975\n",
      "batch 1249: loss 0.1411573588848114\n",
      "batch 1250: loss 0.1416904181241989\n",
      "batch 1251: loss 0.20402154326438904\n",
      "batch 1252: loss 0.15770013630390167\n",
      "batch 1253: loss 0.06572642177343369\n",
      "batch 1254: loss 0.17692221701145172\n",
      "batch 1255: loss 0.10943473875522614\n",
      "batch 1256: loss 0.28926903009414673\n",
      "batch 1257: loss 0.23518437147140503\n",
      "batch 1258: loss 0.25475364923477173\n",
      "batch 1259: loss 0.21900241076946259\n",
      "batch 1260: loss 0.13188542425632477\n",
      "batch 1261: loss 0.07896038144826889\n",
      "batch 1262: loss 0.07511511445045471\n",
      "batch 1263: loss 0.11658434569835663\n",
      "batch 1264: loss 0.07686787843704224\n",
      "batch 1265: loss 0.11142536252737045\n",
      "batch 1266: loss 0.16165713965892792\n",
      "batch 1267: loss 0.1163690909743309\n",
      "batch 1268: loss 0.08760026842355728\n",
      "batch 1269: loss 0.042765818536281586\n",
      "batch 1270: loss 0.13239741325378418\n",
      "batch 1271: loss 0.09932020306587219\n",
      "batch 1272: loss 0.17545665800571442\n",
      "batch 1273: loss 0.19062897562980652\n",
      "batch 1274: loss 0.09454257041215897\n",
      "batch 1275: loss 0.08805558830499649\n",
      "batch 1276: loss 0.1433694213628769\n",
      "batch 1277: loss 0.17453905940055847\n",
      "batch 1278: loss 0.038463227450847626\n",
      "batch 1279: loss 0.18938003480434418\n",
      "batch 1280: loss 0.1637822538614273\n",
      "batch 1281: loss 0.09637364000082016\n",
      "batch 1282: loss 0.18330951035022736\n",
      "batch 1283: loss 0.20125137269496918\n",
      "batch 1284: loss 0.14678816497325897\n",
      "batch 1285: loss 0.2263292670249939\n",
      "batch 1286: loss 0.09687274694442749\n",
      "batch 1287: loss 0.12616883218288422\n",
      "batch 1288: loss 0.1746155172586441\n",
      "batch 1289: loss 0.10836133360862732\n",
      "batch 1290: loss 0.14596259593963623\n",
      "batch 1291: loss 0.13879312574863434\n",
      "batch 1292: loss 0.13150377571582794\n",
      "batch 1293: loss 0.09200076758861542\n",
      "batch 1294: loss 0.1129353865981102\n",
      "batch 1295: loss 0.09705609083175659\n",
      "batch 1296: loss 0.22609499096870422\n",
      "batch 1297: loss 0.3425098657608032\n",
      "batch 1298: loss 0.1604827493429184\n",
      "batch 1299: loss 0.09671909362077713\n",
      "batch 1300: loss 0.17910735309123993\n",
      "batch 1301: loss 0.17137537896633148\n",
      "batch 1302: loss 0.2626018226146698\n",
      "batch 1303: loss 0.16063682734966278\n",
      "batch 1304: loss 0.3321536183357239\n",
      "batch 1305: loss 0.07475986331701279\n",
      "batch 1306: loss 0.1265534907579422\n",
      "batch 1307: loss 0.2950271964073181\n",
      "batch 1308: loss 0.15165428817272186\n",
      "batch 1309: loss 0.39154890179634094\n",
      "batch 1310: loss 0.2724017798900604\n",
      "batch 1311: loss 0.10057365149259567\n",
      "batch 1312: loss 0.1886400729417801\n",
      "batch 1313: loss 0.2927458584308624\n",
      "batch 1314: loss 0.11503917723894119\n",
      "batch 1315: loss 0.15231287479400635\n",
      "batch 1316: loss 0.27724987268447876\n",
      "batch 1317: loss 0.06771113723516464\n",
      "batch 1318: loss 0.4195474088191986\n",
      "batch 1319: loss 0.22564846277236938\n",
      "batch 1320: loss 0.20232278108596802\n",
      "batch 1321: loss 0.3079974055290222\n",
      "batch 1322: loss 0.14962047338485718\n",
      "batch 1323: loss 0.0941450446844101\n",
      "batch 1324: loss 0.09417406469583511\n",
      "batch 1325: loss 0.1864650696516037\n",
      "batch 1326: loss 0.21409794688224792\n",
      "batch 1327: loss 0.2338872253894806\n",
      "batch 1328: loss 0.31328657269477844\n",
      "batch 1329: loss 0.11797714233398438\n",
      "batch 1330: loss 0.15072180330753326\n",
      "batch 1331: loss 0.07843828946352005\n",
      "batch 1332: loss 0.06716635823249817\n",
      "batch 1333: loss 0.2709624171257019\n",
      "batch 1334: loss 0.13348904252052307\n",
      "batch 1335: loss 0.23102791607379913\n",
      "batch 1336: loss 0.1465001255273819\n",
      "batch 1337: loss 0.06077688932418823\n",
      "batch 1338: loss 0.1292625516653061\n",
      "batch 1339: loss 0.3653015196323395\n",
      "batch 1340: loss 0.12023212760686874\n",
      "batch 1341: loss 0.07037794589996338\n",
      "batch 1342: loss 0.051368348300457\n",
      "batch 1343: loss 0.3656938076019287\n",
      "batch 1344: loss 0.15618886053562164\n",
      "batch 1345: loss 0.18743571639060974\n",
      "batch 1346: loss 0.13878348469734192\n",
      "batch 1347: loss 0.2775885760784149\n",
      "batch 1348: loss 0.2231205850839615\n",
      "batch 1349: loss 0.05674514174461365\n",
      "batch 1350: loss 0.26860079169273376\n",
      "batch 1351: loss 0.06544199585914612\n",
      "batch 1352: loss 0.05566389113664627\n",
      "batch 1353: loss 0.16203869879245758\n",
      "batch 1354: loss 0.09032484143972397\n",
      "batch 1355: loss 0.13049054145812988\n",
      "batch 1356: loss 0.13252298533916473\n",
      "batch 1357: loss 0.07680080085992813\n",
      "batch 1358: loss 0.11468036472797394\n",
      "batch 1359: loss 0.08495158702135086\n",
      "batch 1360: loss 0.09277688711881638\n",
      "batch 1361: loss 0.25132983922958374\n",
      "batch 1362: loss 0.17978234589099884\n",
      "batch 1363: loss 0.0452212430536747\n",
      "batch 1364: loss 0.21571917831897736\n",
      "batch 1365: loss 0.11897425353527069\n",
      "batch 1366: loss 0.21255415678024292\n",
      "batch 1367: loss 0.2608100175857544\n",
      "batch 1368: loss 0.04335230588912964\n",
      "batch 1369: loss 0.07167278230190277\n",
      "batch 1370: loss 0.06086774170398712\n",
      "batch 1371: loss 0.23393341898918152\n",
      "batch 1372: loss 0.16171863675117493\n",
      "batch 1373: loss 0.13540451228618622\n",
      "batch 1374: loss 0.1851060390472412\n",
      "batch 1375: loss 0.043592680245637894\n",
      "batch 1376: loss 0.057519301772117615\n",
      "batch 1377: loss 0.05257119983434677\n",
      "batch 1378: loss 0.18654967844486237\n",
      "batch 1379: loss 0.1884680539369583\n",
      "batch 1380: loss 0.13354092836380005\n",
      "batch 1381: loss 0.3137715458869934\n",
      "batch 1382: loss 0.06975924223661423\n",
      "batch 1383: loss 0.19441400468349457\n",
      "batch 1384: loss 0.12980610132217407\n",
      "batch 1385: loss 0.19934552907943726\n",
      "batch 1386: loss 0.08706945925951004\n",
      "batch 1387: loss 0.07907745987176895\n",
      "batch 1388: loss 0.1496584117412567\n",
      "batch 1389: loss 0.13657152652740479\n",
      "batch 1390: loss 0.11573179066181183\n",
      "batch 1391: loss 0.15996329486370087\n",
      "batch 1392: loss 0.08929673582315445\n",
      "batch 1393: loss 0.07952352613210678\n",
      "batch 1394: loss 0.17521846294403076\n",
      "batch 1395: loss 0.043410830199718475\n",
      "batch 1396: loss 0.08381298929452896\n",
      "batch 1397: loss 0.2330804020166397\n",
      "batch 1398: loss 0.18355457484722137\n",
      "batch 1399: loss 0.03366232290863991\n",
      "batch 1400: loss 0.17002034187316895\n",
      "batch 1401: loss 0.20646178722381592\n",
      "batch 1402: loss 0.236384317278862\n",
      "batch 1403: loss 0.08209563046693802\n",
      "batch 1404: loss 0.331326961517334\n",
      "batch 1405: loss 0.10458623617887497\n",
      "batch 1406: loss 0.10482032597064972\n",
      "batch 1407: loss 0.21232286095619202\n",
      "batch 1408: loss 0.11365246772766113\n",
      "batch 1409: loss 0.23098422586917877\n",
      "batch 1410: loss 0.10527195781469345\n",
      "batch 1411: loss 0.15760736167430878\n",
      "batch 1412: loss 0.10200154036283493\n",
      "batch 1413: loss 0.06410814076662064\n",
      "batch 1414: loss 0.13143396377563477\n",
      "batch 1415: loss 0.15146106481552124\n",
      "batch 1416: loss 0.20645403861999512\n",
      "batch 1417: loss 0.09897516667842865\n",
      "batch 1418: loss 0.6186814904212952\n",
      "batch 1419: loss 0.21349745988845825\n",
      "batch 1420: loss 0.12650424242019653\n",
      "batch 1421: loss 0.19248083233833313\n",
      "batch 1422: loss 0.1290293037891388\n",
      "batch 1423: loss 0.10350589454174042\n",
      "batch 1424: loss 0.08372610062360764\n",
      "batch 1425: loss 0.11920502036809921\n",
      "batch 1426: loss 0.0382520966231823\n",
      "batch 1427: loss 0.03298509865999222\n",
      "batch 1428: loss 0.08231537789106369\n",
      "batch 1429: loss 0.09316281974315643\n",
      "batch 1430: loss 0.25363996624946594\n",
      "batch 1431: loss 0.09938352555036545\n",
      "batch 1432: loss 0.15405897796154022\n",
      "batch 1433: loss 0.16075828671455383\n",
      "batch 1434: loss 0.06653522700071335\n",
      "batch 1435: loss 0.03204808756709099\n",
      "batch 1436: loss 0.15443958342075348\n",
      "batch 1437: loss 0.05854470282793045\n",
      "batch 1438: loss 0.15424272418022156\n",
      "batch 1439: loss 0.1327996850013733\n",
      "batch 1440: loss 0.25588661432266235\n",
      "batch 1441: loss 0.05111867934465408\n",
      "batch 1442: loss 0.23430001735687256\n",
      "batch 1443: loss 0.07478883862495422\n",
      "batch 1444: loss 0.1276766061782837\n",
      "batch 1445: loss 0.12657423317432404\n",
      "batch 1446: loss 0.20880720019340515\n",
      "batch 1447: loss 0.15963371098041534\n",
      "batch 1448: loss 0.07571350783109665\n",
      "batch 1449: loss 0.047512512654066086\n",
      "batch 1450: loss 0.1000099927186966\n",
      "batch 1451: loss 0.06778423488140106\n",
      "batch 1452: loss 0.23479747772216797\n",
      "batch 1453: loss 0.2195388525724411\n",
      "batch 1454: loss 0.21391800045967102\n",
      "batch 1455: loss 0.09523706138134003\n",
      "batch 1456: loss 0.02920309454202652\n",
      "batch 1457: loss 0.111702099442482\n",
      "batch 1458: loss 0.10639694333076477\n",
      "batch 1459: loss 0.3109181821346283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1460: loss 0.11250843107700348\n",
      "batch 1461: loss 0.1359679400920868\n",
      "batch 1462: loss 0.04147541522979736\n",
      "batch 1463: loss 0.12516947090625763\n",
      "batch 1464: loss 0.09203146398067474\n",
      "batch 1465: loss 0.272529274225235\n",
      "batch 1466: loss 0.22713160514831543\n",
      "batch 1467: loss 0.2667236626148224\n",
      "batch 1468: loss 0.09318993985652924\n",
      "batch 1469: loss 0.14418335258960724\n",
      "batch 1470: loss 0.2796647548675537\n",
      "batch 1471: loss 0.06107597053050995\n",
      "batch 1472: loss 0.11652668565511703\n",
      "batch 1473: loss 0.023209985345602036\n",
      "batch 1474: loss 0.11904828995466232\n",
      "batch 1475: loss 0.08330963551998138\n",
      "batch 1476: loss 0.18624398112297058\n",
      "batch 1477: loss 0.3559463322162628\n",
      "batch 1478: loss 0.10126855969429016\n",
      "batch 1479: loss 0.17819301784038544\n",
      "batch 1480: loss 0.11537052690982819\n",
      "batch 1481: loss 0.10705722868442535\n",
      "batch 1482: loss 0.26025301218032837\n",
      "batch 1483: loss 0.1603609174489975\n",
      "batch 1484: loss 0.12107696384191513\n",
      "batch 1485: loss 0.14630916714668274\n",
      "batch 1486: loss 0.13985595107078552\n",
      "batch 1487: loss 0.05948556587100029\n",
      "batch 1488: loss 0.054228056222200394\n",
      "batch 1489: loss 0.07817791402339935\n",
      "batch 1490: loss 0.3985103666782379\n",
      "batch 1491: loss 0.23254884779453278\n",
      "batch 1492: loss 0.1759943962097168\n",
      "batch 1493: loss 0.240192249417305\n",
      "batch 1494: loss 0.07129154354333878\n",
      "batch 1495: loss 0.09000232815742493\n",
      "batch 1496: loss 0.05842606723308563\n",
      "batch 1497: loss 0.10249768942594528\n",
      "batch 1498: loss 0.05349433422088623\n",
      "batch 1499: loss 0.2429034560918808\n",
      "batch 1500: loss 0.10278889536857605\n",
      "batch 1501: loss 0.09739610552787781\n",
      "batch 1502: loss 0.11772660911083221\n",
      "batch 1503: loss 0.04358787462115288\n",
      "batch 1504: loss 0.16575203835964203\n",
      "batch 1505: loss 0.17297622561454773\n",
      "batch 1506: loss 0.08368176966905594\n",
      "batch 1507: loss 0.08088302612304688\n",
      "batch 1508: loss 0.2581775188446045\n",
      "batch 1509: loss 0.22362470626831055\n",
      "batch 1510: loss 0.10807273536920547\n",
      "batch 1511: loss 0.07593008875846863\n",
      "batch 1512: loss 0.030753621831536293\n",
      "batch 1513: loss 0.120638407766819\n",
      "batch 1514: loss 0.09615687280893326\n",
      "batch 1515: loss 0.10211043059825897\n",
      "batch 1516: loss 0.23003901541233063\n",
      "batch 1517: loss 0.1651342362165451\n",
      "batch 1518: loss 0.10288549214601517\n",
      "batch 1519: loss 0.10477151721715927\n",
      "batch 1520: loss 0.15635688602924347\n",
      "batch 1521: loss 0.0865715742111206\n",
      "batch 1522: loss 0.024781353771686554\n",
      "batch 1523: loss 0.09234151989221573\n",
      "batch 1524: loss 0.1485193967819214\n",
      "batch 1525: loss 0.11521146446466446\n",
      "batch 1526: loss 0.11727917194366455\n",
      "batch 1527: loss 0.10011135041713715\n",
      "batch 1528: loss 0.2027614414691925\n",
      "batch 1529: loss 0.25149768590927124\n",
      "batch 1530: loss 0.11073756217956543\n",
      "batch 1531: loss 0.06549807637929916\n",
      "batch 1532: loss 0.07293775677680969\n",
      "batch 1533: loss 0.09083370119333267\n",
      "batch 1534: loss 0.050148606300354004\n",
      "batch 1535: loss 0.40493690967559814\n",
      "batch 1536: loss 0.09348657727241516\n",
      "batch 1537: loss 0.30630868673324585\n",
      "batch 1538: loss 0.21109488606452942\n",
      "batch 1539: loss 0.11610791832208633\n",
      "batch 1540: loss 0.046671099960803986\n",
      "batch 1541: loss 0.05590711161494255\n",
      "batch 1542: loss 0.09777923673391342\n",
      "batch 1543: loss 0.1597685068845749\n",
      "batch 1544: loss 0.07977709919214249\n",
      "batch 1545: loss 0.22223244607448578\n",
      "batch 1546: loss 0.23184186220169067\n",
      "batch 1547: loss 0.10116275399923325\n",
      "batch 1548: loss 0.07052933424711227\n",
      "batch 1549: loss 0.15542787313461304\n",
      "batch 1550: loss 0.04584413394331932\n",
      "batch 1551: loss 0.1051531732082367\n",
      "batch 1552: loss 0.0612325482070446\n",
      "batch 1553: loss 0.054625775665044785\n",
      "batch 1554: loss 0.0805063396692276\n",
      "batch 1555: loss 0.1375584453344345\n",
      "batch 1556: loss 0.17409001290798187\n",
      "batch 1557: loss 0.040368080139160156\n",
      "batch 1558: loss 0.13553370535373688\n",
      "batch 1559: loss 0.07999925315380096\n",
      "batch 1560: loss 0.05375043675303459\n",
      "batch 1561: loss 0.10789456963539124\n",
      "batch 1562: loss 0.06105423346161842\n",
      "batch 1563: loss 0.1966497004032135\n",
      "batch 1564: loss 0.1959245204925537\n",
      "batch 1565: loss 0.3686395287513733\n",
      "batch 1566: loss 0.1403917521238327\n",
      "batch 1567: loss 0.1306460052728653\n",
      "batch 1568: loss 0.09485650807619095\n",
      "batch 1569: loss 0.04236331209540367\n",
      "batch 1570: loss 0.07798106968402863\n",
      "batch 1571: loss 0.26602429151535034\n",
      "batch 1572: loss 0.25415563583374023\n",
      "batch 1573: loss 0.14871011674404144\n",
      "batch 1574: loss 0.1527225822210312\n",
      "batch 1575: loss 0.06860058009624481\n",
      "batch 1576: loss 0.04578141123056412\n",
      "batch 1577: loss 0.18757767975330353\n",
      "batch 1578: loss 0.11915837973356247\n",
      "batch 1579: loss 0.11574725061655045\n",
      "batch 1580: loss 0.1031009778380394\n",
      "batch 1581: loss 0.05847122147679329\n",
      "batch 1582: loss 0.13035550713539124\n",
      "batch 1583: loss 0.08132775872945786\n",
      "batch 1584: loss 0.13516224920749664\n",
      "batch 1585: loss 0.10644184052944183\n",
      "batch 1586: loss 0.23428618907928467\n",
      "batch 1587: loss 0.1478894054889679\n",
      "batch 1588: loss 0.10828700661659241\n",
      "batch 1589: loss 0.08865806460380554\n",
      "batch 1590: loss 0.1265985071659088\n",
      "batch 1591: loss 0.09311673045158386\n",
      "batch 1592: loss 0.16332241892814636\n",
      "batch 1593: loss 0.17314082384109497\n",
      "batch 1594: loss 0.13675560057163239\n",
      "batch 1595: loss 0.12932854890823364\n",
      "batch 1596: loss 0.21423019468784332\n",
      "batch 1597: loss 0.06808566302061081\n",
      "batch 1598: loss 0.05345511436462402\n",
      "batch 1599: loss 0.16454985737800598\n",
      "batch 1600: loss 0.13262352347373962\n",
      "batch 1601: loss 0.1076636090874672\n",
      "batch 1602: loss 0.21176709234714508\n",
      "batch 1603: loss 0.13102826476097107\n",
      "batch 1604: loss 0.13860288262367249\n",
      "batch 1605: loss 0.22666354477405548\n",
      "batch 1606: loss 0.15963546931743622\n",
      "batch 1607: loss 0.12405651807785034\n",
      "batch 1608: loss 0.28305765986442566\n",
      "batch 1609: loss 0.11778396368026733\n",
      "batch 1610: loss 0.15516869723796844\n",
      "batch 1611: loss 0.1585157811641693\n",
      "batch 1612: loss 0.08269135653972626\n",
      "batch 1613: loss 0.06612582504749298\n",
      "batch 1614: loss 0.250138521194458\n",
      "batch 1615: loss 0.12867972254753113\n",
      "batch 1616: loss 0.07018277794122696\n",
      "batch 1617: loss 0.18433822691440582\n",
      "batch 1618: loss 0.15739862620830536\n",
      "batch 1619: loss 0.2419382929801941\n",
      "batch 1620: loss 0.09759330749511719\n",
      "batch 1621: loss 0.2815397083759308\n",
      "batch 1622: loss 0.08825387805700302\n",
      "batch 1623: loss 0.21226736903190613\n",
      "batch 1624: loss 0.11104561388492584\n",
      "batch 1625: loss 0.25637221336364746\n",
      "batch 1626: loss 0.24059955775737762\n",
      "batch 1627: loss 0.1804327666759491\n",
      "batch 1628: loss 0.09952104091644287\n",
      "batch 1629: loss 0.10470112413167953\n",
      "batch 1630: loss 0.08714306354522705\n",
      "batch 1631: loss 0.06491748988628387\n",
      "batch 1632: loss 0.19655922055244446\n",
      "batch 1633: loss 0.10033056139945984\n",
      "batch 1634: loss 0.08773709088563919\n",
      "batch 1635: loss 0.22316323220729828\n",
      "batch 1636: loss 0.039444658905267715\n",
      "batch 1637: loss 0.17855054140090942\n",
      "batch 1638: loss 0.039484892040491104\n",
      "batch 1639: loss 0.0755656287074089\n",
      "batch 1640: loss 0.055428002029657364\n",
      "batch 1641: loss 0.16030700504779816\n",
      "batch 1642: loss 0.1719520539045334\n",
      "batch 1643: loss 0.06782352924346924\n",
      "batch 1644: loss 0.23590464890003204\n",
      "batch 1645: loss 0.22083112597465515\n",
      "batch 1646: loss 0.06030309945344925\n",
      "batch 1647: loss 0.10658598691225052\n",
      "batch 1648: loss 0.0942983627319336\n",
      "batch 1649: loss 0.17507025599479675\n",
      "batch 1650: loss 0.14530612528324127\n",
      "batch 1651: loss 0.048214178532361984\n",
      "batch 1652: loss 0.11214146018028259\n",
      "batch 1653: loss 0.1130305826663971\n",
      "batch 1654: loss 0.19372469186782837\n",
      "batch 1655: loss 0.21632204949855804\n",
      "batch 1656: loss 0.12492283433675766\n",
      "batch 1657: loss 0.17357569932937622\n",
      "batch 1658: loss 0.08942209184169769\n",
      "batch 1659: loss 0.17822353541851044\n",
      "batch 1660: loss 0.2596844434738159\n",
      "batch 1661: loss 0.06642334908246994\n",
      "batch 1662: loss 0.16085338592529297\n",
      "batch 1663: loss 0.17972129583358765\n",
      "batch 1664: loss 0.2017252892255783\n",
      "batch 1665: loss 0.1232059895992279\n",
      "batch 1666: loss 0.17817729711532593\n",
      "batch 1667: loss 0.16032494604587555\n",
      "batch 1668: loss 0.09595390409231186\n",
      "batch 1669: loss 0.23564216494560242\n",
      "batch 1670: loss 0.3685363233089447\n",
      "batch 1671: loss 0.21443618834018707\n",
      "batch 1672: loss 0.1322481781244278\n",
      "batch 1673: loss 0.055650170892477036\n",
      "batch 1674: loss 0.13147377967834473\n",
      "batch 1675: loss 0.12547731399536133\n",
      "batch 1676: loss 0.03862448036670685\n",
      "batch 1677: loss 0.11184760928153992\n",
      "batch 1678: loss 0.08520307391881943\n",
      "batch 1679: loss 0.060934584587812424\n",
      "batch 1680: loss 0.047491542994976044\n",
      "batch 1681: loss 0.21268603205680847\n",
      "batch 1682: loss 0.2057655155658722\n",
      "batch 1683: loss 0.13494227826595306\n",
      "batch 1684: loss 0.10447463393211365\n",
      "batch 1685: loss 0.09480014443397522\n",
      "batch 1686: loss 0.11352052539587021\n",
      "batch 1687: loss 0.161015123128891\n",
      "batch 1688: loss 0.09119872748851776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1689: loss 0.24453970789909363\n",
      "batch 1690: loss 0.061763275414705276\n",
      "batch 1691: loss 0.1402856558561325\n",
      "batch 1692: loss 0.12473845481872559\n",
      "batch 1693: loss 0.1123683974146843\n",
      "batch 1694: loss 0.06556466221809387\n",
      "batch 1695: loss 0.03398787975311279\n",
      "batch 1696: loss 0.07374604791402817\n",
      "batch 1697: loss 0.19704818725585938\n",
      "batch 1698: loss 0.06719808280467987\n",
      "batch 1699: loss 0.23389673233032227\n",
      "batch 1700: loss 0.1316869556903839\n",
      "batch 1701: loss 0.13301661610603333\n",
      "batch 1702: loss 0.10859702527523041\n",
      "batch 1703: loss 0.12210693210363388\n",
      "batch 1704: loss 0.09010181576013565\n",
      "batch 1705: loss 0.18248602747917175\n",
      "batch 1706: loss 0.10198447108268738\n",
      "batch 1707: loss 0.15067318081855774\n",
      "batch 1708: loss 0.19065529108047485\n",
      "batch 1709: loss 0.14493770897388458\n",
      "batch 1710: loss 0.06850707530975342\n",
      "batch 1711: loss 0.14341071248054504\n",
      "batch 1712: loss 0.11175914853811264\n",
      "batch 1713: loss 0.2506709098815918\n",
      "batch 1714: loss 0.285860538482666\n",
      "batch 1715: loss 0.16459758579730988\n",
      "batch 1716: loss 0.057338934391736984\n",
      "batch 1717: loss 0.05840851739048958\n",
      "batch 1718: loss 0.1258624643087387\n",
      "batch 1719: loss 0.03952834755182266\n",
      "batch 1720: loss 0.054537586867809296\n",
      "batch 1721: loss 0.1267203837633133\n",
      "batch 1722: loss 0.055231064558029175\n",
      "batch 1723: loss 0.10068921744823456\n",
      "batch 1724: loss 0.20498402416706085\n",
      "batch 1725: loss 0.05544302985072136\n",
      "batch 1726: loss 0.12754902243614197\n",
      "batch 1727: loss 0.04996250942349434\n",
      "batch 1728: loss 0.015160121954977512\n",
      "batch 1729: loss 0.04701749607920647\n",
      "batch 1730: loss 0.11202745884656906\n",
      "batch 1731: loss 0.26020699739456177\n",
      "batch 1732: loss 0.12023273855447769\n",
      "batch 1733: loss 0.0780031755566597\n",
      "batch 1734: loss 0.14016318321228027\n",
      "batch 1735: loss 0.2897425591945648\n",
      "batch 1736: loss 0.1956753134727478\n",
      "batch 1737: loss 0.07683433592319489\n",
      "batch 1738: loss 0.13537578284740448\n",
      "batch 1739: loss 0.08371204882860184\n",
      "batch 1740: loss 0.15772800147533417\n",
      "batch 1741: loss 0.13733217120170593\n",
      "batch 1742: loss 0.10081716626882553\n",
      "batch 1743: loss 0.05152793601155281\n",
      "batch 1744: loss 0.17108316719532013\n",
      "batch 1745: loss 0.058276500552892685\n",
      "batch 1746: loss 0.07752132415771484\n",
      "batch 1747: loss 0.07129883021116257\n",
      "batch 1748: loss 0.06368566304445267\n",
      "batch 1749: loss 0.10304064303636551\n",
      "batch 1750: loss 0.20261424779891968\n",
      "batch 1751: loss 0.12765023112297058\n",
      "batch 1752: loss 0.1807771623134613\n",
      "batch 1753: loss 0.05465339124202728\n",
      "batch 1754: loss 0.32769355177879333\n",
      "batch 1755: loss 0.039678268134593964\n",
      "batch 1756: loss 0.32780811190605164\n",
      "batch 1757: loss 0.13730525970458984\n",
      "batch 1758: loss 0.05511865019798279\n",
      "batch 1759: loss 0.1532026082277298\n",
      "batch 1760: loss 0.16028687357902527\n",
      "batch 1761: loss 0.08790458738803864\n",
      "batch 1762: loss 0.05929996818304062\n",
      "batch 1763: loss 0.12554100155830383\n",
      "batch 1764: loss 0.06355613470077515\n",
      "batch 1765: loss 0.06361763179302216\n",
      "batch 1766: loss 0.10538463294506073\n",
      "batch 1767: loss 0.16597849130630493\n",
      "batch 1768: loss 0.23357203602790833\n",
      "batch 1769: loss 0.0490303710103035\n",
      "batch 1770: loss 0.12705910205841064\n",
      "batch 1771: loss 0.08425822108983994\n",
      "batch 1772: loss 0.11117840558290482\n",
      "batch 1773: loss 0.1324581354856491\n",
      "batch 1774: loss 0.1328326314687729\n",
      "batch 1775: loss 0.09142521768808365\n",
      "batch 1776: loss 0.0538153350353241\n",
      "batch 1777: loss 0.13470996916294098\n",
      "batch 1778: loss 0.047859009355306625\n",
      "batch 1779: loss 0.16176298260688782\n",
      "batch 1780: loss 0.10937321186065674\n",
      "batch 1781: loss 0.13968776166439056\n",
      "batch 1782: loss 0.08051686733961105\n",
      "batch 1783: loss 0.11604388058185577\n",
      "batch 1784: loss 0.06307917088270187\n",
      "batch 1785: loss 0.15050649642944336\n",
      "batch 1786: loss 0.0917484387755394\n",
      "batch 1787: loss 0.11366559565067291\n",
      "batch 1788: loss 0.05010988190770149\n",
      "batch 1789: loss 0.09840124845504761\n",
      "batch 1790: loss 0.08003248274326324\n",
      "batch 1791: loss 0.21076546609401703\n",
      "batch 1792: loss 0.11148886382579803\n",
      "batch 1793: loss 0.06571103632450104\n",
      "batch 1794: loss 0.11651867628097534\n",
      "batch 1795: loss 0.05618107691407204\n",
      "batch 1796: loss 0.05430787056684494\n",
      "batch 1797: loss 0.1261732280254364\n",
      "batch 1798: loss 0.13399069011211395\n",
      "batch 1799: loss 0.09040868282318115\n",
      "batch 1800: loss 0.04378480836749077\n",
      "batch 1801: loss 0.2149825096130371\n",
      "batch 1802: loss 0.356759250164032\n",
      "batch 1803: loss 0.10871810466051102\n",
      "batch 1804: loss 0.1449669599533081\n",
      "batch 1805: loss 0.20711001753807068\n",
      "batch 1806: loss 0.3560357093811035\n",
      "batch 1807: loss 0.11007852107286453\n",
      "batch 1808: loss 0.07958890497684479\n",
      "batch 1809: loss 0.06828689575195312\n",
      "batch 1810: loss 0.14144492149353027\n",
      "batch 1811: loss 0.09736045449972153\n",
      "batch 1812: loss 0.059867601841688156\n",
      "batch 1813: loss 0.20596759021282196\n",
      "batch 1814: loss 0.08919307589530945\n",
      "batch 1815: loss 0.1925920695066452\n",
      "batch 1816: loss 0.2785865366458893\n",
      "batch 1817: loss 0.0833345428109169\n",
      "batch 1818: loss 0.08995932340621948\n",
      "batch 1819: loss 0.09667472541332245\n",
      "batch 1820: loss 0.10423759371042252\n",
      "batch 1821: loss 0.10436160862445831\n",
      "batch 1822: loss 0.2659456133842468\n",
      "batch 1823: loss 0.06435717642307281\n",
      "batch 1824: loss 0.037882279604673386\n",
      "batch 1825: loss 0.10629647225141525\n",
      "batch 1826: loss 0.23311276733875275\n",
      "batch 1827: loss 0.11086318641901016\n",
      "batch 1828: loss 0.23497605323791504\n",
      "batch 1829: loss 0.08066243678331375\n",
      "batch 1830: loss 0.042940665036439896\n",
      "batch 1831: loss 0.13750618696212769\n",
      "batch 1832: loss 0.09389325976371765\n",
      "batch 1833: loss 0.10159913450479507\n",
      "batch 1834: loss 0.05899081006646156\n",
      "batch 1835: loss 0.09450801461935043\n",
      "batch 1836: loss 0.08092731237411499\n",
      "batch 1837: loss 0.0357455350458622\n",
      "batch 1838: loss 0.06423816084861755\n",
      "batch 1839: loss 0.08136652410030365\n",
      "batch 1840: loss 0.07916484773159027\n",
      "batch 1841: loss 0.19002383947372437\n",
      "batch 1842: loss 0.033924400806427\n",
      "batch 1843: loss 0.0929282084107399\n",
      "batch 1844: loss 0.10729728639125824\n",
      "batch 1845: loss 0.07884703576564789\n",
      "batch 1846: loss 0.1217246726155281\n",
      "batch 1847: loss 0.24202144145965576\n",
      "batch 1848: loss 0.09639781713485718\n",
      "batch 1849: loss 0.11720188707113266\n",
      "batch 1850: loss 0.019558917731046677\n",
      "batch 1851: loss 0.06307729333639145\n",
      "batch 1852: loss 0.07560539245605469\n",
      "batch 1853: loss 0.12519106268882751\n",
      "batch 1854: loss 0.11009248346090317\n",
      "batch 1855: loss 0.12855730950832367\n",
      "batch 1856: loss 0.045179784297943115\n",
      "batch 1857: loss 0.03250708058476448\n",
      "batch 1858: loss 0.19603551924228668\n",
      "batch 1859: loss 0.06626538187265396\n",
      "batch 1860: loss 0.08123674988746643\n",
      "batch 1861: loss 0.12346801161766052\n",
      "batch 1862: loss 0.08371078968048096\n",
      "batch 1863: loss 0.10684338957071304\n",
      "batch 1864: loss 0.17340484261512756\n",
      "batch 1865: loss 0.14584040641784668\n",
      "batch 1866: loss 0.09828893095254898\n",
      "batch 1867: loss 0.17999966442584991\n",
      "batch 1868: loss 0.033152345567941666\n",
      "batch 1869: loss 0.1811435967683792\n",
      "batch 1870: loss 0.0649731308221817\n",
      "batch 1871: loss 0.060000237077474594\n",
      "batch 1872: loss 0.08200441300868988\n",
      "batch 1873: loss 0.26829391717910767\n",
      "batch 1874: loss 0.05603789538145065\n",
      "batch 1875: loss 0.10506977885961533\n",
      "batch 1876: loss 0.1281053125858307\n",
      "batch 1877: loss 0.09320584684610367\n",
      "batch 1878: loss 0.14417384564876556\n",
      "batch 1879: loss 0.068145252764225\n",
      "batch 1880: loss 0.12151225656270981\n",
      "batch 1881: loss 0.27844706177711487\n",
      "batch 1882: loss 0.11097820848226547\n",
      "batch 1883: loss 0.07427312433719635\n",
      "batch 1884: loss 0.17045465111732483\n",
      "batch 1885: loss 0.1411588490009308\n",
      "batch 1886: loss 0.09217368066310883\n",
      "batch 1887: loss 0.09094058722257614\n",
      "batch 1888: loss 0.028540868312120438\n",
      "batch 1889: loss 0.09798800945281982\n",
      "batch 1890: loss 0.15354709327220917\n",
      "batch 1891: loss 0.0336453914642334\n",
      "batch 1892: loss 0.1574322134256363\n",
      "batch 1893: loss 0.07866008579730988\n",
      "batch 1894: loss 0.030539045110344887\n",
      "batch 1895: loss 0.09072045981884003\n",
      "batch 1896: loss 0.19386346638202667\n",
      "batch 1897: loss 0.0788402259349823\n",
      "batch 1898: loss 0.16436217725276947\n",
      "batch 1899: loss 0.40060046315193176\n",
      "batch 1900: loss 0.033207278698682785\n",
      "batch 1901: loss 0.02409971132874489\n",
      "batch 1902: loss 0.12775665521621704\n",
      "batch 1903: loss 0.07504546642303467\n",
      "batch 1904: loss 0.09779971092939377\n",
      "batch 1905: loss 0.36816370487213135\n",
      "batch 1906: loss 0.07352302223443985\n",
      "batch 1907: loss 0.3082834780216217\n",
      "batch 1908: loss 0.18938204646110535\n",
      "batch 1909: loss 0.10424571484327316\n",
      "batch 1910: loss 0.16180893778800964\n",
      "batch 1911: loss 0.033686839044094086\n",
      "batch 1912: loss 0.07679612934589386\n",
      "batch 1913: loss 0.23636485636234283\n",
      "batch 1914: loss 0.13783396780490875\n",
      "batch 1915: loss 0.5455418825149536\n",
      "batch 1916: loss 0.08729694038629532\n",
      "batch 1917: loss 0.19586852192878723\n",
      "batch 1918: loss 0.2112162560224533\n",
      "batch 1919: loss 0.10879453271627426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1920: loss 0.17183120548725128\n",
      "batch 1921: loss 0.1681501418352127\n",
      "batch 1922: loss 0.05663676559925079\n",
      "batch 1923: loss 0.16035594046115875\n",
      "batch 1924: loss 0.4885237514972687\n",
      "batch 1925: loss 0.12990112602710724\n",
      "batch 1926: loss 0.13258342444896698\n",
      "batch 1927: loss 0.04881872236728668\n",
      "batch 1928: loss 0.0792296752333641\n",
      "batch 1929: loss 0.07158064842224121\n",
      "batch 1930: loss 0.1058226004242897\n",
      "batch 1931: loss 0.07096090912818909\n",
      "batch 1932: loss 0.09959586709737778\n",
      "batch 1933: loss 0.08520162105560303\n",
      "batch 1934: loss 0.1902616024017334\n",
      "batch 1935: loss 0.16445808112621307\n",
      "batch 1936: loss 0.08739226311445236\n",
      "batch 1937: loss 0.09865913540124893\n",
      "batch 1938: loss 0.0482109934091568\n",
      "batch 1939: loss 0.06018314138054848\n",
      "batch 1940: loss 0.17738638818264008\n",
      "batch 1941: loss 0.09836657345294952\n",
      "batch 1942: loss 0.09307960420846939\n",
      "batch 1943: loss 0.29306092858314514\n",
      "batch 1944: loss 0.11887255311012268\n",
      "batch 1945: loss 0.13067787885665894\n",
      "batch 1946: loss 0.03833404555916786\n",
      "batch 1947: loss 0.08521199226379395\n",
      "batch 1948: loss 0.07093129307031631\n",
      "batch 1949: loss 0.041536346077919006\n",
      "batch 1950: loss 0.08830166608095169\n",
      "batch 1951: loss 0.1417454034090042\n",
      "batch 1952: loss 0.057791970670223236\n",
      "batch 1953: loss 0.02632129192352295\n",
      "batch 1954: loss 0.17573855817317963\n",
      "batch 1955: loss 0.07989601790904999\n",
      "batch 1956: loss 0.09364563971757889\n",
      "batch 1957: loss 0.18396270275115967\n",
      "batch 1958: loss 0.12570054829120636\n",
      "batch 1959: loss 0.15521034598350525\n",
      "batch 1960: loss 0.17959536612033844\n",
      "batch 1961: loss 0.1256708949804306\n",
      "batch 1962: loss 0.12957358360290527\n",
      "batch 1963: loss 0.043876223266124725\n",
      "batch 1964: loss 0.14857640862464905\n",
      "batch 1965: loss 0.14736096560955048\n",
      "batch 1966: loss 0.1180364266037941\n",
      "batch 1967: loss 0.07523353397846222\n",
      "batch 1968: loss 0.08644149452447891\n",
      "batch 1969: loss 0.06898533552885056\n",
      "batch 1970: loss 0.0688927173614502\n",
      "batch 1971: loss 0.20222489535808563\n",
      "batch 1972: loss 0.06996604800224304\n",
      "batch 1973: loss 0.08962047100067139\n",
      "batch 1974: loss 0.12577465176582336\n",
      "batch 1975: loss 0.23079651594161987\n",
      "batch 1976: loss 0.12030679732561111\n",
      "batch 1977: loss 0.06540998071432114\n",
      "batch 1978: loss 0.019846782088279724\n",
      "batch 1979: loss 0.08870463818311691\n",
      "batch 1980: loss 0.04376732558012009\n",
      "batch 1981: loss 0.16549205780029297\n",
      "batch 1982: loss 0.0851283147931099\n",
      "batch 1983: loss 0.03982514142990112\n",
      "batch 1984: loss 0.11538732051849365\n",
      "batch 1985: loss 0.14204712212085724\n",
      "batch 1986: loss 0.06856659799814224\n",
      "batch 1987: loss 0.19396083056926727\n",
      "batch 1988: loss 0.11963239312171936\n",
      "batch 1989: loss 0.04154195636510849\n",
      "batch 1990: loss 0.05796276777982712\n",
      "batch 1991: loss 0.21425873041152954\n",
      "batch 1992: loss 0.2080131322145462\n",
      "batch 1993: loss 0.057185880839824677\n",
      "batch 1994: loss 0.07616643607616425\n",
      "batch 1995: loss 0.10062436759471893\n",
      "batch 1996: loss 0.15945319831371307\n",
      "batch 1997: loss 0.11904817074537277\n",
      "batch 1998: loss 0.07737299054861069\n",
      "batch 1999: loss 0.16881732642650604\n",
      "batch 2000: loss 0.08536075055599213\n",
      "batch 2001: loss 0.26778435707092285\n",
      "batch 2002: loss 0.17535926401615143\n",
      "batch 2003: loss 0.15414603054523468\n",
      "batch 2004: loss 0.03139374777674675\n",
      "batch 2005: loss 0.16523043811321259\n",
      "batch 2006: loss 0.30071333050727844\n",
      "batch 2007: loss 0.08108789473772049\n",
      "batch 2008: loss 0.20365674793720245\n",
      "batch 2009: loss 0.11816203594207764\n",
      "batch 2010: loss 0.09610298275947571\n",
      "batch 2011: loss 0.1852921098470688\n",
      "batch 2012: loss 0.08389431983232498\n",
      "batch 2013: loss 0.04964844509959221\n",
      "batch 2014: loss 0.0972202941775322\n",
      "batch 2015: loss 0.10408903658390045\n",
      "batch 2016: loss 0.12736624479293823\n",
      "batch 2017: loss 0.08746421337127686\n",
      "batch 2018: loss 0.046966247260570526\n",
      "batch 2019: loss 0.06736082583665848\n",
      "batch 2020: loss 0.17158222198486328\n",
      "batch 2021: loss 0.12627705931663513\n",
      "batch 2022: loss 0.08086277544498444\n",
      "batch 2023: loss 0.04794444143772125\n",
      "batch 2024: loss 0.14662663638591766\n",
      "batch 2025: loss 0.06937602907419205\n",
      "batch 2026: loss 0.13866570591926575\n",
      "batch 2027: loss 0.12412582337856293\n",
      "batch 2028: loss 0.07204046845436096\n",
      "batch 2029: loss 0.08954498916864395\n",
      "batch 2030: loss 0.028618378564715385\n",
      "batch 2031: loss 0.2046736478805542\n",
      "batch 2032: loss 0.3174053430557251\n",
      "batch 2033: loss 0.10271631181240082\n",
      "batch 2034: loss 0.21016962826251984\n",
      "batch 2035: loss 0.09473409503698349\n",
      "batch 2036: loss 0.042523372918367386\n",
      "batch 2037: loss 0.09018528461456299\n",
      "batch 2038: loss 0.2106642872095108\n",
      "batch 2039: loss 0.02743176929652691\n",
      "batch 2040: loss 0.1073049008846283\n",
      "batch 2041: loss 0.10361562669277191\n",
      "batch 2042: loss 0.13315024971961975\n",
      "batch 2043: loss 0.06255340576171875\n",
      "batch 2044: loss 0.06590807437896729\n",
      "batch 2045: loss 0.0814274474978447\n",
      "batch 2046: loss 0.1403016448020935\n",
      "batch 2047: loss 0.21111880242824554\n",
      "batch 2048: loss 0.11107584089040756\n",
      "batch 2049: loss 0.0861857607960701\n",
      "batch 2050: loss 0.24799934029579163\n",
      "batch 2051: loss 0.2478179931640625\n",
      "batch 2052: loss 0.09721488505601883\n",
      "batch 2053: loss 0.046095505356788635\n",
      "batch 2054: loss 0.12552092969417572\n",
      "batch 2055: loss 0.22908450663089752\n",
      "batch 2056: loss 0.17513488233089447\n",
      "batch 2057: loss 0.21677497029304504\n",
      "batch 2058: loss 0.07156562060117722\n",
      "batch 2059: loss 0.1666889786720276\n",
      "batch 2060: loss 0.1281147003173828\n",
      "batch 2061: loss 0.13691788911819458\n",
      "batch 2062: loss 0.04042033106088638\n",
      "batch 2063: loss 0.047095756977796555\n",
      "batch 2064: loss 0.07530853152275085\n",
      "batch 2065: loss 0.19169779121875763\n",
      "batch 2066: loss 0.18792873620986938\n",
      "batch 2067: loss 0.0697210282087326\n",
      "batch 2068: loss 0.19748006761074066\n",
      "batch 2069: loss 0.26214393973350525\n",
      "batch 2070: loss 0.15671883523464203\n",
      "batch 2071: loss 0.08708865940570831\n",
      "batch 2072: loss 0.17149297893047333\n",
      "batch 2073: loss 0.031034082174301147\n",
      "batch 2074: loss 0.09283134341239929\n",
      "batch 2075: loss 0.04343222454190254\n",
      "batch 2076: loss 0.2343965619802475\n",
      "batch 2077: loss 0.10765841603279114\n",
      "batch 2078: loss 0.21679571270942688\n",
      "batch 2079: loss 0.15236788988113403\n",
      "batch 2080: loss 0.03332555294036865\n",
      "batch 2081: loss 0.11733702570199966\n",
      "batch 2082: loss 0.11000385135412216\n",
      "batch 2083: loss 0.03446071967482567\n",
      "batch 2084: loss 0.07431253045797348\n",
      "batch 2085: loss 0.10802793502807617\n",
      "batch 2086: loss 0.17971067130565643\n",
      "batch 2087: loss 0.3126102685928345\n",
      "batch 2088: loss 0.04318711534142494\n",
      "batch 2089: loss 0.07841221988201141\n",
      "batch 2090: loss 0.1589667797088623\n",
      "batch 2091: loss 0.22283166646957397\n",
      "batch 2092: loss 0.10611554980278015\n",
      "batch 2093: loss 0.0637018233537674\n",
      "batch 2094: loss 0.09875452518463135\n",
      "batch 2095: loss 0.1223958283662796\n",
      "batch 2096: loss 0.1979924589395523\n",
      "batch 2097: loss 0.25694671273231506\n",
      "batch 2098: loss 0.08801621198654175\n",
      "batch 2099: loss 0.05969124659895897\n",
      "batch 2100: loss 0.11493673920631409\n",
      "batch 2101: loss 0.03873639181256294\n",
      "batch 2102: loss 0.09444213658571243\n",
      "batch 2103: loss 0.05349387973546982\n",
      "batch 2104: loss 0.05483781546354294\n",
      "batch 2105: loss 0.036118242889642715\n",
      "batch 2106: loss 0.1704351007938385\n",
      "batch 2107: loss 0.04540906473994255\n",
      "batch 2108: loss 0.10013086348772049\n",
      "batch 2109: loss 0.15950939059257507\n",
      "batch 2110: loss 0.0947028324007988\n",
      "batch 2111: loss 0.19599051773548126\n",
      "batch 2112: loss 0.0792788714170456\n",
      "batch 2113: loss 0.1255997270345688\n",
      "batch 2114: loss 0.02820872701704502\n",
      "batch 2115: loss 0.19932246208190918\n",
      "batch 2116: loss 0.3421166241168976\n",
      "batch 2117: loss 0.05298590660095215\n",
      "batch 2118: loss 0.05230114981532097\n",
      "batch 2119: loss 0.0402086041867733\n",
      "batch 2120: loss 0.12089547514915466\n",
      "batch 2121: loss 0.19553028047084808\n",
      "batch 2122: loss 0.14034239947795868\n",
      "batch 2123: loss 0.05305393412709236\n",
      "batch 2124: loss 0.10724345594644547\n",
      "batch 2125: loss 0.06940100342035294\n",
      "batch 2126: loss 0.1816459596157074\n",
      "batch 2127: loss 0.10529045015573502\n",
      "batch 2128: loss 0.12022046744823456\n",
      "batch 2129: loss 0.015664303675293922\n",
      "batch 2130: loss 0.1939280778169632\n",
      "batch 2131: loss 0.26429426670074463\n",
      "batch 2132: loss 0.07621133327484131\n",
      "batch 2133: loss 0.0906917080283165\n",
      "batch 2134: loss 0.07205227017402649\n",
      "batch 2135: loss 0.24551188945770264\n",
      "batch 2136: loss 0.1789916604757309\n",
      "batch 2137: loss 0.019668573513627052\n",
      "batch 2138: loss 0.30620700120925903\n",
      "batch 2139: loss 0.060286615043878555\n",
      "batch 2140: loss 0.17762941122055054\n",
      "batch 2141: loss 0.23523937165737152\n",
      "batch 2142: loss 0.14027829468250275\n",
      "batch 2143: loss 0.2761768102645874\n",
      "batch 2144: loss 0.03869722783565521\n",
      "batch 2145: loss 0.1070760190486908\n",
      "batch 2146: loss 0.05440082401037216\n",
      "batch 2147: loss 0.15613868832588196\n",
      "batch 2148: loss 0.15672904253005981\n",
      "batch 2149: loss 0.1801195740699768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2150: loss 0.08695849031209946\n",
      "batch 2151: loss 0.048726387321949005\n",
      "batch 2152: loss 0.04051174223423004\n",
      "batch 2153: loss 0.22520889341831207\n",
      "batch 2154: loss 0.16388240456581116\n",
      "batch 2155: loss 0.209634929895401\n",
      "batch 2156: loss 0.16753898561000824\n",
      "batch 2157: loss 0.1888800412416458\n",
      "batch 2158: loss 0.01915547251701355\n",
      "batch 2159: loss 0.04040980339050293\n",
      "batch 2160: loss 0.1477951556444168\n",
      "batch 2161: loss 0.12125752866268158\n",
      "batch 2162: loss 0.16309751570224762\n",
      "batch 2163: loss 0.2761151194572449\n",
      "batch 2164: loss 0.2464291751384735\n",
      "batch 2165: loss 0.05743597820401192\n",
      "batch 2166: loss 0.04847937449812889\n",
      "batch 2167: loss 0.10369004309177399\n",
      "batch 2168: loss 0.0452052503824234\n",
      "batch 2169: loss 0.06158633530139923\n",
      "batch 2170: loss 0.06989964097738266\n",
      "batch 2171: loss 0.09505008161067963\n",
      "batch 2172: loss 0.10088613629341125\n",
      "batch 2173: loss 0.1709192991256714\n",
      "batch 2174: loss 0.2089129239320755\n",
      "batch 2175: loss 0.08643023669719696\n",
      "batch 2176: loss 0.06460429728031158\n",
      "batch 2177: loss 0.14223213493824005\n",
      "batch 2178: loss 0.11588367819786072\n",
      "batch 2179: loss 0.07027857005596161\n",
      "batch 2180: loss 0.11572685092687607\n",
      "batch 2181: loss 0.07285408675670624\n",
      "batch 2182: loss 0.1392945796251297\n",
      "batch 2183: loss 0.30714693665504456\n",
      "batch 2184: loss 0.10830926895141602\n",
      "batch 2185: loss 0.18962955474853516\n",
      "batch 2186: loss 0.0724237933754921\n",
      "batch 2187: loss 0.23917870223522186\n",
      "batch 2188: loss 0.07870152592658997\n",
      "batch 2189: loss 0.054377663880586624\n",
      "batch 2190: loss 0.03621961176395416\n",
      "batch 2191: loss 0.10359811782836914\n",
      "batch 2192: loss 0.04951733350753784\n",
      "batch 2193: loss 0.2762565016746521\n",
      "batch 2194: loss 0.09451189637184143\n",
      "batch 2195: loss 0.11925861239433289\n",
      "batch 2196: loss 0.13161884248256683\n",
      "batch 2197: loss 0.12675806879997253\n",
      "batch 2198: loss 0.04574095085263252\n",
      "batch 2199: loss 0.0669248029589653\n",
      "batch 2200: loss 0.326086163520813\n",
      "batch 2201: loss 0.12256308645009995\n",
      "batch 2202: loss 0.032646872103214264\n",
      "batch 2203: loss 0.03507760539650917\n",
      "batch 2204: loss 0.08271953463554382\n",
      "batch 2205: loss 0.08832389861345291\n",
      "batch 2206: loss 0.08613288402557373\n",
      "batch 2207: loss 0.031910061836242676\n",
      "batch 2208: loss 0.09350846707820892\n",
      "batch 2209: loss 0.05836731940507889\n",
      "batch 2210: loss 0.09667352586984634\n",
      "batch 2211: loss 0.09234563261270523\n",
      "batch 2212: loss 0.1109575405716896\n",
      "batch 2213: loss 0.2731420397758484\n",
      "batch 2214: loss 0.09543609619140625\n",
      "batch 2215: loss 0.12292289733886719\n",
      "batch 2216: loss 0.14567674696445465\n",
      "batch 2217: loss 0.048511724919080734\n",
      "batch 2218: loss 0.03190638870000839\n",
      "batch 2219: loss 0.040092647075653076\n",
      "batch 2220: loss 0.255121648311615\n",
      "batch 2221: loss 0.055998533964157104\n",
      "batch 2222: loss 0.16878314316272736\n",
      "batch 2223: loss 0.21293513476848602\n",
      "batch 2224: loss 0.0978739783167839\n",
      "batch 2225: loss 0.1555517315864563\n",
      "batch 2226: loss 0.06683031469583511\n",
      "batch 2227: loss 0.07841887325048447\n",
      "batch 2228: loss 0.03295440599322319\n",
      "batch 2229: loss 0.06959635764360428\n",
      "batch 2230: loss 0.15542644262313843\n",
      "batch 2231: loss 0.2062433511018753\n",
      "batch 2232: loss 0.16348206996917725\n",
      "batch 2233: loss 0.03950415179133415\n",
      "batch 2234: loss 0.08171037584543228\n",
      "batch 2235: loss 0.031914256513118744\n",
      "batch 2236: loss 0.04367189481854439\n",
      "batch 2237: loss 0.03757520765066147\n",
      "batch 2238: loss 0.038020968437194824\n",
      "batch 2239: loss 0.2994539439678192\n",
      "batch 2240: loss 0.13436225056648254\n",
      "batch 2241: loss 0.038975875824689865\n",
      "batch 2242: loss 0.022132372483611107\n",
      "batch 2243: loss 0.306302934885025\n",
      "batch 2244: loss 0.06104981154203415\n",
      "batch 2245: loss 0.07485496997833252\n",
      "batch 2246: loss 0.07592224329710007\n",
      "batch 2247: loss 0.0724635124206543\n",
      "batch 2248: loss 0.1738118678331375\n",
      "batch 2249: loss 0.14126569032669067\n",
      "batch 2250: loss 0.03789087384939194\n",
      "batch 2251: loss 0.04976580664515495\n",
      "batch 2252: loss 0.06292075663805008\n",
      "batch 2253: loss 0.18689048290252686\n",
      "batch 2254: loss 0.10210991650819778\n",
      "batch 2255: loss 0.07755260914564133\n",
      "batch 2256: loss 0.13742537796497345\n",
      "batch 2257: loss 0.08679255098104477\n",
      "batch 2258: loss 0.023362765088677406\n",
      "batch 2259: loss 0.2195894718170166\n",
      "batch 2260: loss 0.05504560470581055\n",
      "batch 2261: loss 0.24345119297504425\n",
      "batch 2262: loss 0.17417770624160767\n",
      "batch 2263: loss 0.05908985808491707\n",
      "batch 2264: loss 0.10501284152269363\n",
      "batch 2265: loss 0.038945265114307404\n",
      "batch 2266: loss 0.14217253029346466\n",
      "batch 2267: loss 0.2069910317659378\n",
      "batch 2268: loss 0.13699939846992493\n",
      "batch 2269: loss 0.10340739041566849\n",
      "batch 2270: loss 0.09910707175731659\n",
      "batch 2271: loss 0.1339152604341507\n",
      "batch 2272: loss 0.10815200209617615\n",
      "batch 2273: loss 0.15669383108615875\n",
      "batch 2274: loss 0.04395265504717827\n",
      "batch 2275: loss 0.17405959963798523\n",
      "batch 2276: loss 0.13066239655017853\n",
      "batch 2277: loss 0.09414196759462357\n",
      "batch 2278: loss 0.030431365594267845\n",
      "batch 2279: loss 0.0798400416970253\n",
      "batch 2280: loss 0.06548666954040527\n",
      "batch 2281: loss 0.14330245554447174\n",
      "batch 2282: loss 0.04882045090198517\n",
      "batch 2283: loss 0.15504536032676697\n",
      "batch 2284: loss 0.36704981327056885\n",
      "batch 2285: loss 0.10984872281551361\n",
      "batch 2286: loss 0.13359178602695465\n",
      "batch 2287: loss 0.12410753220319748\n",
      "batch 2288: loss 0.059711914509534836\n",
      "batch 2289: loss 0.07455854117870331\n",
      "batch 2290: loss 0.03147326037287712\n",
      "batch 2291: loss 0.060938119888305664\n",
      "batch 2292: loss 0.04617265984416008\n",
      "batch 2293: loss 0.19189435243606567\n",
      "batch 2294: loss 0.08497059345245361\n",
      "batch 2295: loss 0.07126940786838531\n",
      "batch 2296: loss 0.08819026499986649\n",
      "batch 2297: loss 0.06474997103214264\n",
      "batch 2298: loss 0.12995147705078125\n",
      "batch 2299: loss 0.042331304401159286\n",
      "batch 2300: loss 0.16291444003582\n",
      "batch 2301: loss 0.15403248369693756\n",
      "batch 2302: loss 0.13991515338420868\n",
      "batch 2303: loss 0.09224527329206467\n",
      "batch 2304: loss 0.0485006719827652\n",
      "batch 2305: loss 0.0632212832570076\n",
      "batch 2306: loss 0.08713600039482117\n",
      "batch 2307: loss 0.26174890995025635\n",
      "batch 2308: loss 0.13430339097976685\n",
      "batch 2309: loss 0.07632430642843246\n",
      "batch 2310: loss 0.07320453971624374\n",
      "batch 2311: loss 0.06453333050012589\n",
      "batch 2312: loss 0.17385421693325043\n",
      "batch 2313: loss 0.13519656658172607\n",
      "batch 2314: loss 0.07400739192962646\n",
      "batch 2315: loss 0.09789304435253143\n",
      "batch 2316: loss 0.108766570687294\n",
      "batch 2317: loss 0.044541891664266586\n",
      "batch 2318: loss 0.12163727730512619\n",
      "batch 2319: loss 0.03585292398929596\n",
      "batch 2320: loss 0.057497162371873856\n",
      "batch 2321: loss 0.06312867999076843\n",
      "batch 2322: loss 0.07818885892629623\n",
      "batch 2323: loss 0.07003556936979294\n",
      "batch 2324: loss 0.0892019048333168\n",
      "batch 2325: loss 0.05795734375715256\n",
      "batch 2326: loss 0.10575275123119354\n",
      "batch 2327: loss 0.14352987706661224\n",
      "batch 2328: loss 0.123018778860569\n",
      "batch 2329: loss 0.03882504254579544\n",
      "batch 2330: loss 0.01485065184533596\n",
      "batch 2331: loss 0.09780845791101456\n",
      "batch 2332: loss 0.15839378535747528\n",
      "batch 2333: loss 0.08109845966100693\n",
      "batch 2334: loss 0.13017301261425018\n",
      "batch 2335: loss 0.1404249519109726\n",
      "batch 2336: loss 0.15968847274780273\n",
      "batch 2337: loss 0.04068627208471298\n",
      "batch 2338: loss 0.06094532832503319\n",
      "batch 2339: loss 0.06725384294986725\n",
      "batch 2340: loss 0.14647813141345978\n",
      "batch 2341: loss 0.06642555445432663\n",
      "batch 2342: loss 0.08300714939832687\n",
      "batch 2343: loss 0.04738606885075569\n",
      "batch 2344: loss 0.05536998063325882\n",
      "batch 2345: loss 0.17484770715236664\n",
      "batch 2346: loss 0.0520247146487236\n",
      "batch 2347: loss 0.09800750762224197\n",
      "batch 2348: loss 0.10165494680404663\n",
      "batch 2349: loss 0.02384220063686371\n",
      "batch 2350: loss 0.0425819493830204\n",
      "batch 2351: loss 0.186664417386055\n",
      "batch 2352: loss 0.03953227028250694\n",
      "batch 2353: loss 0.1567675918340683\n",
      "batch 2354: loss 0.17316560447216034\n",
      "batch 2355: loss 0.15789788961410522\n",
      "batch 2356: loss 0.2631042003631592\n",
      "batch 2357: loss 0.04061828926205635\n",
      "batch 2358: loss 0.024961581453680992\n",
      "batch 2359: loss 0.1754523068666458\n",
      "batch 2360: loss 0.05034913122653961\n",
      "batch 2361: loss 0.09831748902797699\n",
      "batch 2362: loss 0.16413334012031555\n",
      "batch 2363: loss 0.07979433983564377\n",
      "batch 2364: loss 0.09806711971759796\n",
      "batch 2365: loss 0.057374007999897\n",
      "batch 2366: loss 0.036964301019907\n",
      "batch 2367: loss 0.0830281600356102\n",
      "batch 2368: loss 0.03967124596238136\n",
      "batch 2369: loss 0.12682613730430603\n",
      "batch 2370: loss 0.0982566624879837\n",
      "batch 2371: loss 0.06650486588478088\n",
      "batch 2372: loss 0.17715734243392944\n",
      "batch 2373: loss 0.11484788358211517\n",
      "batch 2374: loss 0.14038459956645966\n",
      "batch 2375: loss 0.029430001974105835\n",
      "batch 2376: loss 0.022013600915670395\n",
      "batch 2377: loss 0.13905398547649384\n",
      "batch 2378: loss 0.03630140796303749\n",
      "batch 2379: loss 0.08055759221315384\n",
      "batch 2380: loss 0.05558078736066818\n",
      "batch 2381: loss 0.130536749958992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2382: loss 0.10628524422645569\n",
      "batch 2383: loss 0.04801355302333832\n",
      "batch 2384: loss 0.1668861210346222\n",
      "batch 2385: loss 0.08185670524835587\n",
      "batch 2386: loss 0.0424811877310276\n",
      "batch 2387: loss 0.25581756234169006\n",
      "batch 2388: loss 0.1434057652950287\n",
      "batch 2389: loss 0.045227374881505966\n",
      "batch 2390: loss 0.10177922993898392\n",
      "batch 2391: loss 0.05081059783697128\n",
      "batch 2392: loss 0.13902625441551208\n",
      "batch 2393: loss 0.10596532374620438\n",
      "batch 2394: loss 0.08395815640687943\n",
      "batch 2395: loss 0.16645972430706024\n",
      "batch 2396: loss 0.1644289791584015\n",
      "batch 2397: loss 0.035744957625865936\n",
      "batch 2398: loss 0.12477460503578186\n",
      "batch 2399: loss 0.024753794074058533\n",
      "batch 2400: loss 0.04829861968755722\n",
      "batch 2401: loss 0.0795716717839241\n",
      "batch 2402: loss 0.17564429342746735\n",
      "batch 2403: loss 0.04044977203011513\n",
      "batch 2404: loss 0.11865818500518799\n",
      "batch 2405: loss 0.07653027027845383\n",
      "batch 2406: loss 0.027599701657891273\n",
      "batch 2407: loss 0.06412193924188614\n",
      "batch 2408: loss 0.23012280464172363\n",
      "batch 2409: loss 0.04691774398088455\n",
      "batch 2410: loss 0.07271042466163635\n",
      "batch 2411: loss 0.053724486380815506\n",
      "batch 2412: loss 0.09859181940555573\n",
      "batch 2413: loss 0.0684230849146843\n",
      "batch 2414: loss 0.08234204351902008\n",
      "batch 2415: loss 0.1417558640241623\n",
      "batch 2416: loss 0.09490789473056793\n",
      "batch 2417: loss 0.0255997646600008\n",
      "batch 2418: loss 0.07632975280284882\n",
      "batch 2419: loss 0.1756044328212738\n",
      "batch 2420: loss 0.06906341761350632\n",
      "batch 2421: loss 0.14374762773513794\n",
      "batch 2422: loss 0.13547754287719727\n",
      "batch 2423: loss 0.06720034778118134\n",
      "batch 2424: loss 0.0529216043651104\n",
      "batch 2425: loss 0.06494622677564621\n",
      "batch 2426: loss 0.06641639024019241\n",
      "batch 2427: loss 0.1335226595401764\n",
      "batch 2428: loss 0.14963015913963318\n",
      "batch 2429: loss 0.07432213425636292\n",
      "batch 2430: loss 0.09506484866142273\n",
      "batch 2431: loss 0.1025637611746788\n",
      "batch 2432: loss 0.038315318524837494\n",
      "batch 2433: loss 0.0478394590318203\n",
      "batch 2434: loss 0.034838490188121796\n",
      "batch 2435: loss 0.057138022035360336\n",
      "batch 2436: loss 0.05296896770596504\n",
      "batch 2437: loss 0.11122796684503555\n",
      "batch 2438: loss 0.31248417496681213\n",
      "batch 2439: loss 0.2467162311077118\n",
      "batch 2440: loss 0.07955452054738998\n",
      "batch 2441: loss 0.13002640008926392\n",
      "batch 2442: loss 0.1283593475818634\n",
      "batch 2443: loss 0.054580505937337875\n",
      "batch 2444: loss 0.07825037091970444\n",
      "batch 2445: loss 0.02371259592473507\n",
      "batch 2446: loss 0.1092018112540245\n",
      "batch 2447: loss 0.12955735623836517\n",
      "batch 2448: loss 0.05214205011725426\n",
      "batch 2449: loss 0.05448766052722931\n",
      "batch 2450: loss 0.11442085355520248\n",
      "batch 2451: loss 0.05125943198800087\n",
      "batch 2452: loss 0.05383211001753807\n",
      "batch 2453: loss 0.07482974231243134\n",
      "batch 2454: loss 0.06712177395820618\n",
      "batch 2455: loss 0.16252164542675018\n",
      "batch 2456: loss 0.15411964058876038\n",
      "batch 2457: loss 0.05241478979587555\n",
      "batch 2458: loss 0.030169744044542313\n",
      "batch 2459: loss 0.06538276374340057\n",
      "batch 2460: loss 0.14006385207176208\n",
      "batch 2461: loss 0.20475724339485168\n",
      "batch 2462: loss 0.1214427724480629\n",
      "batch 2463: loss 0.012810096144676208\n",
      "batch 2464: loss 0.06253769993782043\n",
      "batch 2465: loss 0.20783507823944092\n",
      "batch 2466: loss 0.09675899147987366\n",
      "batch 2467: loss 0.11582744121551514\n",
      "batch 2468: loss 0.08562356978654861\n",
      "batch 2469: loss 0.04767190292477608\n",
      "batch 2470: loss 0.04135558009147644\n",
      "batch 2471: loss 0.05880184471607208\n",
      "batch 2472: loss 0.09914624691009521\n",
      "batch 2473: loss 0.07523734122514725\n",
      "batch 2474: loss 0.039116181433200836\n",
      "batch 2475: loss 0.0323224775493145\n",
      "batch 2476: loss 0.10903758555650711\n",
      "batch 2477: loss 0.04309253767132759\n",
      "batch 2478: loss 0.15708160400390625\n",
      "batch 2479: loss 0.24121515452861786\n",
      "batch 2480: loss 0.12637419998645782\n",
      "batch 2481: loss 0.05882091447710991\n",
      "batch 2482: loss 0.24629691243171692\n",
      "batch 2483: loss 0.10547428578138351\n",
      "batch 2484: loss 0.08799924701452255\n",
      "batch 2485: loss 0.16884544491767883\n",
      "batch 2486: loss 0.020715337246656418\n",
      "batch 2487: loss 0.05572199076414108\n",
      "batch 2488: loss 0.09217916429042816\n",
      "batch 2489: loss 0.17537958920001984\n",
      "batch 2490: loss 0.026326309889554977\n",
      "batch 2491: loss 0.04605988413095474\n",
      "batch 2492: loss 0.11051225662231445\n",
      "batch 2493: loss 0.19337445497512817\n",
      "batch 2494: loss 0.054020803421735764\n",
      "batch 2495: loss 0.22214564681053162\n",
      "batch 2496: loss 0.022149905562400818\n",
      "batch 2497: loss 0.09951834380626678\n",
      "batch 2498: loss 0.46277913451194763\n",
      "batch 2499: loss 0.072728730738163\n",
      "batch 2500: loss 0.020630916580557823\n",
      "batch 2501: loss 0.018476786091923714\n",
      "batch 2502: loss 0.2504175007343292\n",
      "batch 2503: loss 0.06060468405485153\n",
      "batch 2504: loss 0.0954974889755249\n",
      "batch 2505: loss 0.20232918858528137\n",
      "batch 2506: loss 0.0572778545320034\n",
      "batch 2507: loss 0.17022931575775146\n",
      "batch 2508: loss 0.06788185983896255\n",
      "batch 2509: loss 0.0631563812494278\n",
      "batch 2510: loss 0.1782689094543457\n",
      "batch 2511: loss 0.1702652871608734\n",
      "batch 2512: loss 0.02395414374768734\n",
      "batch 2513: loss 0.10446061193943024\n",
      "batch 2514: loss 0.0565418042242527\n",
      "batch 2515: loss 0.3231392502784729\n",
      "batch 2516: loss 0.12723210453987122\n",
      "batch 2517: loss 0.08618175983428955\n",
      "batch 2518: loss 0.050563372671604156\n",
      "batch 2519: loss 0.23209601640701294\n",
      "batch 2520: loss 0.16967277228832245\n",
      "batch 2521: loss 0.10236615687608719\n",
      "batch 2522: loss 0.03475514426827431\n",
      "batch 2523: loss 0.033672995865345\n",
      "batch 2524: loss 0.05253472179174423\n",
      "batch 2525: loss 0.08727513253688812\n",
      "batch 2526: loss 0.0618218258023262\n",
      "batch 2527: loss 0.17946495115756989\n",
      "batch 2528: loss 0.09294310957193375\n",
      "batch 2529: loss 0.10552307218313217\n",
      "batch 2530: loss 0.2179589569568634\n",
      "batch 2531: loss 0.07609812915325165\n",
      "batch 2532: loss 0.12259481847286224\n",
      "batch 2533: loss 0.0678190290927887\n",
      "batch 2534: loss 0.183822900056839\n",
      "batch 2535: loss 0.1536218672990799\n",
      "batch 2536: loss 0.1858767867088318\n",
      "batch 2537: loss 0.09359221905469894\n",
      "batch 2538: loss 0.07459888607263565\n",
      "batch 2539: loss 0.07789306342601776\n",
      "batch 2540: loss 0.043207377195358276\n",
      "batch 2541: loss 0.13832272589206696\n",
      "batch 2542: loss 0.10880108922719955\n",
      "batch 2543: loss 0.03859783336520195\n",
      "batch 2544: loss 0.11005280166864395\n",
      "batch 2545: loss 0.04867149144411087\n",
      "batch 2546: loss 0.08312790840864182\n",
      "batch 2547: loss 0.09535298496484756\n",
      "batch 2548: loss 0.090873122215271\n",
      "batch 2549: loss 0.14266782999038696\n",
      "batch 2550: loss 0.10380834341049194\n",
      "batch 2551: loss 0.011959738098084927\n",
      "batch 2552: loss 0.039705175906419754\n",
      "batch 2553: loss 0.08341118693351746\n",
      "batch 2554: loss 0.04583396390080452\n",
      "batch 2555: loss 0.04756208136677742\n",
      "batch 2556: loss 0.054640285670757294\n",
      "batch 2557: loss 0.09025785326957703\n",
      "batch 2558: loss 0.27658337354660034\n",
      "batch 2559: loss 0.05459451675415039\n",
      "batch 2560: loss 0.14424574375152588\n",
      "batch 2561: loss 0.07418204843997955\n",
      "batch 2562: loss 0.21443840861320496\n",
      "batch 2563: loss 0.08275417238473892\n",
      "batch 2564: loss 0.07036590576171875\n",
      "batch 2565: loss 0.035253170877695084\n",
      "batch 2566: loss 0.05450684577226639\n",
      "batch 2567: loss 0.06348814815282822\n",
      "batch 2568: loss 0.15237033367156982\n",
      "batch 2569: loss 0.21017171442508698\n",
      "batch 2570: loss 0.11383996903896332\n",
      "batch 2571: loss 0.03684871643781662\n",
      "batch 2572: loss 0.09991073608398438\n",
      "batch 2573: loss 0.0890047699213028\n",
      "batch 2574: loss 0.05725916847586632\n",
      "batch 2575: loss 0.18141348659992218\n",
      "batch 2576: loss 0.10702191293239594\n",
      "batch 2577: loss 0.1818687915802002\n",
      "batch 2578: loss 0.12271523475646973\n",
      "batch 2579: loss 0.14886173605918884\n",
      "batch 2580: loss 0.07510256767272949\n",
      "batch 2581: loss 0.044162213802337646\n",
      "batch 2582: loss 0.22610698640346527\n",
      "batch 2583: loss 0.08949003368616104\n",
      "batch 2584: loss 0.20519447326660156\n",
      "batch 2585: loss 0.05053785815834999\n",
      "batch 2586: loss 0.0933503732085228\n",
      "batch 2587: loss 0.07878391444683075\n",
      "batch 2588: loss 0.07315173745155334\n",
      "batch 2589: loss 0.1609693318605423\n",
      "batch 2590: loss 0.08292645961046219\n",
      "batch 2591: loss 0.10567134618759155\n",
      "batch 2592: loss 0.2071782946586609\n",
      "batch 2593: loss 0.03282824158668518\n",
      "batch 2594: loss 0.08792577683925629\n",
      "batch 2595: loss 0.12396449595689774\n",
      "batch 2596: loss 0.14278659224510193\n",
      "batch 2597: loss 0.038346126675605774\n",
      "batch 2598: loss 0.1217898353934288\n",
      "batch 2599: loss 0.1747138500213623\n",
      "batch 2600: loss 0.2965080738067627\n",
      "batch 2601: loss 0.026184819638729095\n",
      "batch 2602: loss 0.11972586065530777\n",
      "batch 2603: loss 0.03849811479449272\n",
      "batch 2604: loss 0.17211610078811646\n",
      "batch 2605: loss 0.07696770131587982\n",
      "batch 2606: loss 0.057448651641607285\n",
      "batch 2607: loss 0.08836368471384048\n",
      "batch 2608: loss 0.025858350098133087\n",
      "batch 2609: loss 0.02619847282767296\n",
      "batch 2610: loss 0.112370565533638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2611: loss 0.252103328704834\n",
      "batch 2612: loss 0.13280850648880005\n",
      "batch 2613: loss 0.280124694108963\n",
      "batch 2614: loss 0.34361356496810913\n",
      "batch 2615: loss 0.05957774072885513\n",
      "batch 2616: loss 0.0685478001832962\n",
      "batch 2617: loss 0.09308689832687378\n",
      "batch 2618: loss 0.3005453646183014\n",
      "batch 2619: loss 0.09761513769626617\n",
      "batch 2620: loss 0.028384186327457428\n",
      "batch 2621: loss 0.15378285944461823\n",
      "batch 2622: loss 0.07252050191164017\n",
      "batch 2623: loss 0.2097136676311493\n",
      "batch 2624: loss 0.1667896956205368\n",
      "batch 2625: loss 0.07373461127281189\n",
      "batch 2626: loss 0.1428060382604599\n",
      "batch 2627: loss 0.1720465123653412\n",
      "batch 2628: loss 0.028928270563483238\n",
      "batch 2629: loss 0.35508471727371216\n",
      "batch 2630: loss 0.20603495836257935\n",
      "batch 2631: loss 0.033050570636987686\n",
      "batch 2632: loss 0.07622829079627991\n",
      "batch 2633: loss 0.06852160394191742\n",
      "batch 2634: loss 0.0768405869603157\n",
      "batch 2635: loss 0.14471812546253204\n",
      "batch 2636: loss 0.13276250660419464\n",
      "batch 2637: loss 0.081377774477005\n",
      "batch 2638: loss 0.11567143350839615\n",
      "batch 2639: loss 0.16514259576797485\n",
      "batch 2640: loss 0.05468779429793358\n",
      "batch 2641: loss 0.04953295737504959\n",
      "batch 2642: loss 0.06234809756278992\n",
      "batch 2643: loss 0.06006743386387825\n",
      "batch 2644: loss 0.12098481506109238\n",
      "batch 2645: loss 0.10960821062326431\n",
      "batch 2646: loss 0.07391475141048431\n",
      "batch 2647: loss 0.11679254472255707\n",
      "batch 2648: loss 0.06364423781633377\n",
      "batch 2649: loss 0.10470221936702728\n",
      "batch 2650: loss 0.058850400149822235\n",
      "batch 2651: loss 0.07972898334264755\n",
      "batch 2652: loss 0.052321285009384155\n",
      "batch 2653: loss 0.20807471871376038\n",
      "batch 2654: loss 0.02366623282432556\n",
      "batch 2655: loss 0.05392874777317047\n",
      "batch 2656: loss 0.2268439382314682\n",
      "batch 2657: loss 0.23994651436805725\n",
      "batch 2658: loss 0.1448545604944229\n",
      "batch 2659: loss 0.11554445326328278\n",
      "batch 2660: loss 0.14148911833763123\n",
      "batch 2661: loss 0.08146174252033234\n",
      "batch 2662: loss 0.0847102552652359\n",
      "batch 2663: loss 0.07878796756267548\n",
      "batch 2664: loss 0.118560291826725\n",
      "batch 2665: loss 0.03198104724287987\n",
      "batch 2666: loss 0.22747094929218292\n",
      "batch 2667: loss 0.05224955826997757\n",
      "batch 2668: loss 0.11760763078927994\n",
      "batch 2669: loss 0.012132976204156876\n",
      "batch 2670: loss 0.10455858707427979\n",
      "batch 2671: loss 0.0191643089056015\n",
      "batch 2672: loss 0.10419788211584091\n",
      "batch 2673: loss 0.21739298105239868\n",
      "batch 2674: loss 0.12874332070350647\n",
      "batch 2675: loss 0.15402188897132874\n",
      "batch 2676: loss 0.240914985537529\n",
      "batch 2677: loss 0.13952647149562836\n",
      "batch 2678: loss 0.17882980406284332\n",
      "batch 2679: loss 0.06355170160531998\n",
      "batch 2680: loss 0.16181659698486328\n",
      "batch 2681: loss 0.06246129795908928\n",
      "batch 2682: loss 0.0874103531241417\n",
      "batch 2683: loss 0.11498626321554184\n",
      "batch 2684: loss 0.07571254670619965\n",
      "batch 2685: loss 0.020852722227573395\n",
      "batch 2686: loss 0.028953883796930313\n",
      "batch 2687: loss 0.07766038924455643\n",
      "batch 2688: loss 0.13896186649799347\n",
      "batch 2689: loss 0.24432100355625153\n",
      "batch 2690: loss 0.020417479798197746\n",
      "batch 2691: loss 0.10368522256612778\n",
      "batch 2692: loss 0.16933435201644897\n",
      "batch 2693: loss 0.05399532988667488\n",
      "batch 2694: loss 0.2880468964576721\n",
      "batch 2695: loss 0.09661736339330673\n",
      "batch 2696: loss 0.2086247205734253\n",
      "batch 2697: loss 0.07700860500335693\n",
      "batch 2698: loss 0.07462204992771149\n",
      "batch 2699: loss 0.0644681304693222\n",
      "batch 2700: loss 0.05569292977452278\n",
      "batch 2701: loss 0.16451862454414368\n",
      "batch 2702: loss 0.03909863531589508\n",
      "batch 2703: loss 0.1134006455540657\n",
      "batch 2704: loss 0.09753163158893585\n",
      "batch 2705: loss 0.05184140056371689\n",
      "batch 2706: loss 0.03528768941760063\n",
      "batch 2707: loss 0.07341020554304123\n",
      "batch 2708: loss 0.08849702775478363\n",
      "batch 2709: loss 0.04817558825016022\n",
      "batch 2710: loss 0.07105464488267899\n",
      "batch 2711: loss 0.05216658115386963\n",
      "batch 2712: loss 0.18588215112686157\n",
      "batch 2713: loss 0.06854886561632156\n",
      "batch 2714: loss 0.2593131959438324\n",
      "batch 2715: loss 0.07413995265960693\n",
      "batch 2716: loss 0.03889469802379608\n",
      "batch 2717: loss 0.1459946483373642\n",
      "batch 2718: loss 0.10683578252792358\n",
      "batch 2719: loss 0.041350916028022766\n",
      "batch 2720: loss 0.07500370591878891\n",
      "batch 2721: loss 0.10005050152540207\n",
      "batch 2722: loss 0.0536150261759758\n",
      "batch 2723: loss 0.03354116901755333\n",
      "batch 2724: loss 0.11371588706970215\n",
      "batch 2725: loss 0.15888866782188416\n",
      "batch 2726: loss 0.04630765691399574\n",
      "batch 2727: loss 0.031234845519065857\n",
      "batch 2728: loss 0.08533502370119095\n",
      "batch 2729: loss 0.11248496174812317\n",
      "batch 2730: loss 0.23518754541873932\n",
      "batch 2731: loss 0.04031219705939293\n",
      "batch 2732: loss 0.10132530331611633\n",
      "batch 2733: loss 0.09484389424324036\n",
      "batch 2734: loss 0.09984821826219559\n",
      "batch 2735: loss 0.0608765073120594\n",
      "batch 2736: loss 0.05164332315325737\n",
      "batch 2737: loss 0.03294270113110542\n",
      "batch 2738: loss 0.1744907945394516\n",
      "batch 2739: loss 0.07600163668394089\n",
      "batch 2740: loss 0.09827359765768051\n",
      "batch 2741: loss 0.2761813700199127\n",
      "batch 2742: loss 0.07781297713518143\n",
      "batch 2743: loss 0.1335739642381668\n",
      "batch 2744: loss 0.2164761871099472\n",
      "batch 2745: loss 0.06541129946708679\n",
      "batch 2746: loss 0.0647779181599617\n",
      "batch 2747: loss 0.10277264565229416\n",
      "batch 2748: loss 0.031209144741296768\n",
      "batch 2749: loss 0.0820198580622673\n",
      "batch 2750: loss 0.117740698158741\n",
      "batch 2751: loss 0.04978063330054283\n",
      "batch 2752: loss 0.015203187242150307\n",
      "batch 2753: loss 0.08254695683717728\n",
      "batch 2754: loss 0.10498840361833572\n",
      "batch 2755: loss 0.10371005535125732\n",
      "batch 2756: loss 0.12189797312021255\n",
      "batch 2757: loss 0.05655108764767647\n",
      "batch 2758: loss 0.05800126492977142\n",
      "batch 2759: loss 0.023521235212683678\n",
      "batch 2760: loss 0.04380883276462555\n",
      "batch 2761: loss 0.033560704439878464\n",
      "batch 2762: loss 0.07448381930589676\n",
      "batch 2763: loss 0.10015455633401871\n",
      "batch 2764: loss 0.0866740494966507\n",
      "batch 2765: loss 0.06981254369020462\n",
      "batch 2766: loss 0.21508590877056122\n",
      "batch 2767: loss 0.041403159499168396\n",
      "batch 2768: loss 0.04145796597003937\n",
      "batch 2769: loss 0.06394239515066147\n",
      "batch 2770: loss 0.08629308640956879\n",
      "batch 2771: loss 0.02859611250460148\n",
      "batch 2772: loss 0.08951498568058014\n",
      "batch 2773: loss 0.21046900749206543\n",
      "batch 2774: loss 0.05447666347026825\n",
      "batch 2775: loss 0.029442839324474335\n",
      "batch 2776: loss 0.07237217575311661\n",
      "batch 2777: loss 0.13152499496936798\n",
      "batch 2778: loss 0.03433794900774956\n",
      "batch 2779: loss 0.043319206684827805\n",
      "batch 2780: loss 0.20703113079071045\n",
      "batch 2781: loss 0.09735255688428879\n",
      "batch 2782: loss 0.021739758551120758\n",
      "batch 2783: loss 0.2376527488231659\n",
      "batch 2784: loss 0.04533078148961067\n",
      "batch 2785: loss 0.11171761900186539\n",
      "batch 2786: loss 0.06474247574806213\n",
      "batch 2787: loss 0.05061883479356766\n",
      "batch 2788: loss 0.058454353362321854\n",
      "batch 2789: loss 0.03509688749909401\n",
      "batch 2790: loss 0.2834210991859436\n",
      "batch 2791: loss 0.02358432672917843\n",
      "batch 2792: loss 0.08489744365215302\n",
      "batch 2793: loss 0.06304517388343811\n",
      "batch 2794: loss 0.15348321199417114\n",
      "batch 2795: loss 0.1982484608888626\n",
      "batch 2796: loss 0.14397256076335907\n",
      "batch 2797: loss 0.11237911880016327\n",
      "batch 2798: loss 0.03157501667737961\n",
      "batch 2799: loss 0.06717570126056671\n",
      "batch 2800: loss 0.02287963032722473\n",
      "batch 2801: loss 0.08538611233234406\n",
      "batch 2802: loss 0.04716179147362709\n",
      "batch 2803: loss 0.08639572560787201\n",
      "batch 2804: loss 0.03338683769106865\n",
      "batch 2805: loss 0.07326428592205048\n",
      "batch 2806: loss 0.23714391887187958\n",
      "batch 2807: loss 0.09465902298688889\n",
      "batch 2808: loss 0.07407503575086594\n",
      "batch 2809: loss 0.15530367195606232\n",
      "batch 2810: loss 0.24383294582366943\n",
      "batch 2811: loss 0.1834281086921692\n",
      "batch 2812: loss 0.1444595903158188\n",
      "batch 2813: loss 0.15250703692436218\n",
      "batch 2814: loss 0.08305686712265015\n",
      "batch 2815: loss 0.02228088304400444\n",
      "batch 2816: loss 0.025348123162984848\n",
      "batch 2817: loss 0.2999109923839569\n",
      "batch 2818: loss 0.11897174268960953\n",
      "batch 2819: loss 0.08498983085155487\n",
      "batch 2820: loss 0.022447757422924042\n",
      "batch 2821: loss 0.040050096809864044\n",
      "batch 2822: loss 0.0555330254137516\n",
      "batch 2823: loss 0.17327536642551422\n",
      "batch 2824: loss 0.03357098251581192\n",
      "batch 2825: loss 0.05855417624115944\n",
      "batch 2826: loss 0.12472459673881531\n",
      "batch 2827: loss 0.0270976684987545\n",
      "batch 2828: loss 0.07415671646595001\n",
      "batch 2829: loss 0.2010480761528015\n",
      "batch 2830: loss 0.192671999335289\n",
      "batch 2831: loss 0.07587085664272308\n",
      "batch 2832: loss 0.06443314254283905\n",
      "batch 2833: loss 0.03816216439008713\n",
      "batch 2834: loss 0.02819262258708477\n",
      "batch 2835: loss 0.052162040024995804\n",
      "batch 2836: loss 0.12323445081710815\n",
      "batch 2837: loss 0.020115146413445473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2838: loss 0.08162789046764374\n",
      "batch 2839: loss 0.07371589541435242\n",
      "batch 2840: loss 0.0483550950884819\n",
      "batch 2841: loss 0.05127594992518425\n",
      "batch 2842: loss 0.05724584311246872\n",
      "batch 2843: loss 0.05640621855854988\n",
      "batch 2844: loss 0.023130564019083977\n",
      "batch 2845: loss 0.048347778618335724\n",
      "batch 2846: loss 0.09105836600065231\n",
      "batch 2847: loss 0.05887335538864136\n",
      "batch 2848: loss 0.051437053829431534\n",
      "batch 2849: loss 0.07800912857055664\n",
      "batch 2850: loss 0.1308281123638153\n",
      "batch 2851: loss 0.03677067160606384\n",
      "batch 2852: loss 0.06303553283214569\n",
      "batch 2853: loss 0.1576356440782547\n",
      "batch 2854: loss 0.05273560434579849\n",
      "batch 2855: loss 0.11029969900846481\n",
      "batch 2856: loss 0.12557971477508545\n",
      "batch 2857: loss 0.1040748879313469\n",
      "batch 2858: loss 0.09188485145568848\n",
      "batch 2859: loss 0.046092696487903595\n",
      "batch 2860: loss 0.051684558391571045\n",
      "batch 2861: loss 0.12958365678787231\n",
      "batch 2862: loss 0.14255504310131073\n",
      "batch 2863: loss 0.12029280513525009\n",
      "batch 2864: loss 0.040938131511211395\n",
      "batch 2865: loss 0.08935204893350601\n",
      "batch 2866: loss 0.06147249415516853\n",
      "batch 2867: loss 0.04471157118678093\n",
      "batch 2868: loss 0.2021341472864151\n",
      "batch 2869: loss 0.06003297492861748\n",
      "batch 2870: loss 0.0558282844722271\n",
      "batch 2871: loss 0.0982694998383522\n",
      "batch 2872: loss 0.08759362995624542\n",
      "batch 2873: loss 0.0964907631278038\n",
      "batch 2874: loss 0.02927430532872677\n",
      "batch 2875: loss 0.05799858272075653\n",
      "batch 2876: loss 0.05383665859699249\n",
      "batch 2877: loss 0.23361140489578247\n",
      "batch 2878: loss 0.10372287780046463\n",
      "batch 2879: loss 0.03809234872460365\n",
      "batch 2880: loss 0.07719238847494125\n",
      "batch 2881: loss 0.0182174239307642\n",
      "batch 2882: loss 0.12488376349210739\n",
      "batch 2883: loss 0.07168929278850555\n",
      "batch 2884: loss 0.06002042815089226\n",
      "batch 2885: loss 0.04265371710062027\n",
      "batch 2886: loss 0.11136232316493988\n",
      "batch 2887: loss 0.1093912273645401\n",
      "batch 2888: loss 0.0975440964102745\n",
      "batch 2889: loss 0.04298316314816475\n",
      "batch 2890: loss 0.12258567661046982\n",
      "batch 2891: loss 0.14854773879051208\n",
      "batch 2892: loss 0.03995866701006889\n",
      "batch 2893: loss 0.10512595623731613\n",
      "batch 2894: loss 0.17249999940395355\n",
      "batch 2895: loss 0.22032499313354492\n",
      "batch 2896: loss 0.06385564804077148\n",
      "batch 2897: loss 0.06069859489798546\n",
      "batch 2898: loss 0.037167519330978394\n",
      "batch 2899: loss 0.016455762088298798\n",
      "batch 2900: loss 0.11195048689842224\n",
      "batch 2901: loss 0.04578535631299019\n",
      "batch 2902: loss 0.04403059557080269\n",
      "batch 2903: loss 0.048432715237140656\n",
      "batch 2904: loss 0.04131728410720825\n",
      "batch 2905: loss 0.20935289561748505\n",
      "batch 2906: loss 0.0529513880610466\n",
      "batch 2907: loss 0.020439650863409042\n",
      "batch 2908: loss 0.0840408131480217\n",
      "batch 2909: loss 0.09035734087228775\n",
      "batch 2910: loss 0.06017984077334404\n",
      "batch 2911: loss 0.07313821464776993\n",
      "batch 2912: loss 0.15543782711029053\n",
      "batch 2913: loss 0.025347864255309105\n",
      "batch 2914: loss 0.09150516241788864\n",
      "batch 2915: loss 0.12049859017133713\n",
      "batch 2916: loss 0.016262734308838844\n",
      "batch 2917: loss 0.045119475573301315\n",
      "batch 2918: loss 0.14762157201766968\n",
      "batch 2919: loss 0.061586473137140274\n",
      "batch 2920: loss 0.08236797153949738\n",
      "batch 2921: loss 0.054562538862228394\n",
      "batch 2922: loss 0.14654621481895447\n",
      "batch 2923: loss 0.06859105825424194\n",
      "batch 2924: loss 0.030264612287282944\n",
      "batch 2925: loss 0.07308880984783173\n",
      "batch 2926: loss 0.06735552102327347\n",
      "batch 2927: loss 0.18777942657470703\n",
      "batch 2928: loss 0.08718538284301758\n",
      "batch 2929: loss 0.08068902790546417\n",
      "batch 2930: loss 0.053858354687690735\n",
      "batch 2931: loss 0.14518499374389648\n",
      "batch 2932: loss 0.2509448528289795\n",
      "batch 2933: loss 0.028495129197835922\n",
      "batch 2934: loss 0.036017876118421555\n",
      "batch 2935: loss 0.03345737233757973\n",
      "batch 2936: loss 0.1798231154680252\n",
      "batch 2937: loss 0.02768273837864399\n",
      "batch 2938: loss 0.07601885497570038\n",
      "batch 2939: loss 0.29359495639801025\n",
      "batch 2940: loss 0.02079183980822563\n",
      "batch 2941: loss 0.12287330627441406\n",
      "batch 2942: loss 0.029476620256900787\n",
      "batch 2943: loss 0.03958721458911896\n",
      "batch 2944: loss 0.1895807534456253\n",
      "batch 2945: loss 0.08061625063419342\n",
      "batch 2946: loss 0.05281505361199379\n",
      "batch 2947: loss 0.021379511803388596\n",
      "batch 2948: loss 0.19452448189258575\n",
      "batch 2949: loss 0.0900195762515068\n",
      "batch 2950: loss 0.0779031366109848\n",
      "batch 2951: loss 0.12644517421722412\n",
      "batch 2952: loss 0.10881690680980682\n",
      "batch 2953: loss 0.024045562371611595\n",
      "batch 2954: loss 0.03241020441055298\n",
      "batch 2955: loss 0.07025796920061111\n",
      "batch 2956: loss 0.07182778418064117\n",
      "batch 2957: loss 0.09489619731903076\n",
      "batch 2958: loss 0.11315073072910309\n",
      "batch 2959: loss 0.08890262991189957\n",
      "batch 2960: loss 0.041536182165145874\n",
      "batch 2961: loss 0.11589603126049042\n",
      "batch 2962: loss 0.030035924166440964\n",
      "batch 2963: loss 0.015803510323166847\n",
      "batch 2964: loss 0.04882501810789108\n",
      "batch 2965: loss 0.0699729323387146\n",
      "batch 2966: loss 0.09904405474662781\n",
      "batch 2967: loss 0.12680573761463165\n",
      "batch 2968: loss 0.10345836728811264\n",
      "batch 2969: loss 0.04239644110202789\n",
      "batch 2970: loss 0.06380583345890045\n",
      "batch 2971: loss 0.07811734825372696\n",
      "batch 2972: loss 0.157242089509964\n",
      "batch 2973: loss 0.0922560766339302\n",
      "batch 2974: loss 0.15393632650375366\n",
      "batch 2975: loss 0.30963653326034546\n",
      "batch 2976: loss 0.1027221828699112\n",
      "batch 2977: loss 0.11053172498941422\n",
      "batch 2978: loss 0.13616366684436798\n",
      "batch 2979: loss 0.0309955645352602\n",
      "batch 2980: loss 0.03877854719758034\n",
      "batch 2981: loss 0.21938644349575043\n",
      "batch 2982: loss 0.25864988565444946\n",
      "batch 2983: loss 0.14403124153614044\n",
      "batch 2984: loss 0.04907240718603134\n",
      "batch 2985: loss 0.10502885282039642\n",
      "batch 2986: loss 0.09486876428127289\n",
      "batch 2987: loss 0.020890025421977043\n",
      "batch 2988: loss 0.07906116545200348\n",
      "batch 2989: loss 0.03479044511914253\n",
      "batch 2990: loss 0.01658320613205433\n",
      "batch 2991: loss 0.08735345304012299\n",
      "batch 2992: loss 0.03527740016579628\n",
      "batch 2993: loss 0.0518416166305542\n",
      "batch 2994: loss 0.08270440995693207\n",
      "batch 2995: loss 0.03840436786413193\n",
      "batch 2996: loss 0.09271737933158875\n",
      "batch 2997: loss 0.032565925270318985\n",
      "batch 2998: loss 0.09957580268383026\n",
      "batch 2999: loss 0.21976815164089203\n",
      "batch 3000: loss 0.04828561842441559\n",
      "batch 3001: loss 0.07738149166107178\n",
      "batch 3002: loss 0.013373112305998802\n",
      "batch 3003: loss 0.06628644466400146\n",
      "batch 3004: loss 0.027764298021793365\n",
      "batch 3005: loss 0.03665803000330925\n",
      "batch 3006: loss 0.04834546148777008\n",
      "batch 3007: loss 0.13970325887203217\n",
      "batch 3008: loss 0.28171858191490173\n",
      "batch 3009: loss 0.13408030569553375\n",
      "batch 3010: loss 0.01162923313677311\n",
      "batch 3011: loss 0.17862465977668762\n",
      "batch 3012: loss 0.08784421533346176\n",
      "batch 3013: loss 0.1081937924027443\n",
      "batch 3014: loss 0.016680505126714706\n",
      "batch 3015: loss 0.1002158597111702\n",
      "batch 3016: loss 0.18513308465480804\n",
      "batch 3017: loss 0.03967190533876419\n",
      "batch 3018: loss 0.045029416680336\n",
      "batch 3019: loss 0.052640967071056366\n",
      "batch 3020: loss 0.03743644058704376\n",
      "batch 3021: loss 0.04107096418738365\n",
      "batch 3022: loss 0.09202348440885544\n",
      "batch 3023: loss 0.15177851915359497\n",
      "batch 3024: loss 0.11354269087314606\n",
      "batch 3025: loss 0.19708748161792755\n",
      "batch 3026: loss 0.02196457050740719\n",
      "batch 3027: loss 0.04006858170032501\n",
      "batch 3028: loss 0.048389751464128494\n",
      "batch 3029: loss 0.0964285284280777\n",
      "batch 3030: loss 0.1605508029460907\n",
      "batch 3031: loss 0.15003158152103424\n",
      "batch 3032: loss 0.05627167597413063\n",
      "batch 3033: loss 0.06581577658653259\n",
      "batch 3034: loss 0.17022885382175446\n",
      "batch 3035: loss 0.02636299468576908\n",
      "batch 3036: loss 0.21945397555828094\n",
      "batch 3037: loss 0.06254696100950241\n",
      "batch 3038: loss 0.10896629095077515\n",
      "batch 3039: loss 0.06457987427711487\n",
      "batch 3040: loss 0.06154462695121765\n",
      "batch 3041: loss 0.048325903713703156\n",
      "batch 3042: loss 0.027973340824246407\n",
      "batch 3043: loss 0.06432371586561203\n",
      "batch 3044: loss 0.018928436562418938\n",
      "batch 3045: loss 0.10376259684562683\n",
      "batch 3046: loss 0.0452011302113533\n",
      "batch 3047: loss 0.039596397429704666\n",
      "batch 3048: loss 0.15317890048027039\n",
      "batch 3049: loss 0.09039317816495895\n",
      "batch 3050: loss 0.034288812428712845\n",
      "batch 3051: loss 0.23348021507263184\n",
      "batch 3052: loss 0.07542459666728973\n",
      "batch 3053: loss 0.25233715772628784\n",
      "batch 3054: loss 0.07072833925485611\n",
      "batch 3055: loss 0.13153523206710815\n",
      "batch 3056: loss 0.13088218867778778\n",
      "batch 3057: loss 0.03670983389019966\n",
      "batch 3058: loss 0.08372171223163605\n",
      "batch 3059: loss 0.03816568851470947\n",
      "batch 3060: loss 0.08509470522403717\n",
      "batch 3061: loss 0.04900128394365311\n",
      "batch 3062: loss 0.11168563365936279\n",
      "batch 3063: loss 0.10158971697092056\n",
      "batch 3064: loss 0.02223184145987034\n",
      "batch 3065: loss 0.04551101475954056\n",
      "batch 3066: loss 0.29522016644477844\n",
      "batch 3067: loss 0.0665336474776268\n",
      "batch 3068: loss 0.08917564898729324\n",
      "batch 3069: loss 0.13899363577365875\n",
      "batch 3070: loss 0.019200848415493965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3071: loss 0.028692658990621567\n",
      "batch 3072: loss 0.029867030680179596\n",
      "batch 3073: loss 0.06233566254377365\n",
      "batch 3074: loss 0.06010990962386131\n",
      "batch 3075: loss 0.07843604683876038\n",
      "batch 3076: loss 0.23430082201957703\n",
      "batch 3077: loss 0.14510735869407654\n",
      "batch 3078: loss 0.01995847001671791\n",
      "batch 3079: loss 0.04244048893451691\n",
      "batch 3080: loss 0.07809233665466309\n",
      "batch 3081: loss 0.09145224094390869\n",
      "batch 3082: loss 0.06367561966180801\n",
      "batch 3083: loss 0.12491054087877274\n",
      "batch 3084: loss 0.11588021367788315\n",
      "batch 3085: loss 0.1427973508834839\n",
      "batch 3086: loss 0.05326111242175102\n",
      "batch 3087: loss 0.11503597348928452\n",
      "batch 3088: loss 0.03900478035211563\n",
      "batch 3089: loss 0.077642522752285\n",
      "batch 3090: loss 0.1189141497015953\n",
      "batch 3091: loss 0.012078914791345596\n",
      "batch 3092: loss 0.07074509561061859\n",
      "batch 3093: loss 0.019341982901096344\n",
      "batch 3094: loss 0.023076917976140976\n",
      "batch 3095: loss 0.034651439636945724\n",
      "batch 3096: loss 0.1412518322467804\n",
      "batch 3097: loss 0.027991807088255882\n",
      "batch 3098: loss 0.060108985751867294\n",
      "batch 3099: loss 0.07064475119113922\n",
      "batch 3100: loss 0.05183256044983864\n",
      "batch 3101: loss 0.03114570863544941\n",
      "batch 3102: loss 0.07864773273468018\n",
      "batch 3103: loss 0.03429432213306427\n",
      "batch 3104: loss 0.009991275146603584\n",
      "batch 3105: loss 0.025486985221505165\n",
      "batch 3106: loss 0.03831345587968826\n",
      "batch 3107: loss 0.03913184627890587\n",
      "batch 3108: loss 0.027250701561570168\n",
      "batch 3109: loss 0.07582162320613861\n",
      "batch 3110: loss 0.10756070911884308\n",
      "batch 3111: loss 0.114712655544281\n",
      "batch 3112: loss 0.020383838564157486\n",
      "batch 3113: loss 0.02702515758574009\n",
      "batch 3114: loss 0.17428162693977356\n",
      "batch 3115: loss 0.06241011992096901\n",
      "batch 3116: loss 0.28130877017974854\n",
      "batch 3117: loss 0.10264328122138977\n",
      "batch 3118: loss 0.11376240104436874\n",
      "batch 3119: loss 0.06243289262056351\n",
      "batch 3120: loss 0.06068825721740723\n",
      "batch 3121: loss 0.08425472676753998\n",
      "batch 3122: loss 0.09846016764640808\n",
      "batch 3123: loss 0.03236277773976326\n",
      "batch 3124: loss 0.11886407434940338\n",
      "batch 3125: loss 0.0785701721906662\n",
      "batch 3126: loss 0.09112254530191422\n",
      "batch 3127: loss 0.10917547345161438\n",
      "batch 3128: loss 0.14427590370178223\n",
      "batch 3129: loss 0.00832398235797882\n",
      "batch 3130: loss 0.16604995727539062\n",
      "batch 3131: loss 0.011568248271942139\n",
      "batch 3132: loss 0.0430925115942955\n",
      "batch 3133: loss 0.03579306602478027\n",
      "batch 3134: loss 0.14800307154655457\n",
      "batch 3135: loss 0.10664161294698715\n",
      "batch 3136: loss 0.059587955474853516\n",
      "batch 3137: loss 0.07965539395809174\n",
      "batch 3138: loss 0.16133804619312286\n",
      "batch 3139: loss 0.18272127211093903\n",
      "batch 3140: loss 0.07238443940877914\n",
      "batch 3141: loss 0.09691198170185089\n",
      "batch 3142: loss 0.13449174165725708\n",
      "batch 3143: loss 0.014924727380275726\n",
      "batch 3144: loss 0.02585771679878235\n",
      "batch 3145: loss 0.060898177325725555\n",
      "batch 3146: loss 0.2670305073261261\n",
      "batch 3147: loss 0.1619505137205124\n",
      "batch 3148: loss 0.04013737663626671\n",
      "batch 3149: loss 0.0909358412027359\n",
      "batch 3150: loss 0.01775696687400341\n",
      "batch 3151: loss 0.03892313316464424\n",
      "batch 3152: loss 0.08048747479915619\n",
      "batch 3153: loss 0.14822126924991608\n",
      "batch 3154: loss 0.15169164538383484\n",
      "batch 3155: loss 0.022273054346442223\n",
      "batch 3156: loss 0.03507021442055702\n",
      "batch 3157: loss 0.08049968630075455\n",
      "batch 3158: loss 0.11779659986495972\n",
      "batch 3159: loss 0.06877067685127258\n",
      "batch 3160: loss 0.04885958880186081\n",
      "batch 3161: loss 0.16218791902065277\n",
      "batch 3162: loss 0.04359753429889679\n",
      "batch 3163: loss 0.1554850935935974\n",
      "batch 3164: loss 0.029929570853710175\n",
      "batch 3165: loss 0.21538172662258148\n",
      "batch 3166: loss 0.11057919263839722\n",
      "batch 3167: loss 0.01785697601735592\n",
      "batch 3168: loss 0.045516934245824814\n",
      "batch 3169: loss 0.10293836146593094\n",
      "batch 3170: loss 0.0738147497177124\n",
      "batch 3171: loss 0.01776481792330742\n",
      "batch 3172: loss 0.17718970775604248\n",
      "batch 3173: loss 0.053648803383111954\n",
      "batch 3174: loss 0.06272424757480621\n",
      "batch 3175: loss 0.06789283454418182\n",
      "batch 3176: loss 0.047363389283418655\n",
      "batch 3177: loss 0.04924115911126137\n",
      "batch 3178: loss 0.05783367529511452\n",
      "batch 3179: loss 0.24148957431316376\n",
      "batch 3180: loss 0.023516010493040085\n",
      "batch 3181: loss 0.028007252141833305\n",
      "batch 3182: loss 0.07188116759061813\n",
      "batch 3183: loss 0.05035783350467682\n",
      "batch 3184: loss 0.04805514216423035\n",
      "batch 3185: loss 0.06457122415304184\n",
      "batch 3186: loss 0.0645356997847557\n",
      "batch 3187: loss 0.08295393735170364\n",
      "batch 3188: loss 0.1867145448923111\n",
      "batch 3189: loss 0.15105971693992615\n",
      "batch 3190: loss 0.025093993172049522\n",
      "batch 3191: loss 0.06146368011832237\n",
      "batch 3192: loss 0.14405910670757294\n",
      "batch 3193: loss 0.05966660752892494\n",
      "batch 3194: loss 0.11853307485580444\n",
      "batch 3195: loss 0.07611153274774551\n",
      "batch 3196: loss 0.13557025790214539\n",
      "batch 3197: loss 0.17762479186058044\n",
      "batch 3198: loss 0.05763170123100281\n",
      "batch 3199: loss 0.06769507378339767\n",
      "batch 3200: loss 0.0559990294277668\n",
      "batch 3201: loss 0.08312860131263733\n",
      "batch 3202: loss 0.14571674168109894\n",
      "batch 3203: loss 0.13425958156585693\n",
      "batch 3204: loss 0.027677392587065697\n",
      "batch 3205: loss 0.0841008722782135\n",
      "batch 3206: loss 0.14441485702991486\n",
      "batch 3207: loss 0.08242682367563248\n",
      "batch 3208: loss 0.11264418065547943\n",
      "batch 3209: loss 0.05531064793467522\n",
      "batch 3210: loss 0.065830759704113\n",
      "batch 3211: loss 0.09376212954521179\n",
      "batch 3212: loss 0.08025601506233215\n",
      "batch 3213: loss 0.17129990458488464\n",
      "batch 3214: loss 0.1341574639081955\n",
      "batch 3215: loss 0.16095618903636932\n",
      "batch 3216: loss 0.050783831626176834\n",
      "batch 3217: loss 0.026143116876482964\n",
      "batch 3218: loss 0.04544566944241524\n",
      "batch 3219: loss 0.08965083956718445\n",
      "batch 3220: loss 0.08680357038974762\n",
      "batch 3221: loss 0.012385718524456024\n",
      "batch 3222: loss 0.024832047522068024\n",
      "batch 3223: loss 0.08550213277339935\n",
      "batch 3224: loss 0.04255516827106476\n",
      "batch 3225: loss 0.07384038716554642\n",
      "batch 3226: loss 0.13829253613948822\n",
      "batch 3227: loss 0.15970052778720856\n",
      "batch 3228: loss 0.06358475238084793\n",
      "batch 3229: loss 0.252474844455719\n",
      "batch 3230: loss 0.06145624816417694\n",
      "batch 3231: loss 0.04243100434541702\n",
      "batch 3232: loss 0.09280549734830856\n",
      "batch 3233: loss 0.19196553528308868\n",
      "batch 3234: loss 0.1119154691696167\n",
      "batch 3235: loss 0.05920406058430672\n",
      "batch 3236: loss 0.01606146991252899\n",
      "batch 3237: loss 0.11026015132665634\n",
      "batch 3238: loss 0.08112424612045288\n",
      "batch 3239: loss 0.1272611916065216\n",
      "batch 3240: loss 0.028856489807367325\n",
      "batch 3241: loss 0.03422395512461662\n",
      "batch 3242: loss 0.015023338608443737\n",
      "batch 3243: loss 0.0725974291563034\n",
      "batch 3244: loss 0.020506318658590317\n",
      "batch 3245: loss 0.11969461292028427\n",
      "batch 3246: loss 0.09758678823709488\n",
      "batch 3247: loss 0.05045801028609276\n",
      "batch 3248: loss 0.2294742912054062\n",
      "batch 3249: loss 0.08824189007282257\n",
      "batch 3250: loss 0.24853941798210144\n",
      "batch 3251: loss 0.009915407747030258\n",
      "batch 3252: loss 0.05384628102183342\n",
      "batch 3253: loss 0.012172196060419083\n",
      "batch 3254: loss 0.22192995250225067\n",
      "batch 3255: loss 0.09467442333698273\n",
      "batch 3256: loss 0.10014365613460541\n",
      "batch 3257: loss 0.05420713871717453\n",
      "batch 3258: loss 0.08661290258169174\n",
      "batch 3259: loss 0.18755459785461426\n",
      "batch 3260: loss 0.06656166166067123\n",
      "batch 3261: loss 0.12021863460540771\n",
      "batch 3262: loss 0.08471115678548813\n",
      "batch 3263: loss 0.20105423033237457\n",
      "batch 3264: loss 0.08782552182674408\n",
      "batch 3265: loss 0.11873499304056168\n",
      "batch 3266: loss 0.151776984333992\n",
      "batch 3267: loss 0.11373485624790192\n",
      "batch 3268: loss 0.08540228009223938\n",
      "batch 3269: loss 0.18619872629642487\n",
      "batch 3270: loss 0.15244919061660767\n",
      "batch 3271: loss 0.16901962459087372\n",
      "batch 3272: loss 0.14193373918533325\n",
      "batch 3273: loss 0.02651902660727501\n",
      "batch 3274: loss 0.10701215267181396\n",
      "batch 3275: loss 0.1411248743534088\n",
      "batch 3276: loss 0.10764321684837341\n",
      "batch 3277: loss 0.03799421340227127\n",
      "batch 3278: loss 0.12026940286159515\n",
      "batch 3279: loss 0.07972516864538193\n",
      "batch 3280: loss 0.14184463024139404\n",
      "batch 3281: loss 0.2503931224346161\n",
      "batch 3282: loss 0.07694536447525024\n",
      "batch 3283: loss 0.08074703067541122\n",
      "batch 3284: loss 0.10399995744228363\n",
      "batch 3285: loss 0.3120211958885193\n",
      "batch 3286: loss 0.049308761954307556\n",
      "batch 3287: loss 0.0393085740506649\n",
      "batch 3288: loss 0.06877852976322174\n",
      "batch 3289: loss 0.06420285999774933\n",
      "batch 3290: loss 0.03566984087228775\n",
      "batch 3291: loss 0.05670659989118576\n",
      "batch 3292: loss 0.07242314517498016\n",
      "batch 3293: loss 0.08330462127923965\n",
      "batch 3294: loss 0.16590584814548492\n",
      "batch 3295: loss 0.03710911422967911\n",
      "batch 3296: loss 0.1172214075922966\n",
      "batch 3297: loss 0.10415062308311462\n",
      "batch 3298: loss 0.18183070421218872\n",
      "batch 3299: loss 0.15357688069343567\n",
      "batch 3300: loss 0.13410726189613342\n",
      "batch 3301: loss 0.061717767268419266\n",
      "batch 3302: loss 0.061191074550151825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3303: loss 0.1721855252981186\n",
      "batch 3304: loss 0.27314823865890503\n",
      "batch 3305: loss 0.1020222157239914\n",
      "batch 3306: loss 0.013486032374203205\n",
      "batch 3307: loss 0.2241886705160141\n",
      "batch 3308: loss 0.04375320300459862\n",
      "batch 3309: loss 0.04613880068063736\n",
      "batch 3310: loss 0.08755498379468918\n",
      "batch 3311: loss 0.05024833604693413\n",
      "batch 3312: loss 0.1210804432630539\n",
      "batch 3313: loss 0.0444004200398922\n",
      "batch 3314: loss 0.047660358250141144\n",
      "batch 3315: loss 0.0679621547460556\n",
      "batch 3316: loss 0.03569868206977844\n",
      "batch 3317: loss 0.03385927155613899\n",
      "batch 3318: loss 0.1328859180212021\n",
      "batch 3319: loss 0.08034559339284897\n",
      "batch 3320: loss 0.09201285988092422\n",
      "batch 3321: loss 0.13011273741722107\n",
      "batch 3322: loss 0.055712562054395676\n",
      "batch 3323: loss 0.04406911879777908\n",
      "batch 3324: loss 0.11436714231967926\n",
      "batch 3325: loss 0.04697142541408539\n",
      "batch 3326: loss 0.1537514477968216\n",
      "batch 3327: loss 0.056993741542100906\n",
      "batch 3328: loss 0.18270649015903473\n",
      "batch 3329: loss 0.11109789460897446\n",
      "batch 3330: loss 0.03586616739630699\n",
      "batch 3331: loss 0.053694382309913635\n",
      "batch 3332: loss 0.0452566035091877\n",
      "batch 3333: loss 0.11410161107778549\n",
      "batch 3334: loss 0.026385299861431122\n",
      "batch 3335: loss 0.14754949510097504\n",
      "batch 3336: loss 0.03289897367358208\n",
      "batch 3337: loss 0.13679571449756622\n",
      "batch 3338: loss 0.03277190029621124\n",
      "batch 3339: loss 0.06654391437768936\n",
      "batch 3340: loss 0.09877946972846985\n",
      "batch 3341: loss 0.12220212817192078\n",
      "batch 3342: loss 0.07462923973798752\n",
      "batch 3343: loss 0.05254463478922844\n",
      "batch 3344: loss 0.19638152420520782\n",
      "batch 3345: loss 0.01951667293906212\n",
      "batch 3346: loss 0.04101524129509926\n",
      "batch 3347: loss 0.09769432991743088\n",
      "batch 3348: loss 0.03856881707906723\n",
      "batch 3349: loss 0.02096078358590603\n",
      "batch 3350: loss 0.09683007001876831\n",
      "batch 3351: loss 0.06045951321721077\n",
      "batch 3352: loss 0.1534646898508072\n",
      "batch 3353: loss 0.08181431889533997\n",
      "batch 3354: loss 0.029308917000889778\n",
      "batch 3355: loss 0.08194835484027863\n",
      "batch 3356: loss 0.04270976781845093\n",
      "batch 3357: loss 0.03204001113772392\n",
      "batch 3358: loss 0.026828225702047348\n",
      "batch 3359: loss 0.0293108057230711\n",
      "batch 3360: loss 0.05318760871887207\n",
      "batch 3361: loss 0.08173291385173798\n",
      "batch 3362: loss 0.0755239874124527\n",
      "batch 3363: loss 0.15893946588039398\n",
      "batch 3364: loss 0.04568401724100113\n",
      "batch 3365: loss 0.1723089963197708\n",
      "batch 3366: loss 0.05029001459479332\n",
      "batch 3367: loss 0.1127861738204956\n",
      "batch 3368: loss 0.0479263961315155\n",
      "batch 3369: loss 0.20246970653533936\n",
      "batch 3370: loss 0.1710299253463745\n",
      "batch 3371: loss 0.03688923642039299\n",
      "batch 3372: loss 0.022997448220849037\n",
      "batch 3373: loss 0.047323744744062424\n",
      "batch 3374: loss 0.10485831648111343\n",
      "batch 3375: loss 0.023341093212366104\n",
      "batch 3376: loss 0.06156042590737343\n",
      "batch 3377: loss 0.14758484065532684\n",
      "batch 3378: loss 0.0452166348695755\n",
      "batch 3379: loss 0.03731584921479225\n",
      "batch 3380: loss 0.026769230142235756\n",
      "batch 3381: loss 0.12585307657718658\n",
      "batch 3382: loss 0.06214958056807518\n",
      "batch 3383: loss 0.038644541054964066\n",
      "batch 3384: loss 0.10643190145492554\n",
      "batch 3385: loss 0.01422383077442646\n",
      "batch 3386: loss 0.05939750373363495\n",
      "batch 3387: loss 0.04374244064092636\n",
      "batch 3388: loss 0.18314778804779053\n",
      "batch 3389: loss 0.019806472584605217\n",
      "batch 3390: loss 0.022088808938860893\n",
      "batch 3391: loss 0.03731629624962807\n",
      "batch 3392: loss 0.05796976760029793\n",
      "batch 3393: loss 0.05720410868525505\n",
      "batch 3394: loss 0.11064765602350235\n",
      "batch 3395: loss 0.06478574872016907\n",
      "batch 3396: loss 0.1423925757408142\n",
      "batch 3397: loss 0.041834086179733276\n",
      "batch 3398: loss 0.10032038390636444\n",
      "batch 3399: loss 0.09518498182296753\n",
      "batch 3400: loss 0.06172974780201912\n",
      "batch 3401: loss 0.026896513998508453\n",
      "batch 3402: loss 0.10918830335140228\n",
      "batch 3403: loss 0.10145089775323868\n",
      "batch 3404: loss 0.05590124800801277\n",
      "batch 3405: loss 0.08620605617761612\n",
      "batch 3406: loss 0.05232352018356323\n",
      "batch 3407: loss 0.12446042895317078\n",
      "batch 3408: loss 0.10566964745521545\n",
      "batch 3409: loss 0.015457144938409328\n",
      "batch 3410: loss 0.026615837588906288\n",
      "batch 3411: loss 0.19258573651313782\n",
      "batch 3412: loss 0.13812249898910522\n",
      "batch 3413: loss 0.06556426733732224\n",
      "batch 3414: loss 0.03887774050235748\n",
      "batch 3415: loss 0.13213643431663513\n",
      "batch 3416: loss 0.15102975070476532\n",
      "batch 3417: loss 0.06833826005458832\n",
      "batch 3418: loss 0.011594535782933235\n",
      "batch 3419: loss 0.07259424775838852\n",
      "batch 3420: loss 0.09115065634250641\n",
      "batch 3421: loss 0.018510418012738228\n",
      "batch 3422: loss 0.06200939416885376\n",
      "batch 3423: loss 0.0349188856780529\n",
      "batch 3424: loss 0.02710769511759281\n",
      "batch 3425: loss 0.04412657022476196\n",
      "batch 3426: loss 0.17588426172733307\n",
      "batch 3427: loss 0.010847662575542927\n",
      "batch 3428: loss 0.08575700223445892\n",
      "batch 3429: loss 0.027070676907896996\n",
      "batch 3430: loss 0.07549650222063065\n",
      "batch 3431: loss 0.08732235431671143\n",
      "batch 3432: loss 0.0928836241364479\n",
      "batch 3433: loss 0.03807700052857399\n",
      "batch 3434: loss 0.08042550832033157\n",
      "batch 3435: loss 0.14105914533138275\n",
      "batch 3436: loss 0.03205174580216408\n",
      "batch 3437: loss 0.05846186354756355\n",
      "batch 3438: loss 0.014643696136772633\n",
      "batch 3439: loss 0.13213558495044708\n",
      "batch 3440: loss 0.0239800326526165\n",
      "batch 3441: loss 0.08673403412103653\n",
      "batch 3442: loss 0.14677821099758148\n",
      "batch 3443: loss 0.050583772361278534\n",
      "batch 3444: loss 0.03536602854728699\n",
      "batch 3445: loss 0.20121264457702637\n",
      "batch 3446: loss 0.09147855639457703\n",
      "batch 3447: loss 0.09234417974948883\n",
      "batch 3448: loss 0.21279487013816833\n",
      "batch 3449: loss 0.1441401094198227\n",
      "batch 3450: loss 0.1435065120458603\n",
      "batch 3451: loss 0.05782899633049965\n",
      "batch 3452: loss 0.2551990747451782\n",
      "batch 3453: loss 0.045250892639160156\n",
      "batch 3454: loss 0.07332410663366318\n",
      "batch 3455: loss 0.016857147216796875\n",
      "batch 3456: loss 0.16823771595954895\n",
      "batch 3457: loss 0.05163323134183884\n",
      "batch 3458: loss 0.07218276709318161\n",
      "batch 3459: loss 0.06350919604301453\n",
      "batch 3460: loss 0.21365098655223846\n",
      "batch 3461: loss 0.06963013857603073\n",
      "batch 3462: loss 0.06249640882015228\n",
      "batch 3463: loss 0.05531301721930504\n",
      "batch 3464: loss 0.09829286485910416\n",
      "batch 3465: loss 0.020198049023747444\n",
      "batch 3466: loss 0.03324373811483383\n",
      "batch 3467: loss 0.0590384416282177\n",
      "batch 3468: loss 0.05263867229223251\n",
      "batch 3469: loss 0.0506669320166111\n",
      "batch 3470: loss 0.04438585042953491\n",
      "batch 3471: loss 0.13417769968509674\n",
      "batch 3472: loss 0.12378165125846863\n",
      "batch 3473: loss 0.04238009452819824\n",
      "batch 3474: loss 0.13607358932495117\n",
      "batch 3475: loss 0.26238784193992615\n",
      "batch 3476: loss 0.03869020938873291\n",
      "batch 3477: loss 0.013518325053155422\n",
      "batch 3478: loss 0.11343593150377274\n",
      "batch 3479: loss 0.1417882889509201\n",
      "batch 3480: loss 0.26041755080223083\n",
      "batch 3481: loss 0.04441610351204872\n",
      "batch 3482: loss 0.19676291942596436\n",
      "batch 3483: loss 0.16158829629421234\n",
      "batch 3484: loss 0.06404581665992737\n",
      "batch 3485: loss 0.06281580030918121\n",
      "batch 3486: loss 0.19438014924526215\n",
      "batch 3487: loss 0.035671576857566833\n",
      "batch 3488: loss 0.051787953823804855\n",
      "batch 3489: loss 0.09031210839748383\n",
      "batch 3490: loss 0.14317424595355988\n",
      "batch 3491: loss 0.18342097103595734\n",
      "batch 3492: loss 0.224043607711792\n",
      "batch 3493: loss 0.05892013758420944\n",
      "batch 3494: loss 0.08623945713043213\n",
      "batch 3495: loss 0.0764300599694252\n",
      "batch 3496: loss 0.055145904421806335\n",
      "batch 3497: loss 0.0416639968752861\n",
      "batch 3498: loss 0.10660172253847122\n",
      "batch 3499: loss 0.16630691289901733\n",
      "batch 3500: loss 0.12674294412136078\n",
      "batch 3501: loss 0.3235616683959961\n",
      "batch 3502: loss 0.09900474548339844\n",
      "batch 3503: loss 0.07660983502864838\n",
      "batch 3504: loss 0.17008714377880096\n",
      "batch 3505: loss 0.0677730143070221\n",
      "batch 3506: loss 0.029592689126729965\n",
      "batch 3507: loss 0.08903352171182632\n",
      "batch 3508: loss 0.16832946240901947\n",
      "batch 3509: loss 0.09318363666534424\n",
      "batch 3510: loss 0.020746834576129913\n",
      "batch 3511: loss 0.06772278994321823\n",
      "batch 3512: loss 0.19897495210170746\n",
      "batch 3513: loss 0.012502599507570267\n",
      "batch 3514: loss 0.05168258398771286\n",
      "batch 3515: loss 0.07423344254493713\n",
      "batch 3516: loss 0.03124942258000374\n",
      "batch 3517: loss 0.2085929960012436\n",
      "batch 3518: loss 0.07028280198574066\n",
      "batch 3519: loss 0.04881275072693825\n",
      "batch 3520: loss 0.11785418540239334\n",
      "batch 3521: loss 0.01826966181397438\n",
      "batch 3522: loss 0.11309674382209778\n",
      "batch 3523: loss 0.0989425852894783\n",
      "batch 3524: loss 0.022963695228099823\n",
      "batch 3525: loss 0.18556328117847443\n",
      "batch 3526: loss 0.10565152764320374\n",
      "batch 3527: loss 0.09758850187063217\n",
      "batch 3528: loss 0.06430688500404358\n",
      "batch 3529: loss 0.22279000282287598\n",
      "batch 3530: loss 0.1721074879169464\n",
      "batch 3531: loss 0.0324224978685379\n",
      "batch 3532: loss 0.19634507596492767\n",
      "batch 3533: loss 0.17641764879226685\n",
      "batch 3534: loss 0.08566632866859436\n",
      "batch 3535: loss 0.04155518487095833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3536: loss 0.09453058242797852\n",
      "batch 3537: loss 0.0641007125377655\n",
      "batch 3538: loss 0.027202052995562553\n",
      "batch 3539: loss 0.07875315845012665\n",
      "batch 3540: loss 0.12689760327339172\n",
      "batch 3541: loss 0.1135612428188324\n",
      "batch 3542: loss 0.01910015381872654\n",
      "batch 3543: loss 0.07078294456005096\n",
      "batch 3544: loss 0.033393606543540955\n",
      "batch 3545: loss 0.143934428691864\n",
      "batch 3546: loss 0.030366849154233932\n",
      "batch 3547: loss 0.06180335953831673\n",
      "batch 3548: loss 0.14781661331653595\n",
      "batch 3549: loss 0.03899306058883667\n",
      "batch 3550: loss 0.07014326006174088\n",
      "batch 3551: loss 0.0766938254237175\n",
      "batch 3552: loss 0.11689906567335129\n",
      "batch 3553: loss 0.12726755440235138\n",
      "batch 3554: loss 0.04892101138830185\n",
      "batch 3555: loss 0.031354859471321106\n",
      "batch 3556: loss 0.1495324820280075\n",
      "batch 3557: loss 0.14865702390670776\n",
      "batch 3558: loss 0.05133343115448952\n",
      "batch 3559: loss 0.20719100534915924\n",
      "batch 3560: loss 0.06184220314025879\n",
      "batch 3561: loss 0.07600609958171844\n",
      "batch 3562: loss 0.05306467041373253\n",
      "batch 3563: loss 0.033618539571762085\n",
      "batch 3564: loss 0.07586849480867386\n",
      "batch 3565: loss 0.056131284683942795\n",
      "batch 3566: loss 0.12477268278598785\n",
      "batch 3567: loss 0.12466036528348923\n",
      "batch 3568: loss 0.14633120596408844\n",
      "batch 3569: loss 0.052459463477134705\n",
      "batch 3570: loss 0.06301941722631454\n",
      "batch 3571: loss 0.1727847307920456\n",
      "batch 3572: loss 0.051997870206832886\n",
      "batch 3573: loss 0.025758594274520874\n",
      "batch 3574: loss 0.01787991262972355\n",
      "batch 3575: loss 0.05274355784058571\n",
      "batch 3576: loss 0.020467283204197884\n",
      "batch 3577: loss 0.03920486941933632\n",
      "batch 3578: loss 0.07349301874637604\n",
      "batch 3579: loss 0.05362165719270706\n",
      "batch 3580: loss 0.06005376577377319\n",
      "batch 3581: loss 0.1343732327222824\n",
      "batch 3582: loss 0.02079356089234352\n",
      "batch 3583: loss 0.022788265720009804\n",
      "batch 3584: loss 0.12059790641069412\n",
      "batch 3585: loss 0.054436974227428436\n",
      "batch 3586: loss 0.13729919493198395\n",
      "batch 3587: loss 0.02568654716014862\n",
      "batch 3588: loss 0.19492416083812714\n",
      "batch 3589: loss 0.06590893119573593\n",
      "batch 3590: loss 0.06953965127468109\n",
      "batch 3591: loss 0.2454325258731842\n",
      "batch 3592: loss 0.11366592347621918\n",
      "batch 3593: loss 0.10621839016675949\n",
      "batch 3594: loss 0.0370807908475399\n",
      "batch 3595: loss 0.03109057806432247\n",
      "batch 3596: loss 0.08992862701416016\n",
      "batch 3597: loss 0.17053958773612976\n",
      "batch 3598: loss 0.09617312997579575\n",
      "batch 3599: loss 0.06331509351730347\n",
      "batch 3600: loss 0.07251688838005066\n",
      "batch 3601: loss 0.03681597113609314\n",
      "batch 3602: loss 0.0436926931142807\n",
      "batch 3603: loss 0.031105827540159225\n",
      "batch 3604: loss 0.02697829157114029\n",
      "batch 3605: loss 0.04359501227736473\n",
      "batch 3606: loss 0.09062178432941437\n",
      "batch 3607: loss 0.20842549204826355\n",
      "batch 3608: loss 0.02677031420171261\n",
      "batch 3609: loss 0.04913029447197914\n",
      "batch 3610: loss 0.00959173496812582\n",
      "batch 3611: loss 0.049497563391923904\n",
      "batch 3612: loss 0.04105154797434807\n",
      "batch 3613: loss 0.029771432280540466\n",
      "batch 3614: loss 0.12241094559431076\n",
      "batch 3615: loss 0.038057658821344376\n",
      "batch 3616: loss 0.01612457074224949\n",
      "batch 3617: loss 0.0827820748090744\n",
      "batch 3618: loss 0.20793263614177704\n",
      "batch 3619: loss 0.0331806056201458\n",
      "batch 3620: loss 0.10231117159128189\n",
      "batch 3621: loss 0.06454059481620789\n",
      "batch 3622: loss 0.02353895641863346\n",
      "batch 3623: loss 0.03928953409194946\n",
      "batch 3624: loss 0.08175233006477356\n",
      "batch 3625: loss 0.04509948566555977\n",
      "batch 3626: loss 0.04670526087284088\n",
      "batch 3627: loss 0.30314818024635315\n",
      "batch 3628: loss 0.08395791053771973\n",
      "batch 3629: loss 0.1794581115245819\n",
      "batch 3630: loss 0.03871540725231171\n",
      "batch 3631: loss 0.06372763216495514\n",
      "batch 3632: loss 0.04341190308332443\n",
      "batch 3633: loss 0.04454604163765907\n",
      "batch 3634: loss 0.07309389114379883\n",
      "batch 3635: loss 0.0765000730752945\n",
      "batch 3636: loss 0.17301028966903687\n",
      "batch 3637: loss 0.02451779507100582\n",
      "batch 3638: loss 0.07716086506843567\n",
      "batch 3639: loss 0.23799143731594086\n",
      "batch 3640: loss 0.10861190408468246\n",
      "batch 3641: loss 0.023832494392991066\n",
      "batch 3642: loss 0.1582251489162445\n",
      "batch 3643: loss 0.13905981183052063\n",
      "batch 3644: loss 0.05787702277302742\n",
      "batch 3645: loss 0.02050810493528843\n",
      "batch 3646: loss 0.10483743250370026\n",
      "batch 3647: loss 0.17080268263816833\n",
      "batch 3648: loss 0.09682772308588028\n",
      "batch 3649: loss 0.11788906157016754\n",
      "batch 3650: loss 0.12149892747402191\n",
      "batch 3651: loss 0.05642683058977127\n",
      "batch 3652: loss 0.037039242684841156\n",
      "batch 3653: loss 0.04873671755194664\n",
      "batch 3654: loss 0.119912289083004\n",
      "batch 3655: loss 0.02535327337682247\n",
      "batch 3656: loss 0.025007138028740883\n",
      "batch 3657: loss 0.021736647933721542\n",
      "batch 3658: loss 0.13672827184200287\n",
      "batch 3659: loss 0.05295490473508835\n",
      "batch 3660: loss 0.023790592327713966\n",
      "batch 3661: loss 0.06956738978624344\n",
      "batch 3662: loss 0.03121590055525303\n",
      "batch 3663: loss 0.039183974266052246\n",
      "batch 3664: loss 0.04688085988163948\n",
      "batch 3665: loss 0.013937436044216156\n",
      "batch 3666: loss 0.0337543748319149\n",
      "batch 3667: loss 0.11775106191635132\n",
      "batch 3668: loss 0.14824333786964417\n",
      "batch 3669: loss 0.004077308811247349\n",
      "batch 3670: loss 0.020539745688438416\n",
      "batch 3671: loss 0.037873685359954834\n",
      "batch 3672: loss 0.024014510214328766\n",
      "batch 3673: loss 0.09599722921848297\n",
      "batch 3674: loss 0.011974813416600227\n",
      "batch 3675: loss 0.16584888100624084\n",
      "batch 3676: loss 0.04216088727116585\n",
      "batch 3677: loss 0.11777224391698837\n",
      "batch 3678: loss 0.03865671530365944\n",
      "batch 3679: loss 0.05208840221166611\n",
      "batch 3680: loss 0.15261825919151306\n",
      "batch 3681: loss 0.06231607869267464\n",
      "batch 3682: loss 0.039543427526950836\n",
      "batch 3683: loss 0.13670213520526886\n",
      "batch 3684: loss 0.12515103816986084\n",
      "batch 3685: loss 0.052207645028829575\n",
      "batch 3686: loss 0.021995913237333298\n",
      "batch 3687: loss 0.03048383630812168\n",
      "batch 3688: loss 0.10167558491230011\n",
      "batch 3689: loss 0.05643501132726669\n",
      "batch 3690: loss 0.1332312673330307\n",
      "batch 3691: loss 0.05649253726005554\n",
      "batch 3692: loss 0.08022391051054001\n",
      "batch 3693: loss 0.06475720554590225\n",
      "batch 3694: loss 0.12668196856975555\n",
      "batch 3695: loss 0.015508245676755905\n",
      "batch 3696: loss 0.12732456624507904\n",
      "batch 3697: loss 0.057395827025175095\n",
      "batch 3698: loss 0.08257696032524109\n",
      "batch 3699: loss 0.10797624289989471\n",
      "batch 3700: loss 0.15300822257995605\n",
      "batch 3701: loss 0.01862390898168087\n",
      "batch 3702: loss 0.021684223785996437\n",
      "batch 3703: loss 0.11505604535341263\n",
      "batch 3704: loss 0.07192060351371765\n",
      "batch 3705: loss 0.045929908752441406\n",
      "batch 3706: loss 0.020491210743784904\n",
      "batch 3707: loss 0.027237381786108017\n",
      "batch 3708: loss 0.08018218725919724\n",
      "batch 3709: loss 0.04011237993836403\n",
      "batch 3710: loss 0.059771183878183365\n",
      "batch 3711: loss 0.06013384088873863\n",
      "batch 3712: loss 0.10419877618551254\n",
      "batch 3713: loss 0.10081151872873306\n",
      "batch 3714: loss 0.0495600588619709\n",
      "batch 3715: loss 0.0634811520576477\n",
      "batch 3716: loss 0.10926087945699692\n",
      "batch 3717: loss 0.226356640458107\n",
      "batch 3718: loss 0.28472939133644104\n",
      "batch 3719: loss 0.06840723007917404\n",
      "batch 3720: loss 0.03776952624320984\n",
      "batch 3721: loss 0.07474283874034882\n",
      "batch 3722: loss 0.14067891240119934\n",
      "batch 3723: loss 0.2635558843612671\n",
      "batch 3724: loss 0.11558639258146286\n",
      "batch 3725: loss 0.03377543017268181\n",
      "batch 3726: loss 0.14590393006801605\n",
      "batch 3727: loss 0.047737471759319305\n",
      "batch 3728: loss 0.03552587330341339\n",
      "batch 3729: loss 0.04181067273020744\n",
      "batch 3730: loss 0.01994493044912815\n",
      "batch 3731: loss 0.1924828290939331\n",
      "batch 3732: loss 0.16839885711669922\n",
      "batch 3733: loss 0.0788118913769722\n",
      "batch 3734: loss 0.2625575065612793\n",
      "batch 3735: loss 0.24143436551094055\n",
      "batch 3736: loss 0.1763320118188858\n",
      "batch 3737: loss 0.06887245923280716\n",
      "batch 3738: loss 0.06081951782107353\n",
      "batch 3739: loss 0.01496911235153675\n",
      "batch 3740: loss 0.07849801331758499\n",
      "batch 3741: loss 0.11211412400007248\n",
      "batch 3742: loss 0.20691269636154175\n",
      "batch 3743: loss 0.0840163305401802\n",
      "batch 3744: loss 0.08847251534461975\n",
      "batch 3745: loss 0.07924048602581024\n",
      "batch 3746: loss 0.028939861804246902\n",
      "batch 3747: loss 0.0367349274456501\n",
      "batch 3748: loss 0.03288642317056656\n",
      "batch 3749: loss 0.03753986209630966\n",
      "batch 3750: loss 0.027473313733935356\n",
      "batch 3751: loss 0.11061103641986847\n",
      "batch 3752: loss 0.048625726252794266\n",
      "batch 3753: loss 0.13457880914211273\n",
      "batch 3754: loss 0.07605839520692825\n",
      "batch 3755: loss 0.03757922351360321\n",
      "batch 3756: loss 0.044028010219335556\n",
      "batch 3757: loss 0.07629043608903885\n",
      "batch 3758: loss 0.023538105189800262\n",
      "batch 3759: loss 0.013792094774544239\n",
      "batch 3760: loss 0.045835960656404495\n",
      "batch 3761: loss 0.012047420255839825\n",
      "batch 3762: loss 0.07815273851156235\n",
      "batch 3763: loss 0.09642009437084198\n",
      "batch 3764: loss 0.056905362755060196\n",
      "batch 3765: loss 0.21376483142375946\n",
      "batch 3766: loss 0.10093989223241806\n",
      "batch 3767: loss 0.029231049120426178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3768: loss 0.2540540397167206\n",
      "batch 3769: loss 0.15654203295707703\n",
      "batch 3770: loss 0.05851902812719345\n",
      "batch 3771: loss 0.13186438381671906\n",
      "batch 3772: loss 0.14092646539211273\n",
      "batch 3773: loss 0.06293380260467529\n",
      "batch 3774: loss 0.022629400715231895\n",
      "batch 3775: loss 0.07162503898143768\n",
      "batch 3776: loss 0.06273949146270752\n",
      "batch 3777: loss 0.0838392898440361\n",
      "batch 3778: loss 0.04195934534072876\n",
      "batch 3779: loss 0.007529278751462698\n",
      "batch 3780: loss 0.08189790695905685\n",
      "batch 3781: loss 0.025563962757587433\n",
      "batch 3782: loss 0.13351964950561523\n",
      "batch 3783: loss 0.057307250797748566\n",
      "batch 3784: loss 0.12182866036891937\n",
      "batch 3785: loss 0.09130673855543137\n",
      "batch 3786: loss 0.02286677621304989\n",
      "batch 3787: loss 0.04691353812813759\n",
      "batch 3788: loss 0.18000978231430054\n",
      "batch 3789: loss 0.03255210444331169\n",
      "batch 3790: loss 0.05179348960518837\n",
      "batch 3791: loss 0.030574802309274673\n",
      "batch 3792: loss 0.08946559578180313\n",
      "batch 3793: loss 0.13809223473072052\n",
      "batch 3794: loss 0.15778562426567078\n",
      "batch 3795: loss 0.11130153387784958\n",
      "batch 3796: loss 0.019014626741409302\n",
      "batch 3797: loss 0.06439422816038132\n",
      "batch 3798: loss 0.10904565453529358\n",
      "batch 3799: loss 0.1357523649930954\n",
      "batch 3800: loss 0.1148206889629364\n",
      "batch 3801: loss 0.07380672544240952\n",
      "batch 3802: loss 0.12140443176031113\n",
      "batch 3803: loss 0.13861200213432312\n",
      "batch 3804: loss 0.10380008816719055\n",
      "batch 3805: loss 0.06941504776477814\n",
      "batch 3806: loss 0.13952624797821045\n",
      "batch 3807: loss 0.12390852719545364\n",
      "batch 3808: loss 0.022296883165836334\n",
      "batch 3809: loss 0.1253686249256134\n",
      "batch 3810: loss 0.028826704248785973\n",
      "batch 3811: loss 0.016986675560474396\n",
      "batch 3812: loss 0.07340352982282639\n",
      "batch 3813: loss 0.041214726865291595\n",
      "batch 3814: loss 0.06698956340551376\n",
      "batch 3815: loss 0.11630737781524658\n",
      "batch 3816: loss 0.22153612971305847\n",
      "batch 3817: loss 0.21236161887645721\n",
      "batch 3818: loss 0.14352549612522125\n",
      "batch 3819: loss 0.024263259023427963\n",
      "batch 3820: loss 0.12947280704975128\n",
      "batch 3821: loss 0.04812604933977127\n",
      "batch 3822: loss 0.05792762711644173\n",
      "batch 3823: loss 0.030518826097249985\n",
      "batch 3824: loss 0.044356219470500946\n",
      "batch 3825: loss 0.17049640417099\n",
      "batch 3826: loss 0.03606436774134636\n",
      "batch 3827: loss 0.037047259509563446\n",
      "batch 3828: loss 0.00871273409575224\n",
      "batch 3829: loss 0.06675803661346436\n",
      "batch 3830: loss 0.12344542890787125\n",
      "batch 3831: loss 0.08724240958690643\n",
      "batch 3832: loss 0.07284168154001236\n",
      "batch 3833: loss 0.07441981136798859\n",
      "batch 3834: loss 0.17984849214553833\n",
      "batch 3835: loss 0.181721031665802\n",
      "batch 3836: loss 0.04612867161631584\n",
      "batch 3837: loss 0.01987096481025219\n",
      "batch 3838: loss 0.16248062252998352\n",
      "batch 3839: loss 0.06938420981168747\n",
      "batch 3840: loss 0.021304901689291\n",
      "batch 3841: loss 0.06413909047842026\n",
      "batch 3842: loss 0.07902753353118896\n",
      "batch 3843: loss 0.0598001554608345\n",
      "batch 3844: loss 0.05385413393378258\n",
      "batch 3845: loss 0.015271013602614403\n",
      "batch 3846: loss 0.09459980577230453\n",
      "batch 3847: loss 0.10980316996574402\n",
      "batch 3848: loss 0.053100474178791046\n",
      "batch 3849: loss 0.11527824401855469\n",
      "batch 3850: loss 0.0391957089304924\n",
      "batch 3851: loss 0.18288002908229828\n",
      "batch 3852: loss 0.05038432776927948\n",
      "batch 3853: loss 0.07956717908382416\n",
      "batch 3854: loss 0.07780903577804565\n",
      "batch 3855: loss 0.03781219944357872\n",
      "batch 3856: loss 0.04571984335780144\n",
      "batch 3857: loss 0.10936284810304642\n",
      "batch 3858: loss 0.03016524203121662\n",
      "batch 3859: loss 0.13850510120391846\n",
      "batch 3860: loss 0.0940605029463768\n",
      "batch 3861: loss 0.03197203204035759\n",
      "batch 3862: loss 0.08430992811918259\n",
      "batch 3863: loss 0.049985188990831375\n",
      "batch 3864: loss 0.08999409526586533\n",
      "batch 3865: loss 0.022837016731500626\n",
      "batch 3866: loss 0.03425459563732147\n",
      "batch 3867: loss 0.0456501767039299\n",
      "batch 3868: loss 0.0496629998087883\n",
      "batch 3869: loss 0.023532923310995102\n",
      "batch 3870: loss 0.29036352038383484\n",
      "batch 3871: loss 0.019427210092544556\n",
      "batch 3872: loss 0.018262891098856926\n",
      "batch 3873: loss 0.05383146181702614\n",
      "batch 3874: loss 0.02257126197218895\n",
      "batch 3875: loss 0.05611065775156021\n",
      "batch 3876: loss 0.011884694918990135\n",
      "batch 3877: loss 0.03021160140633583\n",
      "batch 3878: loss 0.06623147428035736\n",
      "batch 3879: loss 0.07603801786899567\n",
      "batch 3880: loss 0.03847651928663254\n",
      "batch 3881: loss 0.08394306898117065\n",
      "batch 3882: loss 0.049765437841415405\n",
      "batch 3883: loss 0.05875921994447708\n",
      "batch 3884: loss 0.02210979349911213\n",
      "batch 3885: loss 0.02784224972128868\n",
      "batch 3886: loss 0.09034828096628189\n",
      "batch 3887: loss 0.025832099840044975\n",
      "batch 3888: loss 0.04434022679924965\n",
      "batch 3889: loss 0.0719270408153534\n",
      "batch 3890: loss 0.04357210919260979\n",
      "batch 3891: loss 0.022784151136875153\n",
      "batch 3892: loss 0.012018491514027119\n",
      "batch 3893: loss 0.01598498225212097\n",
      "batch 3894: loss 0.12120892852544785\n",
      "batch 3895: loss 0.013526049442589283\n",
      "batch 3896: loss 0.04982176795601845\n",
      "batch 3897: loss 0.06908246874809265\n",
      "batch 3898: loss 0.06233476847410202\n",
      "batch 3899: loss 0.14370642602443695\n",
      "batch 3900: loss 0.03212035074830055\n",
      "batch 3901: loss 0.021894292905926704\n",
      "batch 3902: loss 0.01731630228459835\n",
      "batch 3903: loss 0.17426970601081848\n",
      "batch 3904: loss 0.06958668678998947\n",
      "batch 3905: loss 0.34242957830429077\n",
      "batch 3906: loss 0.042708855122327805\n",
      "batch 3907: loss 0.02987506240606308\n",
      "batch 3908: loss 0.015847546979784966\n",
      "batch 3909: loss 0.05164334177970886\n",
      "batch 3910: loss 0.02628479339182377\n",
      "batch 3911: loss 0.03130646049976349\n",
      "batch 3912: loss 0.0652398020029068\n",
      "batch 3913: loss 0.0219115037471056\n",
      "batch 3914: loss 0.3818622827529907\n",
      "batch 3915: loss 0.0770111083984375\n",
      "batch 3916: loss 0.013501500710844994\n",
      "batch 3917: loss 0.12581750750541687\n",
      "batch 3918: loss 0.038379158824682236\n",
      "batch 3919: loss 0.22634923458099365\n",
      "batch 3920: loss 0.07509157061576843\n",
      "batch 3921: loss 0.05245934799313545\n",
      "batch 3922: loss 0.08411631733179092\n",
      "batch 3923: loss 0.09093932807445526\n",
      "batch 3924: loss 0.023431312292814255\n",
      "batch 3925: loss 0.07527682930231094\n",
      "batch 3926: loss 0.032178785651922226\n",
      "batch 3927: loss 0.0937810018658638\n",
      "batch 3928: loss 0.05327453464269638\n",
      "batch 3929: loss 0.039362695068120956\n",
      "batch 3930: loss 0.035916540771722794\n",
      "batch 3931: loss 0.12544821202754974\n",
      "batch 3932: loss 0.0972043052315712\n",
      "batch 3933: loss 0.03883052244782448\n",
      "batch 3934: loss 0.064301997423172\n",
      "batch 3935: loss 0.0869947001338005\n",
      "batch 3936: loss 0.0759224146604538\n",
      "batch 3937: loss 0.02305816113948822\n",
      "batch 3938: loss 0.0742616355419159\n",
      "batch 3939: loss 0.05063144117593765\n",
      "batch 3940: loss 0.014690608717501163\n",
      "batch 3941: loss 0.11546346545219421\n",
      "batch 3942: loss 0.046372946351766586\n",
      "batch 3943: loss 0.10884036123752594\n",
      "batch 3944: loss 0.025574957951903343\n",
      "batch 3945: loss 0.06317301839590073\n",
      "batch 3946: loss 0.04122134670615196\n",
      "batch 3947: loss 0.022666173055768013\n",
      "batch 3948: loss 0.10327738523483276\n",
      "batch 3949: loss 0.08314850926399231\n",
      "batch 3950: loss 0.05581357330083847\n",
      "batch 3951: loss 0.09709464758634567\n",
      "batch 3952: loss 0.1177637055516243\n",
      "batch 3953: loss 0.043130986392498016\n",
      "batch 3954: loss 0.019812362268567085\n",
      "batch 3955: loss 0.03206609562039375\n",
      "batch 3956: loss 0.028184685856103897\n",
      "batch 3957: loss 0.04943572357296944\n",
      "batch 3958: loss 0.08790851384401321\n",
      "batch 3959: loss 0.0653977021574974\n",
      "batch 3960: loss 0.15748153626918793\n",
      "batch 3961: loss 0.091807059943676\n",
      "batch 3962: loss 0.10397231578826904\n",
      "batch 3963: loss 0.13950614631175995\n",
      "batch 3964: loss 0.09621879458427429\n",
      "batch 3965: loss 0.05451303347945213\n",
      "batch 3966: loss 0.14514297246932983\n",
      "batch 3967: loss 0.18167506158351898\n",
      "batch 3968: loss 0.02691792882978916\n",
      "batch 3969: loss 0.06618555635213852\n",
      "batch 3970: loss 0.03934450075030327\n",
      "batch 3971: loss 0.07041526585817337\n",
      "batch 3972: loss 0.10851367563009262\n",
      "batch 3973: loss 0.02321784198284149\n",
      "batch 3974: loss 0.10965956747531891\n",
      "batch 3975: loss 0.09071370959281921\n",
      "batch 3976: loss 0.02359737642109394\n",
      "batch 3977: loss 0.10827655345201492\n",
      "batch 3978: loss 0.14401860535144806\n",
      "batch 3979: loss 0.18295828998088837\n",
      "batch 3980: loss 0.06578747928142548\n",
      "batch 3981: loss 0.014378463849425316\n",
      "batch 3982: loss 0.09828124940395355\n",
      "batch 3983: loss 0.045891888439655304\n",
      "batch 3984: loss 0.008072265423834324\n",
      "batch 3985: loss 0.03643304109573364\n",
      "batch 3986: loss 0.05927435681223869\n",
      "batch 3987: loss 0.162443608045578\n",
      "batch 3988: loss 0.15409687161445618\n",
      "batch 3989: loss 0.06676453351974487\n",
      "batch 3990: loss 0.05042782798409462\n",
      "batch 3991: loss 0.01848079077899456\n",
      "batch 3992: loss 0.04100464656949043\n",
      "batch 3993: loss 0.0339733250439167\n",
      "batch 3994: loss 0.10789670050144196\n",
      "batch 3995: loss 0.06217204034328461\n",
      "batch 3996: loss 0.010319004766643047\n",
      "batch 3997: loss 0.12590399384498596\n",
      "batch 3998: loss 0.013714736327528954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3999: loss 0.009392740204930305\n",
      "batch 4000: loss 0.044879309833049774\n",
      "batch 4001: loss 0.10019142180681229\n",
      "batch 4002: loss 0.07227958738803864\n",
      "batch 4003: loss 0.06500329822301865\n",
      "batch 4004: loss 0.10353606194257736\n",
      "batch 4005: loss 0.11051268130540848\n",
      "batch 4006: loss 0.12731248140335083\n",
      "batch 4007: loss 0.06379308551549911\n",
      "batch 4008: loss 0.019855299964547157\n",
      "batch 4009: loss 0.1292591542005539\n",
      "batch 4010: loss 0.0261918343603611\n",
      "batch 4011: loss 0.027373850345611572\n",
      "batch 4012: loss 0.03949876129627228\n",
      "batch 4013: loss 0.22327342629432678\n",
      "batch 4014: loss 0.04657222330570221\n",
      "batch 4015: loss 0.05603257194161415\n",
      "batch 4016: loss 0.040496814996004105\n",
      "batch 4017: loss 0.03922063112258911\n",
      "batch 4018: loss 0.016838369891047478\n",
      "batch 4019: loss 0.10327206552028656\n",
      "batch 4020: loss 0.04307350143790245\n",
      "batch 4021: loss 0.03405178338289261\n",
      "batch 4022: loss 0.07805048674345016\n",
      "batch 4023: loss 0.20349754393100739\n",
      "batch 4024: loss 0.02473738230764866\n",
      "batch 4025: loss 0.09570280462503433\n",
      "batch 4026: loss 0.042869701981544495\n",
      "batch 4027: loss 0.05478615686297417\n",
      "batch 4028: loss 0.033851321786642075\n",
      "batch 4029: loss 0.09170230478048325\n",
      "batch 4030: loss 0.05601233243942261\n",
      "batch 4031: loss 0.03413742035627365\n",
      "batch 4032: loss 0.07243324816226959\n",
      "batch 4033: loss 0.06200985610485077\n",
      "batch 4034: loss 0.10113455355167389\n",
      "batch 4035: loss 0.07429776340723038\n",
      "batch 4036: loss 0.08949615061283112\n",
      "batch 4037: loss 0.07614397257566452\n",
      "batch 4038: loss 0.05195560306310654\n",
      "batch 4039: loss 0.1534268856048584\n",
      "batch 4040: loss 0.03579128161072731\n",
      "batch 4041: loss 0.03759778290987015\n",
      "batch 4042: loss 0.18090209364891052\n",
      "batch 4043: loss 0.022820016369223595\n",
      "batch 4044: loss 0.06728609651327133\n",
      "batch 4045: loss 0.17863093316555023\n",
      "batch 4046: loss 0.043373093008995056\n",
      "batch 4047: loss 0.1432439535856247\n",
      "batch 4048: loss 0.05885172635316849\n",
      "batch 4049: loss 0.028519243001937866\n",
      "batch 4050: loss 0.05595255643129349\n",
      "batch 4051: loss 0.06910598278045654\n",
      "batch 4052: loss 0.025059960782527924\n",
      "batch 4053: loss 0.06630634516477585\n",
      "batch 4054: loss 0.154296413064003\n",
      "batch 4055: loss 0.021488899365067482\n",
      "batch 4056: loss 0.02601160854101181\n",
      "batch 4057: loss 0.02033965103328228\n",
      "batch 4058: loss 0.038492899388074875\n",
      "batch 4059: loss 0.11725757271051407\n",
      "batch 4060: loss 0.05724838003516197\n",
      "batch 4061: loss 0.05735623091459274\n",
      "batch 4062: loss 0.021448122337460518\n",
      "batch 4063: loss 0.025014931336045265\n",
      "batch 4064: loss 0.05014777183532715\n",
      "batch 4065: loss 0.03379863128066063\n",
      "batch 4066: loss 0.05105804651975632\n",
      "batch 4067: loss 0.015257992781698704\n",
      "batch 4068: loss 0.04393480345606804\n",
      "batch 4069: loss 0.022015633061528206\n",
      "batch 4070: loss 0.012554841116070747\n",
      "batch 4071: loss 0.022612443193793297\n",
      "batch 4072: loss 0.02433941513299942\n",
      "batch 4073: loss 0.13118073344230652\n",
      "batch 4074: loss 0.06139072775840759\n",
      "batch 4075: loss 0.24440139532089233\n",
      "batch 4076: loss 0.018025362864136696\n",
      "batch 4077: loss 0.1102956011891365\n",
      "batch 4078: loss 0.06671981513500214\n",
      "batch 4079: loss 0.09310609847307205\n",
      "batch 4080: loss 0.06377693265676498\n",
      "batch 4081: loss 0.0387241430580616\n",
      "batch 4082: loss 0.09175524860620499\n",
      "batch 4083: loss 0.05367939919233322\n",
      "batch 4084: loss 0.055599238723516464\n",
      "batch 4085: loss 0.017437104135751724\n",
      "batch 4086: loss 0.058791112154722214\n",
      "batch 4087: loss 0.030578402802348137\n",
      "batch 4088: loss 0.04821653664112091\n",
      "batch 4089: loss 0.17417120933532715\n",
      "batch 4090: loss 0.029246114194393158\n",
      "batch 4091: loss 0.05108542740345001\n",
      "batch 4092: loss 0.0751418024301529\n",
      "batch 4093: loss 0.17788100242614746\n",
      "batch 4094: loss 0.05198780074715614\n",
      "batch 4095: loss 0.008558867499232292\n",
      "batch 4096: loss 0.06858954578638077\n",
      "batch 4097: loss 0.04414328560233116\n",
      "batch 4098: loss 0.06681632250547409\n",
      "batch 4099: loss 0.007933317683637142\n",
      "batch 4100: loss 0.1432502567768097\n",
      "batch 4101: loss 0.09892000257968903\n",
      "batch 4102: loss 0.05083201453089714\n",
      "batch 4103: loss 0.03920401632785797\n",
      "batch 4104: loss 0.10150424391031265\n",
      "batch 4105: loss 0.07623973488807678\n",
      "batch 4106: loss 0.14721864461898804\n",
      "batch 4107: loss 0.0482260026037693\n",
      "batch 4108: loss 0.1152312234044075\n",
      "batch 4109: loss 0.05751488730311394\n",
      "batch 4110: loss 0.03574511408805847\n",
      "batch 4111: loss 0.034921932965517044\n",
      "batch 4112: loss 0.12579770386219025\n",
      "batch 4113: loss 0.05326937884092331\n",
      "batch 4114: loss 0.0381462462246418\n",
      "batch 4115: loss 0.019177820533514023\n",
      "batch 4116: loss 0.015986410900950432\n",
      "batch 4117: loss 0.06555967777967453\n",
      "batch 4118: loss 0.0493384450674057\n",
      "batch 4119: loss 0.16810211539268494\n",
      "batch 4120: loss 0.054405681788921356\n",
      "batch 4121: loss 0.013951454311609268\n",
      "batch 4122: loss 0.08968857675790787\n",
      "batch 4123: loss 0.011637268587946892\n",
      "batch 4124: loss 0.017758360132575035\n",
      "batch 4125: loss 0.04010810703039169\n",
      "batch 4126: loss 0.08784390985965729\n",
      "batch 4127: loss 0.01554944273084402\n",
      "batch 4128: loss 0.05098604038357735\n",
      "batch 4129: loss 0.0715436115860939\n",
      "batch 4130: loss 0.030868100002408028\n",
      "batch 4131: loss 0.014729680493474007\n",
      "batch 4132: loss 0.028441771864891052\n",
      "batch 4133: loss 0.08279325067996979\n",
      "batch 4134: loss 0.06850115209817886\n",
      "batch 4135: loss 0.04687049612402916\n",
      "batch 4136: loss 0.06944078952074051\n",
      "batch 4137: loss 0.02491721138358116\n",
      "batch 4138: loss 0.1316717565059662\n",
      "batch 4139: loss 0.05461790785193443\n",
      "batch 4140: loss 0.07375660538673401\n",
      "batch 4141: loss 0.027742713689804077\n",
      "batch 4142: loss 0.03839553892612457\n",
      "batch 4143: loss 0.062074292451143265\n",
      "batch 4144: loss 0.10901252180337906\n",
      "batch 4145: loss 0.1654164046049118\n",
      "batch 4146: loss 0.04566469416022301\n",
      "batch 4147: loss 0.175048366189003\n",
      "batch 4148: loss 0.03928424417972565\n",
      "batch 4149: loss 0.1131984293460846\n",
      "batch 4150: loss 0.0546170137822628\n",
      "batch 4151: loss 0.016932731494307518\n",
      "batch 4152: loss 0.018124748021364212\n",
      "batch 4153: loss 0.11497766524553299\n",
      "batch 4154: loss 0.13022150099277496\n",
      "batch 4155: loss 0.10534755140542984\n",
      "batch 4156: loss 0.2657102942466736\n",
      "batch 4157: loss 0.020987143740057945\n",
      "batch 4158: loss 0.025571994483470917\n",
      "batch 4159: loss 0.06054017320275307\n",
      "batch 4160: loss 0.07039793580770493\n",
      "batch 4161: loss 0.0776376724243164\n",
      "batch 4162: loss 0.05363721773028374\n",
      "batch 4163: loss 0.06519478559494019\n",
      "batch 4164: loss 0.058661021292209625\n",
      "batch 4165: loss 0.1500682532787323\n",
      "batch 4166: loss 0.08755847066640854\n",
      "batch 4167: loss 0.01120135746896267\n",
      "batch 4168: loss 0.11447423696517944\n",
      "batch 4169: loss 0.08686252683401108\n",
      "batch 4170: loss 0.1043940931558609\n",
      "batch 4171: loss 0.10184192657470703\n",
      "batch 4172: loss 0.009068518877029419\n",
      "batch 4173: loss 0.09377084672451019\n",
      "batch 4174: loss 0.03769940882921219\n",
      "batch 4175: loss 0.06055392697453499\n",
      "batch 4176: loss 0.10158788412809372\n",
      "batch 4177: loss 0.01783633418381214\n",
      "batch 4178: loss 0.0772056058049202\n",
      "batch 4179: loss 0.12474534660577774\n",
      "batch 4180: loss 0.11243497580289841\n",
      "batch 4181: loss 0.043043602257966995\n",
      "batch 4182: loss 0.015087594278156757\n",
      "batch 4183: loss 0.08378087729215622\n",
      "batch 4184: loss 0.05880768224596977\n",
      "batch 4185: loss 0.11111816018819809\n",
      "batch 4186: loss 0.025138957425951958\n",
      "batch 4187: loss 0.09239276498556137\n",
      "batch 4188: loss 0.10469699651002884\n",
      "batch 4189: loss 0.21383588016033173\n",
      "batch 4190: loss 0.1416928619146347\n",
      "batch 4191: loss 0.03066832385957241\n",
      "batch 4192: loss 0.033472467213869095\n",
      "batch 4193: loss 0.03663618862628937\n",
      "batch 4194: loss 0.03643249347805977\n",
      "batch 4195: loss 0.05508442595601082\n",
      "batch 4196: loss 0.10148849338293076\n",
      "batch 4197: loss 0.03073088638484478\n",
      "batch 4198: loss 0.12031710147857666\n",
      "batch 4199: loss 0.019956089556217194\n",
      "batch 4200: loss 0.011176404543220997\n",
      "batch 4201: loss 0.03803545981645584\n",
      "batch 4202: loss 0.02141992561519146\n",
      "batch 4203: loss 0.06589531153440475\n",
      "batch 4204: loss 0.04124723747372627\n",
      "batch 4205: loss 0.019894441589713097\n",
      "batch 4206: loss 0.15199293196201324\n",
      "batch 4207: loss 0.0427544042468071\n",
      "batch 4208: loss 0.008391926996409893\n",
      "batch 4209: loss 0.08952870965003967\n",
      "batch 4210: loss 0.07933762669563293\n",
      "batch 4211: loss 0.06677456200122833\n",
      "batch 4212: loss 0.019411887973546982\n",
      "batch 4213: loss 0.13134700059890747\n",
      "batch 4214: loss 0.020353440195322037\n",
      "batch 4215: loss 0.03057991713285446\n",
      "batch 4216: loss 0.17460471391677856\n",
      "batch 4217: loss 0.011904241517186165\n",
      "batch 4218: loss 0.010120073333382607\n",
      "batch 4219: loss 0.1127263605594635\n",
      "batch 4220: loss 0.039293210953474045\n",
      "batch 4221: loss 0.05821690335869789\n",
      "batch 4222: loss 0.020801784470677376\n",
      "batch 4223: loss 0.026665495708584785\n",
      "batch 4224: loss 0.14754560589790344\n",
      "batch 4225: loss 0.12132082879543304\n",
      "batch 4226: loss 0.07663455605506897\n",
      "batch 4227: loss 0.16985076665878296\n",
      "batch 4228: loss 0.043918266892433167\n",
      "batch 4229: loss 0.05904913693666458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4230: loss 0.08226146548986435\n",
      "batch 4231: loss 0.05692882463335991\n",
      "batch 4232: loss 0.09493596106767654\n",
      "batch 4233: loss 0.018580717965960503\n",
      "batch 4234: loss 0.02123429998755455\n",
      "batch 4235: loss 0.05818045139312744\n",
      "batch 4236: loss 0.015826862305402756\n",
      "batch 4237: loss 0.16572332382202148\n",
      "batch 4238: loss 0.05125819146633148\n",
      "batch 4239: loss 0.08622781932353973\n",
      "batch 4240: loss 0.0357387475669384\n",
      "batch 4241: loss 0.07343786209821701\n",
      "batch 4242: loss 0.027255196124315262\n",
      "batch 4243: loss 0.030307907611131668\n",
      "batch 4244: loss 0.03991209343075752\n",
      "batch 4245: loss 0.025164131075143814\n",
      "batch 4246: loss 0.03787998482584953\n",
      "batch 4247: loss 0.013577418401837349\n",
      "batch 4248: loss 0.035869065672159195\n",
      "batch 4249: loss 0.0551343634724617\n",
      "batch 4250: loss 0.023580776527523994\n",
      "batch 4251: loss 0.033320482820272446\n",
      "batch 4252: loss 0.0322171151638031\n",
      "batch 4253: loss 0.04151683300733566\n",
      "batch 4254: loss 0.045548632740974426\n",
      "batch 4255: loss 0.043570756912231445\n",
      "batch 4256: loss 0.044251058250665665\n",
      "batch 4257: loss 0.12630130350589752\n",
      "batch 4258: loss 0.10227642953395844\n",
      "batch 4259: loss 0.0366477370262146\n",
      "batch 4260: loss 0.13723669946193695\n",
      "batch 4261: loss 0.12947070598602295\n",
      "batch 4262: loss 0.06061864644289017\n",
      "batch 4263: loss 0.13494983315467834\n",
      "batch 4264: loss 0.03503120690584183\n",
      "batch 4265: loss 0.20949943363666534\n",
      "batch 4266: loss 0.027964219450950623\n",
      "batch 4267: loss 0.04720887169241905\n",
      "batch 4268: loss 0.06275846809148788\n",
      "batch 4269: loss 0.035379860550165176\n",
      "batch 4270: loss 0.0426056943833828\n",
      "batch 4271: loss 0.06165391206741333\n",
      "batch 4272: loss 0.026895610615611076\n",
      "batch 4273: loss 0.05159911885857582\n",
      "batch 4274: loss 0.08424157649278641\n",
      "batch 4275: loss 0.10391015559434891\n",
      "batch 4276: loss 0.019562488421797752\n",
      "batch 4277: loss 0.06264761835336685\n",
      "batch 4278: loss 0.15558354556560516\n",
      "batch 4279: loss 0.02979634702205658\n",
      "batch 4280: loss 0.003956882748752832\n",
      "batch 4281: loss 0.06663824617862701\n",
      "batch 4282: loss 0.06080203503370285\n",
      "batch 4283: loss 0.07120721787214279\n",
      "batch 4284: loss 0.07590503245592117\n",
      "batch 4285: loss 0.1493472009897232\n",
      "batch 4286: loss 0.0481971837580204\n",
      "batch 4287: loss 0.11327782273292542\n",
      "batch 4288: loss 0.02897742949426174\n",
      "batch 4289: loss 0.08823108673095703\n",
      "batch 4290: loss 0.08539304882287979\n",
      "batch 4291: loss 0.06686022877693176\n",
      "batch 4292: loss 0.11851205676794052\n",
      "batch 4293: loss 0.0619167797267437\n",
      "batch 4294: loss 0.02760460041463375\n",
      "batch 4295: loss 0.016203224658966064\n",
      "batch 4296: loss 0.05486278235912323\n",
      "batch 4297: loss 0.049129705876111984\n",
      "batch 4298: loss 0.01887435093522072\n",
      "batch 4299: loss 0.05581982806324959\n",
      "batch 4300: loss 0.1685677468776703\n",
      "batch 4301: loss 0.020665133371949196\n",
      "batch 4302: loss 0.14967161417007446\n",
      "batch 4303: loss 0.048531513661146164\n",
      "batch 4304: loss 0.03434859961271286\n",
      "batch 4305: loss 0.07428736239671707\n",
      "batch 4306: loss 0.13274000585079193\n",
      "batch 4307: loss 0.03602314367890358\n",
      "batch 4308: loss 0.1071983277797699\n",
      "batch 4309: loss 0.17038817703723907\n",
      "batch 4310: loss 0.10556162893772125\n",
      "batch 4311: loss 0.018665030598640442\n",
      "batch 4312: loss 0.004292339086532593\n",
      "batch 4313: loss 0.09959521144628525\n",
      "batch 4314: loss 0.03837301954627037\n",
      "batch 4315: loss 0.040553465485572815\n",
      "batch 4316: loss 0.1390732079744339\n",
      "batch 4317: loss 0.07105867564678192\n",
      "batch 4318: loss 0.1605650633573532\n",
      "batch 4319: loss 0.09937048703432083\n",
      "batch 4320: loss 0.18677712976932526\n",
      "batch 4321: loss 0.007149007171392441\n",
      "batch 4322: loss 0.13848385214805603\n",
      "batch 4323: loss 0.02516304887831211\n",
      "batch 4324: loss 0.05878535285592079\n",
      "batch 4325: loss 0.032623838633298874\n",
      "batch 4326: loss 0.019252052530646324\n",
      "batch 4327: loss 0.00962668377906084\n",
      "batch 4328: loss 0.0992962121963501\n",
      "batch 4329: loss 0.12024972587823868\n",
      "batch 4330: loss 0.048316579312086105\n",
      "batch 4331: loss 0.03793776035308838\n",
      "batch 4332: loss 0.04440499097108841\n",
      "batch 4333: loss 0.015014995820820332\n",
      "batch 4334: loss 0.1395207792520523\n",
      "batch 4335: loss 0.08562880009412766\n",
      "batch 4336: loss 0.025826087221503258\n",
      "batch 4337: loss 0.04621369391679764\n",
      "batch 4338: loss 0.017677050083875656\n",
      "batch 4339: loss 0.05222431197762489\n",
      "batch 4340: loss 0.027476662769913673\n",
      "batch 4341: loss 0.11919829994440079\n",
      "batch 4342: loss 0.0927831158041954\n",
      "batch 4343: loss 0.021049432456493378\n",
      "batch 4344: loss 0.08684306591749191\n",
      "batch 4345: loss 0.02748222090303898\n",
      "batch 4346: loss 0.023413101211190224\n",
      "batch 4347: loss 0.11775407195091248\n",
      "batch 4348: loss 0.03133290633559227\n",
      "batch 4349: loss 0.08690161257982254\n",
      "batch 4350: loss 0.11698761582374573\n",
      "batch 4351: loss 0.005679916124790907\n",
      "batch 4352: loss 0.021722787991166115\n",
      "batch 4353: loss 0.11109704524278641\n",
      "batch 4354: loss 0.039124105125665665\n",
      "batch 4355: loss 0.04675857350230217\n",
      "batch 4356: loss 0.046141527593135834\n",
      "batch 4357: loss 0.04811231419444084\n",
      "batch 4358: loss 0.01330917701125145\n",
      "batch 4359: loss 0.016392869874835014\n",
      "batch 4360: loss 0.2937110960483551\n",
      "batch 4361: loss 0.04243355616927147\n",
      "batch 4362: loss 0.0243027713149786\n",
      "batch 4363: loss 0.05330122262239456\n",
      "batch 4364: loss 0.08352695405483246\n",
      "batch 4365: loss 0.10339879989624023\n",
      "batch 4366: loss 0.06887083500623703\n",
      "batch 4367: loss 0.014453841373324394\n",
      "batch 4368: loss 0.10824693739414215\n",
      "batch 4369: loss 0.055458638817071915\n",
      "batch 4370: loss 0.027585893869400024\n",
      "batch 4371: loss 0.10970667749643326\n",
      "batch 4372: loss 0.08515055477619171\n",
      "batch 4373: loss 0.03701280802488327\n",
      "batch 4374: loss 0.05499783903360367\n",
      "batch 4375: loss 0.08174413442611694\n",
      "batch 4376: loss 0.03819792717695236\n",
      "batch 4377: loss 0.07751144468784332\n",
      "batch 4378: loss 0.07114583998918533\n",
      "batch 4379: loss 0.02214992046356201\n",
      "batch 4380: loss 0.018901756033301353\n",
      "batch 4381: loss 0.1307610422372818\n",
      "batch 4382: loss 0.04246398061513901\n",
      "batch 4383: loss 0.016818344593048096\n",
      "batch 4384: loss 0.035483863204717636\n",
      "batch 4385: loss 0.05808587744832039\n",
      "batch 4386: loss 0.03513762354850769\n",
      "batch 4387: loss 0.12389323860406876\n",
      "batch 4388: loss 0.0725984126329422\n",
      "batch 4389: loss 0.08650194853544235\n",
      "batch 4390: loss 0.034491024911403656\n",
      "batch 4391: loss 0.11330083757638931\n",
      "batch 4392: loss 0.14406320452690125\n",
      "batch 4393: loss 0.0589463971555233\n",
      "batch 4394: loss 0.046461980789899826\n",
      "batch 4395: loss 0.06510960310697556\n",
      "batch 4396: loss 0.028266603127121925\n",
      "batch 4397: loss 0.05502224713563919\n",
      "batch 4398: loss 0.06863038241863251\n",
      "batch 4399: loss 0.0638301819562912\n",
      "batch 4400: loss 0.01965370960533619\n",
      "batch 4401: loss 0.04414452612400055\n",
      "batch 4402: loss 0.0948340967297554\n",
      "batch 4403: loss 0.012313345447182655\n",
      "batch 4404: loss 0.08571979403495789\n",
      "batch 4405: loss 0.06986992061138153\n",
      "batch 4406: loss 0.04927792400121689\n",
      "batch 4407: loss 0.08661811798810959\n",
      "batch 4408: loss 0.24127867817878723\n",
      "batch 4409: loss 0.04476121813058853\n",
      "batch 4410: loss 0.025730468332767487\n",
      "batch 4411: loss 0.04099666327238083\n",
      "batch 4412: loss 0.11443343013525009\n",
      "batch 4413: loss 0.023888085037469864\n",
      "batch 4414: loss 0.1255314201116562\n",
      "batch 4415: loss 0.012593774124979973\n",
      "batch 4416: loss 0.007220644969493151\n",
      "batch 4417: loss 0.13799996674060822\n",
      "batch 4418: loss 0.05710817500948906\n",
      "batch 4419: loss 0.08796007186174393\n",
      "batch 4420: loss 0.061597421765327454\n",
      "batch 4421: loss 0.019303737208247185\n",
      "batch 4422: loss 0.2143273949623108\n",
      "batch 4423: loss 0.06018247827887535\n",
      "batch 4424: loss 0.041754238307476044\n",
      "batch 4425: loss 0.05953662842512131\n",
      "batch 4426: loss 0.0974547490477562\n",
      "batch 4427: loss 0.04761093109846115\n",
      "batch 4428: loss 0.10417710989713669\n",
      "batch 4429: loss 0.07539024949073792\n",
      "batch 4430: loss 0.07963746041059494\n",
      "batch 4431: loss 0.13344407081604004\n",
      "batch 4432: loss 0.020170748233795166\n",
      "batch 4433: loss 0.03579515218734741\n",
      "batch 4434: loss 0.052398499101400375\n",
      "batch 4435: loss 0.11393024027347565\n",
      "batch 4436: loss 0.02428516373038292\n",
      "batch 4437: loss 0.026069745421409607\n",
      "batch 4438: loss 0.14632846415042877\n",
      "batch 4439: loss 0.02439791150391102\n",
      "batch 4440: loss 0.1212594211101532\n",
      "batch 4441: loss 0.12477780133485794\n",
      "batch 4442: loss 0.0686066746711731\n",
      "batch 4443: loss 0.10885760933160782\n",
      "batch 4444: loss 0.1961388736963272\n",
      "batch 4445: loss 0.05108476057648659\n",
      "batch 4446: loss 0.09773198515176773\n",
      "batch 4447: loss 0.049671076238155365\n",
      "batch 4448: loss 0.07554393261671066\n",
      "batch 4449: loss 0.026166602969169617\n",
      "batch 4450: loss 0.0455189123749733\n",
      "batch 4451: loss 0.036574121564626694\n",
      "batch 4452: loss 0.08086702227592468\n",
      "batch 4453: loss 0.08326530456542969\n",
      "batch 4454: loss 0.021309826523065567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4455: loss 0.124223493039608\n",
      "batch 4456: loss 0.0486871562898159\n",
      "batch 4457: loss 0.1285775899887085\n",
      "batch 4458: loss 0.015531294979155064\n",
      "batch 4459: loss 0.10573092848062515\n",
      "batch 4460: loss 0.02721850387752056\n",
      "batch 4461: loss 0.0589543916285038\n",
      "batch 4462: loss 0.04090629518032074\n",
      "batch 4463: loss 0.023546865209937096\n",
      "batch 4464: loss 0.03551863506436348\n",
      "batch 4465: loss 0.04710167273879051\n",
      "batch 4466: loss 0.03348633646965027\n",
      "batch 4467: loss 0.07892189174890518\n",
      "batch 4468: loss 0.03873438388109207\n",
      "batch 4469: loss 0.02049337327480316\n",
      "batch 4470: loss 0.12387368083000183\n",
      "batch 4471: loss 0.02577192708849907\n",
      "batch 4472: loss 0.05636851117014885\n",
      "batch 4473: loss 0.021134668961167336\n",
      "batch 4474: loss 0.009531998075544834\n",
      "batch 4475: loss 0.09622514247894287\n",
      "batch 4476: loss 0.13036225736141205\n",
      "batch 4477: loss 0.12516525387763977\n",
      "batch 4478: loss 0.07142367213964462\n",
      "batch 4479: loss 0.03531532734632492\n",
      "batch 4480: loss 0.008582143113017082\n",
      "batch 4481: loss 0.061696041375398636\n",
      "batch 4482: loss 0.053838394582271576\n",
      "batch 4483: loss 0.18190120160579681\n",
      "batch 4484: loss 0.07901672273874283\n",
      "batch 4485: loss 0.09731575101613998\n",
      "batch 4486: loss 0.11374794691801071\n",
      "batch 4487: loss 0.039492424577474594\n",
      "batch 4488: loss 0.19924436509609222\n",
      "batch 4489: loss 0.018862077966332436\n",
      "batch 4490: loss 0.0771532878279686\n",
      "batch 4491: loss 0.029774606227874756\n",
      "batch 4492: loss 0.13727138936519623\n",
      "batch 4493: loss 0.05176297202706337\n",
      "batch 4494: loss 0.0395282544195652\n",
      "batch 4495: loss 0.02427118644118309\n",
      "batch 4496: loss 0.00750631932169199\n",
      "batch 4497: loss 0.06925619393587112\n",
      "batch 4498: loss 0.01571095734834671\n",
      "batch 4499: loss 0.009663698263466358\n",
      "batch 4500: loss 0.07415018230676651\n",
      "batch 4501: loss 0.04054083675146103\n",
      "batch 4502: loss 0.08279132843017578\n",
      "batch 4503: loss 0.10454705357551575\n",
      "batch 4504: loss 0.1700626164674759\n",
      "batch 4505: loss 0.02997756563127041\n",
      "batch 4506: loss 0.020612487569451332\n",
      "batch 4507: loss 0.06656626611948013\n",
      "batch 4508: loss 0.019208485260605812\n",
      "batch 4509: loss 0.13070671260356903\n",
      "batch 4510: loss 0.028395039960741997\n",
      "batch 4511: loss 0.12363304942846298\n",
      "batch 4512: loss 0.08521147817373276\n",
      "batch 4513: loss 0.0993872806429863\n",
      "batch 4514: loss 0.08125297725200653\n",
      "batch 4515: loss 0.03616785258054733\n",
      "batch 4516: loss 0.1201665848493576\n",
      "batch 4517: loss 0.06726466864347458\n",
      "batch 4518: loss 0.1587524712085724\n",
      "batch 4519: loss 0.03899368271231651\n",
      "batch 4520: loss 0.1225147619843483\n",
      "batch 4521: loss 0.11154059320688248\n",
      "batch 4522: loss 0.04328666254878044\n",
      "batch 4523: loss 0.17940431833267212\n",
      "batch 4524: loss 0.06240611895918846\n",
      "batch 4525: loss 0.041001226752996445\n",
      "batch 4526: loss 0.20165874063968658\n",
      "batch 4527: loss 0.09825155138969421\n",
      "batch 4528: loss 0.05685713514685631\n",
      "batch 4529: loss 0.10070107132196426\n",
      "batch 4530: loss 0.13439126312732697\n",
      "batch 4531: loss 0.0409969799220562\n",
      "batch 4532: loss 0.04099253565073013\n",
      "batch 4533: loss 0.03843133524060249\n",
      "batch 4534: loss 0.1270541101694107\n",
      "batch 4535: loss 0.029293712228536606\n",
      "batch 4536: loss 0.0309869647026062\n",
      "batch 4537: loss 0.04979332908987999\n",
      "batch 4538: loss 0.10337510704994202\n",
      "batch 4539: loss 0.040795598179101944\n",
      "batch 4540: loss 0.017046624794602394\n",
      "batch 4541: loss 0.06976420432329178\n",
      "batch 4542: loss 0.027097344398498535\n",
      "batch 4543: loss 0.040392644703388214\n",
      "batch 4544: loss 0.023716023191809654\n",
      "batch 4545: loss 0.045690812170505524\n",
      "batch 4546: loss 0.05897374078631401\n",
      "batch 4547: loss 0.03335205838084221\n",
      "batch 4548: loss 0.03131774067878723\n",
      "batch 4549: loss 0.22138327360153198\n",
      "batch 4550: loss 0.012211469002068043\n",
      "batch 4551: loss 0.04284152016043663\n",
      "batch 4552: loss 0.01803738996386528\n",
      "batch 4553: loss 0.17891646921634674\n",
      "batch 4554: loss 0.04817390814423561\n",
      "batch 4555: loss 0.06776146590709686\n",
      "batch 4556: loss 0.021087350323796272\n",
      "batch 4557: loss 0.14379513263702393\n",
      "batch 4558: loss 0.10661303251981735\n",
      "batch 4559: loss 0.03488203510642052\n",
      "batch 4560: loss 0.017436133697628975\n",
      "batch 4561: loss 0.04751697555184364\n",
      "batch 4562: loss 0.045933883637189865\n",
      "batch 4563: loss 0.07188711315393448\n",
      "batch 4564: loss 0.05346833914518356\n",
      "batch 4565: loss 0.026625918224453926\n",
      "batch 4566: loss 0.23881588876247406\n",
      "batch 4567: loss 0.04829706251621246\n",
      "batch 4568: loss 0.030157307162880898\n",
      "batch 4569: loss 0.11696397513151169\n",
      "batch 4570: loss 0.09632928669452667\n",
      "batch 4571: loss 0.03736565634608269\n",
      "batch 4572: loss 0.05415140464901924\n",
      "batch 4573: loss 0.11870507150888443\n",
      "batch 4574: loss 0.03258200362324715\n",
      "batch 4575: loss 0.040500298142433167\n",
      "batch 4576: loss 0.022079123184084892\n",
      "batch 4577: loss 0.019330019131302834\n",
      "batch 4578: loss 0.11871518939733505\n",
      "batch 4579: loss 0.08092162013053894\n",
      "batch 4580: loss 0.0693519115447998\n",
      "batch 4581: loss 0.03230074793100357\n",
      "batch 4582: loss 0.07034902274608612\n",
      "batch 4583: loss 0.1985156387090683\n",
      "batch 4584: loss 0.08222679048776627\n",
      "batch 4585: loss 0.08744536340236664\n",
      "batch 4586: loss 0.10329074412584305\n",
      "batch 4587: loss 0.04879644885659218\n",
      "batch 4588: loss 0.019958486780524254\n",
      "batch 4589: loss 0.1378757208585739\n",
      "batch 4590: loss 0.04757285863161087\n",
      "batch 4591: loss 0.0241079181432724\n",
      "batch 4592: loss 0.027605189010500908\n",
      "batch 4593: loss 0.2179831862449646\n",
      "batch 4594: loss 0.037443604320287704\n",
      "batch 4595: loss 0.030114775523543358\n",
      "batch 4596: loss 0.022787973284721375\n",
      "batch 4597: loss 0.02626539207994938\n",
      "batch 4598: loss 0.17993290722370148\n",
      "batch 4599: loss 0.04471750929951668\n",
      "batch 4600: loss 0.010862423107028008\n",
      "batch 4601: loss 0.018009167164564133\n",
      "batch 4602: loss 0.0148659348487854\n",
      "batch 4603: loss 0.06567010283470154\n",
      "batch 4604: loss 0.06909854710102081\n",
      "batch 4605: loss 0.10456477850675583\n",
      "batch 4606: loss 0.03847207501530647\n",
      "batch 4607: loss 0.028693661093711853\n",
      "batch 4608: loss 0.04455553740262985\n",
      "batch 4609: loss 0.08112408220767975\n",
      "batch 4610: loss 0.021993989124894142\n",
      "batch 4611: loss 0.013111623004078865\n",
      "batch 4612: loss 0.15456047654151917\n",
      "batch 4613: loss 0.01203096378594637\n",
      "batch 4614: loss 0.049390628933906555\n",
      "batch 4615: loss 0.13856400549411774\n",
      "batch 4616: loss 0.03199181333184242\n",
      "batch 4617: loss 0.19699576497077942\n",
      "batch 4618: loss 0.03361482918262482\n",
      "batch 4619: loss 0.04902375489473343\n",
      "batch 4620: loss 0.08480579406023026\n",
      "batch 4621: loss 0.057049330323934555\n",
      "batch 4622: loss 0.07157521694898605\n",
      "batch 4623: loss 0.009271113201975822\n",
      "batch 4624: loss 0.03743646666407585\n",
      "batch 4625: loss 0.08538644760847092\n",
      "batch 4626: loss 0.04425101727247238\n",
      "batch 4627: loss 0.08105023205280304\n",
      "batch 4628: loss 0.06045961752533913\n",
      "batch 4629: loss 0.1676691770553589\n",
      "batch 4630: loss 0.08636008948087692\n",
      "batch 4631: loss 0.04461099952459335\n",
      "batch 4632: loss 0.08311133831739426\n",
      "batch 4633: loss 0.010519986040890217\n",
      "batch 4634: loss 0.07596928626298904\n",
      "batch 4635: loss 0.08402862399816513\n",
      "batch 4636: loss 0.02514728717505932\n",
      "batch 4637: loss 0.051813047379255295\n",
      "batch 4638: loss 0.061877619475126266\n",
      "batch 4639: loss 0.13957813382148743\n",
      "batch 4640: loss 0.034124281257390976\n",
      "batch 4641: loss 0.036151595413684845\n",
      "batch 4642: loss 0.09615562856197357\n",
      "batch 4643: loss 0.034947119653224945\n",
      "batch 4644: loss 0.09260467439889908\n",
      "batch 4645: loss 0.06043967232108116\n",
      "batch 4646: loss 0.015791602432727814\n",
      "batch 4647: loss 0.10735076665878296\n",
      "batch 4648: loss 0.039377011358737946\n",
      "batch 4649: loss 0.11653121560811996\n",
      "batch 4650: loss 0.05223185941576958\n",
      "batch 4651: loss 0.019930323585867882\n",
      "batch 4652: loss 0.06374413520097733\n",
      "batch 4653: loss 0.2135489284992218\n",
      "batch 4654: loss 0.04152609407901764\n",
      "batch 4655: loss 0.09330617636442184\n",
      "batch 4656: loss 0.04149124398827553\n",
      "batch 4657: loss 0.030221393331885338\n",
      "batch 4658: loss 0.05655067414045334\n",
      "batch 4659: loss 0.07382358610630035\n",
      "batch 4660: loss 0.06391914933919907\n",
      "batch 4661: loss 0.2025269716978073\n",
      "batch 4662: loss 0.01417082641273737\n",
      "batch 4663: loss 0.08086497336626053\n",
      "batch 4664: loss 0.0782492384314537\n",
      "batch 4665: loss 0.06622705608606339\n",
      "batch 4666: loss 0.0302761048078537\n",
      "batch 4667: loss 0.020691407844424248\n",
      "batch 4668: loss 0.14569012820720673\n",
      "batch 4669: loss 0.07138848304748535\n",
      "batch 4670: loss 0.07101106643676758\n",
      "batch 4671: loss 0.022000767290592194\n",
      "batch 4672: loss 0.06597721576690674\n",
      "batch 4673: loss 0.05277818441390991\n",
      "batch 4674: loss 0.06391910463571548\n",
      "batch 4675: loss 0.07899294048547745\n",
      "batch 4676: loss 0.06040528789162636\n",
      "batch 4677: loss 0.1106991395354271\n",
      "batch 4678: loss 0.03575707972049713\n",
      "batch 4679: loss 0.011216256767511368\n",
      "batch 4680: loss 0.05657397210597992\n",
      "batch 4681: loss 0.03035159967839718\n",
      "batch 4682: loss 0.03078397363424301\n",
      "batch 4683: loss 0.0656260997056961\n",
      "batch 4684: loss 0.02444830909371376\n",
      "batch 4685: loss 0.05250179022550583\n",
      "batch 4686: loss 0.03670128062367439\n",
      "batch 4687: loss 0.04699186608195305\n",
      "batch 4688: loss 0.03704226762056351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4689: loss 0.22388692200183868\n",
      "batch 4690: loss 0.09300503879785538\n",
      "batch 4691: loss 0.14734739065170288\n",
      "batch 4692: loss 0.0454648956656456\n",
      "batch 4693: loss 0.143210768699646\n",
      "batch 4694: loss 0.20717324316501617\n",
      "batch 4695: loss 0.020057279616594315\n",
      "batch 4696: loss 0.05945516377687454\n",
      "batch 4697: loss 0.018213097006082535\n",
      "batch 4698: loss 0.023616841062903404\n",
      "batch 4699: loss 0.04981011152267456\n",
      "batch 4700: loss 0.03202986344695091\n",
      "batch 4701: loss 0.025759385898709297\n",
      "batch 4702: loss 0.032208990305662155\n",
      "batch 4703: loss 0.01735798828303814\n",
      "batch 4704: loss 0.022728776559233665\n",
      "batch 4705: loss 0.014387856237590313\n",
      "batch 4706: loss 0.06026336923241615\n",
      "batch 4707: loss 0.16928665339946747\n",
      "batch 4708: loss 0.04953768104314804\n",
      "batch 4709: loss 0.029455993324518204\n",
      "batch 4710: loss 0.029889749363064766\n",
      "batch 4711: loss 0.02845695987343788\n",
      "batch 4712: loss 0.037795472890138626\n",
      "batch 4713: loss 0.07532337307929993\n",
      "batch 4714: loss 0.010022041387856007\n",
      "batch 4715: loss 0.14652803540229797\n",
      "batch 4716: loss 0.044765252619981766\n",
      "batch 4717: loss 0.018691636621952057\n",
      "batch 4718: loss 0.05017540231347084\n",
      "batch 4719: loss 0.022466270253062248\n",
      "batch 4720: loss 0.07472911477088928\n",
      "batch 4721: loss 0.021585509181022644\n",
      "batch 4722: loss 0.2649075984954834\n",
      "batch 4723: loss 0.038445133715867996\n",
      "batch 4724: loss 0.010985545814037323\n",
      "batch 4725: loss 0.04855167120695114\n",
      "batch 4726: loss 0.02242792584002018\n",
      "batch 4727: loss 0.009617739357054234\n",
      "batch 4728: loss 0.03038432076573372\n",
      "batch 4729: loss 0.10621342062950134\n",
      "batch 4730: loss 0.015015499666333199\n",
      "batch 4731: loss 0.0370028093457222\n",
      "batch 4732: loss 0.04385484755039215\n",
      "batch 4733: loss 0.006913304328918457\n",
      "batch 4734: loss 0.01592887192964554\n",
      "batch 4735: loss 0.09001830220222473\n",
      "batch 4736: loss 0.08835408836603165\n",
      "batch 4737: loss 0.017855031415820122\n",
      "batch 4738: loss 0.15028487145900726\n",
      "batch 4739: loss 0.016205832362174988\n",
      "batch 4740: loss 0.14725205302238464\n",
      "batch 4741: loss 0.10292278975248337\n",
      "batch 4742: loss 0.17799396812915802\n",
      "batch 4743: loss 0.03685850277543068\n",
      "batch 4744: loss 0.0728076845407486\n",
      "batch 4745: loss 0.007800079416483641\n",
      "batch 4746: loss 0.03128845989704132\n",
      "batch 4747: loss 0.13110995292663574\n",
      "batch 4748: loss 0.02130974642932415\n",
      "batch 4749: loss 0.01966342329978943\n",
      "batch 4750: loss 0.031611327081918716\n",
      "batch 4751: loss 0.01869405061006546\n",
      "batch 4752: loss 0.13661374151706696\n",
      "batch 4753: loss 0.049711402505636215\n",
      "batch 4754: loss 0.01673809438943863\n",
      "batch 4755: loss 0.024563835933804512\n",
      "batch 4756: loss 0.026308506727218628\n",
      "batch 4757: loss 0.14021319150924683\n",
      "batch 4758: loss 0.05163826048374176\n",
      "batch 4759: loss 0.05009160563349724\n",
      "batch 4760: loss 0.009469302371144295\n",
      "batch 4761: loss 0.03056195005774498\n",
      "batch 4762: loss 0.019924934953451157\n",
      "batch 4763: loss 0.040829114615917206\n",
      "batch 4764: loss 0.00917099416255951\n",
      "batch 4765: loss 0.043049540370702744\n",
      "batch 4766: loss 0.08471265435218811\n",
      "batch 4767: loss 0.10041575878858566\n",
      "batch 4768: loss 0.22707340121269226\n",
      "batch 4769: loss 0.027228256687521935\n",
      "batch 4770: loss 0.05124315246939659\n",
      "batch 4771: loss 0.024073338136076927\n",
      "batch 4772: loss 0.06384093314409256\n",
      "batch 4773: loss 0.025037365034222603\n",
      "batch 4774: loss 0.11603561788797379\n",
      "batch 4775: loss 0.03297574073076248\n",
      "batch 4776: loss 0.02454383857548237\n",
      "batch 4777: loss 0.04071421921253204\n",
      "batch 4778: loss 0.05903920158743858\n",
      "batch 4779: loss 0.05376618728041649\n",
      "batch 4780: loss 0.10743600875139236\n",
      "batch 4781: loss 0.005284990184009075\n",
      "batch 4782: loss 0.1140265092253685\n",
      "batch 4783: loss 0.031007003039121628\n",
      "batch 4784: loss 0.06571025401353836\n",
      "batch 4785: loss 0.044676799327135086\n",
      "batch 4786: loss 0.03021591156721115\n",
      "batch 4787: loss 0.0914163663983345\n",
      "batch 4788: loss 0.1050645112991333\n",
      "batch 4789: loss 0.08294013142585754\n",
      "batch 4790: loss 0.009355447255074978\n",
      "batch 4791: loss 0.06682893633842468\n",
      "batch 4792: loss 0.03611982986330986\n",
      "batch 4793: loss 0.06380362808704376\n",
      "batch 4794: loss 0.05946282669901848\n",
      "batch 4795: loss 0.009200925938785076\n",
      "batch 4796: loss 0.028042035177350044\n",
      "batch 4797: loss 0.09333199262619019\n",
      "batch 4798: loss 0.07158128172159195\n",
      "batch 4799: loss 0.06853394210338593\n",
      "batch 4800: loss 0.022154025733470917\n",
      "batch 4801: loss 0.07171550393104553\n",
      "batch 4802: loss 0.019990738481283188\n",
      "batch 4803: loss 0.10828281193971634\n",
      "batch 4804: loss 0.040076445788145065\n",
      "batch 4805: loss 0.020125091075897217\n",
      "batch 4806: loss 0.2526825964450836\n",
      "batch 4807: loss 0.08837466686964035\n",
      "batch 4808: loss 0.06761526316404343\n",
      "batch 4809: loss 0.14637620747089386\n",
      "batch 4810: loss 0.01672944612801075\n",
      "batch 4811: loss 0.16567571461200714\n",
      "batch 4812: loss 0.035175736993551254\n",
      "batch 4813: loss 0.03930452838540077\n",
      "batch 4814: loss 0.008637323044240475\n",
      "batch 4815: loss 0.03136062249541283\n",
      "batch 4816: loss 0.0979444608092308\n",
      "batch 4817: loss 0.08372515439987183\n",
      "batch 4818: loss 0.052976641803979874\n",
      "batch 4819: loss 0.05615098401904106\n",
      "batch 4820: loss 0.04060237854719162\n",
      "batch 4821: loss 0.01760619692504406\n",
      "batch 4822: loss 0.13902418315410614\n",
      "batch 4823: loss 0.00908192340284586\n",
      "batch 4824: loss 0.0863223597407341\n",
      "batch 4825: loss 0.028122110292315483\n",
      "batch 4826: loss 0.023644715547561646\n",
      "batch 4827: loss 0.07057826220989227\n",
      "batch 4828: loss 0.02102072350680828\n",
      "batch 4829: loss 0.021296538412570953\n",
      "batch 4830: loss 0.023183174431324005\n",
      "batch 4831: loss 0.07083695381879807\n",
      "batch 4832: loss 0.14523570239543915\n",
      "batch 4833: loss 0.07562798261642456\n",
      "batch 4834: loss 0.0480705164372921\n",
      "batch 4835: loss 0.07663896679878235\n",
      "batch 4836: loss 0.018639879301190376\n",
      "batch 4837: loss 0.07088971883058548\n",
      "batch 4838: loss 0.08783542364835739\n",
      "batch 4839: loss 0.03631670027971268\n",
      "batch 4840: loss 0.10406535863876343\n",
      "batch 4841: loss 0.06829171627759933\n",
      "batch 4842: loss 0.05504683405160904\n",
      "batch 4843: loss 0.012714800424873829\n",
      "batch 4844: loss 0.014190973713994026\n",
      "batch 4845: loss 0.07902881503105164\n",
      "batch 4846: loss 0.0727347806096077\n",
      "batch 4847: loss 0.07930409908294678\n",
      "batch 4848: loss 0.055067598819732666\n",
      "batch 4849: loss 0.02960556000471115\n",
      "batch 4850: loss 0.062425397336483\n",
      "batch 4851: loss 0.033172428607940674\n",
      "batch 4852: loss 0.1251310259103775\n",
      "batch 4853: loss 0.10833195596933365\n",
      "batch 4854: loss 0.086311474442482\n",
      "batch 4855: loss 0.06816170364618301\n",
      "batch 4856: loss 0.01382356882095337\n",
      "batch 4857: loss 0.030910886824131012\n",
      "batch 4858: loss 0.02726869098842144\n",
      "batch 4859: loss 0.024236220866441727\n",
      "batch 4860: loss 0.06711228936910629\n",
      "batch 4861: loss 0.025858495384454727\n",
      "batch 4862: loss 0.016838015988469124\n",
      "batch 4863: loss 0.05566034093499184\n",
      "batch 4864: loss 0.030801795423030853\n",
      "batch 4865: loss 0.014127867296338081\n",
      "batch 4866: loss 0.0416024848818779\n",
      "batch 4867: loss 0.07499320805072784\n",
      "batch 4868: loss 0.05065058171749115\n",
      "batch 4869: loss 0.1155175194144249\n",
      "batch 4870: loss 0.027743352577090263\n",
      "batch 4871: loss 0.02821824513375759\n",
      "batch 4872: loss 0.04424041509628296\n",
      "batch 4873: loss 0.08446561545133591\n",
      "batch 4874: loss 0.12067863345146179\n",
      "batch 4875: loss 0.01917014643549919\n",
      "batch 4876: loss 0.09474033117294312\n",
      "batch 4877: loss 0.027504613623023033\n",
      "batch 4878: loss 0.02509288303554058\n",
      "batch 4879: loss 0.14471760392189026\n",
      "batch 4880: loss 0.11802898347377777\n",
      "batch 4881: loss 0.090366892516613\n",
      "batch 4882: loss 0.16293016076087952\n",
      "batch 4883: loss 0.022353321313858032\n",
      "batch 4884: loss 0.03345705196261406\n",
      "batch 4885: loss 0.017770914360880852\n",
      "batch 4886: loss 0.07812022417783737\n",
      "batch 4887: loss 0.1841518133878708\n",
      "batch 4888: loss 0.024733860045671463\n",
      "batch 4889: loss 0.006003308109939098\n",
      "batch 4890: loss 0.09999538213014603\n",
      "batch 4891: loss 0.05038967356085777\n",
      "batch 4892: loss 0.06441369652748108\n",
      "batch 4893: loss 0.04670783504843712\n",
      "batch 4894: loss 0.0835646241903305\n",
      "batch 4895: loss 0.08206504583358765\n",
      "batch 4896: loss 0.04579443857073784\n",
      "batch 4897: loss 0.19613011181354523\n",
      "batch 4898: loss 0.05070625990629196\n",
      "batch 4899: loss 0.016752449795603752\n",
      "batch 4900: loss 0.1157546266913414\n",
      "batch 4901: loss 0.018433159217238426\n",
      "batch 4902: loss 0.04480200633406639\n",
      "batch 4903: loss 0.04650300368666649\n",
      "batch 4904: loss 0.028523124754428864\n",
      "batch 4905: loss 0.17553775012493134\n",
      "batch 4906: loss 0.10686414688825607\n",
      "batch 4907: loss 0.013621704652905464\n",
      "batch 4908: loss 0.01105956919491291\n",
      "batch 4909: loss 0.04406154900789261\n",
      "batch 4910: loss 0.05516253039240837\n",
      "batch 4911: loss 0.054192040115594864\n",
      "batch 4912: loss 0.05554954707622528\n",
      "batch 4913: loss 0.06709016859531403\n",
      "batch 4914: loss 0.1015346497297287\n",
      "batch 4915: loss 0.07718545943498611\n",
      "batch 4916: loss 0.01549522951245308\n",
      "batch 4917: loss 0.038605570793151855\n",
      "batch 4918: loss 0.017717331647872925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4919: loss 0.052892979234457016\n",
      "batch 4920: loss 0.0937715619802475\n",
      "batch 4921: loss 0.06274821609258652\n",
      "batch 4922: loss 0.044390905648469925\n",
      "batch 4923: loss 0.12508781254291534\n",
      "batch 4924: loss 0.09197679162025452\n",
      "batch 4925: loss 0.01023838296532631\n",
      "batch 4926: loss 0.04252065718173981\n",
      "batch 4927: loss 0.009032294154167175\n",
      "batch 4928: loss 0.06254056841135025\n",
      "batch 4929: loss 0.13622261583805084\n",
      "batch 4930: loss 0.012982625514268875\n",
      "batch 4931: loss 0.01126958429813385\n",
      "batch 4932: loss 0.2361791580915451\n",
      "batch 4933: loss 0.04636678472161293\n",
      "batch 4934: loss 0.061300162225961685\n",
      "batch 4935: loss 0.04163951426744461\n",
      "batch 4936: loss 0.08000452071428299\n",
      "batch 4937: loss 0.10513977706432343\n",
      "batch 4938: loss 0.07086271792650223\n",
      "batch 4939: loss 0.10618475824594498\n",
      "batch 4940: loss 0.10804872959852219\n",
      "batch 4941: loss 0.022961871698498726\n",
      "batch 4942: loss 0.06637685745954514\n",
      "batch 4943: loss 0.042823467403650284\n",
      "batch 4944: loss 0.04062414914369583\n",
      "batch 4945: loss 0.048057135194540024\n",
      "batch 4946: loss 0.01895655319094658\n",
      "batch 4947: loss 0.05639748275279999\n",
      "batch 4948: loss 0.027547556906938553\n",
      "batch 4949: loss 0.014895777218043804\n",
      "batch 4950: loss 0.034026291221380234\n",
      "batch 4951: loss 0.019608786329627037\n",
      "batch 4952: loss 0.04205169901251793\n",
      "batch 4953: loss 0.07531353086233139\n",
      "batch 4954: loss 0.16891925036907196\n",
      "batch 4955: loss 0.1799255907535553\n",
      "batch 4956: loss 0.04466002434492111\n",
      "batch 4957: loss 0.02454681321978569\n",
      "batch 4958: loss 0.06025612726807594\n",
      "batch 4959: loss 0.018477769568562508\n",
      "batch 4960: loss 0.02478659525513649\n",
      "batch 4961: loss 0.07677529752254486\n",
      "batch 4962: loss 0.09956949204206467\n",
      "batch 4963: loss 0.02325516939163208\n",
      "batch 4964: loss 0.011899839155375957\n",
      "batch 4965: loss 0.10176079720258713\n",
      "batch 4966: loss 0.015424485318362713\n",
      "batch 4967: loss 0.016204478219151497\n",
      "batch 4968: loss 0.0386897437274456\n",
      "batch 4969: loss 0.10542991757392883\n",
      "batch 4970: loss 0.021510543301701546\n",
      "batch 4971: loss 0.03732544556260109\n",
      "batch 4972: loss 0.04122684523463249\n",
      "batch 4973: loss 0.05140991136431694\n",
      "batch 4974: loss 0.05723873898386955\n",
      "batch 4975: loss 0.03563378378748894\n",
      "batch 4976: loss 0.01025945320725441\n",
      "batch 4977: loss 0.12849053740501404\n",
      "batch 4978: loss 0.06029336154460907\n",
      "batch 4979: loss 0.05971703305840492\n",
      "batch 4980: loss 0.03835367411375046\n",
      "batch 4981: loss 0.12630847096443176\n",
      "batch 4982: loss 0.019983701407909393\n",
      "batch 4983: loss 0.11250624060630798\n",
      "batch 4984: loss 0.022823741659522057\n",
      "batch 4985: loss 0.03423641249537468\n",
      "batch 4986: loss 0.07805947214365005\n",
      "batch 4987: loss 0.025293048471212387\n",
      "batch 4988: loss 0.005940111819654703\n",
      "batch 4989: loss 0.042353492230176926\n",
      "batch 4990: loss 0.05450659990310669\n",
      "batch 4991: loss 0.03546134755015373\n",
      "batch 4992: loss 0.06011729687452316\n",
      "batch 4993: loss 0.004253466613590717\n",
      "batch 4994: loss 0.027379313483834267\n",
      "batch 4995: loss 0.09765443950891495\n",
      "batch 4996: loss 0.04914646968245506\n",
      "batch 4997: loss 0.007834910415112972\n",
      "batch 4998: loss 0.03512166067957878\n",
      "batch 4999: loss 0.026583809405565262\n",
      "batch 5000: loss 0.04255429655313492\n",
      "batch 5001: loss 0.023217322304844856\n",
      "batch 5002: loss 0.0036541426088660955\n",
      "batch 5003: loss 0.023351449519395828\n",
      "batch 5004: loss 0.009023692458868027\n",
      "batch 5005: loss 0.006517887115478516\n",
      "batch 5006: loss 0.1411493867635727\n",
      "batch 5007: loss 0.0580776147544384\n",
      "batch 5008: loss 0.07780329138040543\n",
      "batch 5009: loss 0.006792895030230284\n",
      "batch 5010: loss 0.0839855819940567\n",
      "batch 5011: loss 0.011584441177546978\n",
      "batch 5012: loss 0.061274707317352295\n",
      "batch 5013: loss 0.0543941967189312\n",
      "batch 5014: loss 0.04089246690273285\n",
      "batch 5015: loss 0.01922455057501793\n",
      "batch 5016: loss 0.02850843407213688\n",
      "batch 5017: loss 0.011230247095227242\n",
      "batch 5018: loss 0.017472043633461\n",
      "batch 5019: loss 0.10674962401390076\n",
      "batch 5020: loss 0.0027743526734411716\n",
      "batch 5021: loss 0.06757067888975143\n",
      "batch 5022: loss 0.033225465565919876\n",
      "batch 5023: loss 0.0409957692027092\n",
      "batch 5024: loss 0.04810004308819771\n",
      "batch 5025: loss 0.1256415694952011\n",
      "batch 5026: loss 0.07521746307611465\n",
      "batch 5027: loss 0.032148327678442\n",
      "batch 5028: loss 0.01090548001229763\n",
      "batch 5029: loss 0.031673043966293335\n",
      "batch 5030: loss 0.18653817474842072\n",
      "batch 5031: loss 0.09155375510454178\n",
      "batch 5032: loss 0.058572690933942795\n",
      "batch 5033: loss 0.14743095636367798\n",
      "batch 5034: loss 0.019060488790273666\n",
      "batch 5035: loss 0.02563617378473282\n",
      "batch 5036: loss 0.01982719451189041\n",
      "batch 5037: loss 0.07687082886695862\n",
      "batch 5038: loss 0.00982168409973383\n",
      "batch 5039: loss 0.09552483260631561\n",
      "batch 5040: loss 0.07115616649389267\n",
      "batch 5041: loss 0.043148450553417206\n",
      "batch 5042: loss 0.057780299335718155\n",
      "batch 5043: loss 0.06502849608659744\n",
      "batch 5044: loss 0.021165898069739342\n",
      "batch 5045: loss 0.07843630015850067\n",
      "batch 5046: loss 0.0069691892713308334\n",
      "batch 5047: loss 0.027557723224163055\n",
      "batch 5048: loss 0.02252272516489029\n",
      "batch 5049: loss 0.11489058285951614\n",
      "batch 5050: loss 0.05282985419034958\n",
      "batch 5051: loss 0.03163944557309151\n",
      "batch 5052: loss 0.009245452471077442\n",
      "batch 5053: loss 0.04352785646915436\n",
      "batch 5054: loss 0.05128631368279457\n",
      "batch 5055: loss 0.024934541434049606\n",
      "batch 5056: loss 0.04204116389155388\n",
      "batch 5057: loss 0.09019740670919418\n",
      "batch 5058: loss 0.026511501520872116\n",
      "batch 5059: loss 0.017045270651578903\n",
      "batch 5060: loss 0.024766787886619568\n",
      "batch 5061: loss 0.06742457300424576\n",
      "batch 5062: loss 0.03967708349227905\n",
      "batch 5063: loss 0.06630953401327133\n",
      "batch 5064: loss 0.042438820004463196\n",
      "batch 5065: loss 0.017370201647281647\n",
      "batch 5066: loss 0.14892300963401794\n",
      "batch 5067: loss 0.03873295336961746\n",
      "batch 5068: loss 0.008838525041937828\n",
      "batch 5069: loss 0.03472712263464928\n",
      "batch 5070: loss 0.03964660316705704\n",
      "batch 5071: loss 0.05100330337882042\n",
      "batch 5072: loss 0.015007604844868183\n",
      "batch 5073: loss 0.01174008846282959\n",
      "batch 5074: loss 0.04820070043206215\n",
      "batch 5075: loss 0.11024598777294159\n",
      "batch 5076: loss 0.08988728374242783\n",
      "batch 5077: loss 0.07289493083953857\n",
      "batch 5078: loss 0.0173823069781065\n",
      "batch 5079: loss 0.028457826003432274\n",
      "batch 5080: loss 0.0499361976981163\n",
      "batch 5081: loss 0.028663983568549156\n",
      "batch 5082: loss 0.026994410902261734\n",
      "batch 5083: loss 0.06463497132062912\n",
      "batch 5084: loss 0.043362684547901154\n",
      "batch 5085: loss 0.05511452630162239\n",
      "batch 5086: loss 0.0547737255692482\n",
      "batch 5087: loss 0.017323501408100128\n",
      "batch 5088: loss 0.01887214370071888\n",
      "batch 5089: loss 0.008077221922576427\n",
      "batch 5090: loss 0.006734286434948444\n",
      "batch 5091: loss 0.04263312742114067\n",
      "batch 5092: loss 0.03950013965368271\n",
      "batch 5093: loss 0.008417703211307526\n",
      "batch 5094: loss 0.02267877198755741\n",
      "batch 5095: loss 0.0021084919571876526\n",
      "batch 5096: loss 0.06587233394384384\n",
      "batch 5097: loss 0.04816149175167084\n",
      "batch 5098: loss 0.08334977924823761\n",
      "batch 5099: loss 0.011618354357779026\n",
      "batch 5100: loss 0.011312970891594887\n",
      "batch 5101: loss 0.007494536694139242\n",
      "batch 5102: loss 0.08378590643405914\n",
      "batch 5103: loss 0.020698564127087593\n",
      "batch 5104: loss 0.05597299337387085\n",
      "batch 5105: loss 0.004278728272765875\n",
      "batch 5106: loss 0.010649651288986206\n",
      "batch 5107: loss 0.15536877512931824\n",
      "batch 5108: loss 0.008736912161111832\n",
      "batch 5109: loss 0.017627766355872154\n",
      "batch 5110: loss 0.006299781613051891\n",
      "batch 5111: loss 0.08892455697059631\n",
      "batch 5112: loss 0.025696510449051857\n",
      "batch 5113: loss 0.07391192764043808\n",
      "batch 5114: loss 0.08486809581518173\n",
      "batch 5115: loss 0.0860675722360611\n",
      "batch 5116: loss 0.015513374470174313\n",
      "batch 5117: loss 0.041979316622018814\n",
      "batch 5118: loss 0.01389925554394722\n",
      "batch 5119: loss 0.20346355438232422\n",
      "batch 5120: loss 0.17727091908454895\n",
      "batch 5121: loss 0.02457517571747303\n",
      "batch 5122: loss 0.21038269996643066\n",
      "batch 5123: loss 0.01377517357468605\n",
      "batch 5124: loss 0.014056963846087456\n",
      "batch 5125: loss 0.03320123627781868\n",
      "batch 5126: loss 0.05772213637828827\n",
      "batch 5127: loss 0.039547037333250046\n",
      "batch 5128: loss 0.06681935489177704\n",
      "batch 5129: loss 0.022464875131845474\n",
      "batch 5130: loss 0.03614578768610954\n",
      "batch 5131: loss 0.01691601239144802\n",
      "batch 5132: loss 0.024477697908878326\n",
      "batch 5133: loss 0.046032000333070755\n",
      "batch 5134: loss 0.025694813579320908\n",
      "batch 5135: loss 0.03440368175506592\n",
      "batch 5136: loss 0.05385659262537956\n",
      "batch 5137: loss 0.04226132482290268\n",
      "batch 5138: loss 0.04147085174918175\n",
      "batch 5139: loss 0.053131990134716034\n",
      "batch 5140: loss 0.051298923790454865\n",
      "batch 5141: loss 0.06347069889307022\n",
      "batch 5142: loss 0.03710002079606056\n",
      "batch 5143: loss 0.060295429080724716\n",
      "batch 5144: loss 0.06458690762519836\n",
      "batch 5145: loss 0.0717078447341919\n",
      "batch 5146: loss 0.04147496446967125\n",
      "batch 5147: loss 0.03019004501402378\n",
      "batch 5148: loss 0.11581000685691833\n",
      "batch 5149: loss 0.010536548681557178\n",
      "batch 5150: loss 0.06569129973649979\n",
      "batch 5151: loss 0.021649904549121857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5152: loss 0.023102696985006332\n",
      "batch 5153: loss 0.04150742292404175\n",
      "batch 5154: loss 0.12350206822156906\n",
      "batch 5155: loss 0.038473162800073624\n",
      "batch 5156: loss 0.2400617152452469\n",
      "batch 5157: loss 0.05360627546906471\n",
      "batch 5158: loss 0.012905625626444817\n",
      "batch 5159: loss 0.03011118434369564\n",
      "batch 5160: loss 0.12793321907520294\n",
      "batch 5161: loss 0.06560973823070526\n",
      "batch 5162: loss 0.07661076635122299\n",
      "batch 5163: loss 0.03989051282405853\n",
      "batch 5164: loss 0.009472118690609932\n",
      "batch 5165: loss 0.07948201149702072\n",
      "batch 5166: loss 0.014187612570822239\n",
      "batch 5167: loss 0.008983428589999676\n",
      "batch 5168: loss 0.0655910074710846\n",
      "batch 5169: loss 0.06710302084684372\n",
      "batch 5170: loss 0.20707343518733978\n",
      "batch 5171: loss 0.011290322057902813\n",
      "batch 5172: loss 0.10453291982412338\n",
      "batch 5173: loss 0.08933732658624649\n",
      "batch 5174: loss 0.1524049937725067\n",
      "batch 5175: loss 0.01137480791658163\n",
      "batch 5176: loss 0.026317190378904343\n",
      "batch 5177: loss 0.007213954348117113\n",
      "batch 5178: loss 0.06274872273206711\n",
      "batch 5179: loss 0.011718596331775188\n",
      "batch 5180: loss 0.008933300152420998\n",
      "batch 5181: loss 0.07871489226818085\n",
      "batch 5182: loss 0.023131689056754112\n",
      "batch 5183: loss 0.029225610196590424\n",
      "batch 5184: loss 0.07653778791427612\n",
      "batch 5185: loss 0.029584025964140892\n",
      "batch 5186: loss 0.02653854712843895\n",
      "batch 5187: loss 0.012652418576180935\n",
      "batch 5188: loss 0.03205231949687004\n",
      "batch 5189: loss 0.05031454935669899\n",
      "batch 5190: loss 0.04065690562129021\n",
      "batch 5191: loss 0.1459389477968216\n",
      "batch 5192: loss 0.08530993014574051\n",
      "batch 5193: loss 0.12256766855716705\n",
      "batch 5194: loss 0.038247689604759216\n",
      "batch 5195: loss 0.056010931730270386\n",
      "batch 5196: loss 0.11043678224086761\n",
      "batch 5197: loss 0.08884602040052414\n",
      "batch 5198: loss 0.1535281389951706\n",
      "batch 5199: loss 0.26733970642089844\n",
      "batch 5200: loss 0.04235241934657097\n",
      "batch 5201: loss 0.04735703021287918\n",
      "batch 5202: loss 0.091756172478199\n",
      "batch 5203: loss 0.010542535223066807\n",
      "batch 5204: loss 0.12089267373085022\n",
      "batch 5205: loss 0.05278424918651581\n",
      "batch 5206: loss 0.0823390781879425\n",
      "batch 5207: loss 0.007844329811632633\n",
      "batch 5208: loss 0.04064332693815231\n",
      "batch 5209: loss 0.022632567211985588\n",
      "batch 5210: loss 0.2019437700510025\n",
      "batch 5211: loss 0.03429954871535301\n",
      "batch 5212: loss 0.0469057634472847\n",
      "batch 5213: loss 0.019025756046175957\n",
      "batch 5214: loss 0.04924658685922623\n",
      "batch 5215: loss 0.11435358971357346\n",
      "batch 5216: loss 0.020088404417037964\n",
      "batch 5217: loss 0.0771932378411293\n",
      "batch 5218: loss 0.014365946874022484\n",
      "batch 5219: loss 0.010262350551784039\n",
      "batch 5220: loss 0.12113875150680542\n",
      "batch 5221: loss 0.03187568485736847\n",
      "batch 5222: loss 0.1699845790863037\n",
      "batch 5223: loss 0.03151029348373413\n",
      "batch 5224: loss 0.07229488343000412\n",
      "batch 5225: loss 0.057378511875867844\n",
      "batch 5226: loss 0.014075854793190956\n",
      "batch 5227: loss 0.03654942661523819\n",
      "batch 5228: loss 0.014498000033199787\n",
      "batch 5229: loss 0.026125920936465263\n",
      "batch 5230: loss 0.034322503954172134\n",
      "batch 5231: loss 0.04427175596356392\n",
      "batch 5232: loss 0.011956281028687954\n",
      "batch 5233: loss 0.03281063959002495\n",
      "batch 5234: loss 0.08462072163820267\n",
      "batch 5235: loss 0.23604504764080048\n",
      "batch 5236: loss 0.08325719833374023\n",
      "batch 5237: loss 0.19405066967010498\n",
      "batch 5238: loss 0.039967406541109085\n",
      "batch 5239: loss 0.00881942082196474\n",
      "batch 5240: loss 0.020740725100040436\n",
      "batch 5241: loss 0.10246144980192184\n",
      "batch 5242: loss 0.07968919724225998\n",
      "batch 5243: loss 0.0070974635891616344\n",
      "batch 5244: loss 0.0333099439740181\n",
      "batch 5245: loss 0.038156311959028244\n",
      "batch 5246: loss 0.016759837046265602\n",
      "batch 5247: loss 0.023949498310685158\n",
      "batch 5248: loss 0.026760155335068703\n",
      "batch 5249: loss 0.022670716047286987\n",
      "batch 5250: loss 0.07824418693780899\n",
      "batch 5251: loss 0.03572654351592064\n",
      "batch 5252: loss 0.029520362615585327\n",
      "batch 5253: loss 0.03006807528436184\n",
      "batch 5254: loss 0.02973700501024723\n",
      "batch 5255: loss 0.03508961200714111\n",
      "batch 5256: loss 0.03169114887714386\n",
      "batch 5257: loss 0.03295336291193962\n",
      "batch 5258: loss 0.06900469958782196\n",
      "batch 5259: loss 0.02005685679614544\n",
      "batch 5260: loss 0.018861671909689903\n",
      "batch 5261: loss 0.017855508252978325\n",
      "batch 5262: loss 0.03432845696806908\n",
      "batch 5263: loss 0.05982816964387894\n",
      "batch 5264: loss 0.0775061547756195\n",
      "batch 5265: loss 0.029941214248538017\n",
      "batch 5266: loss 0.02768169343471527\n",
      "batch 5267: loss 0.041343215852975845\n",
      "batch 5268: loss 0.026502208784222603\n",
      "batch 5269: loss 0.05833495780825615\n",
      "batch 5270: loss 0.05026113986968994\n",
      "batch 5271: loss 0.10412505269050598\n",
      "batch 5272: loss 0.009804214350879192\n",
      "batch 5273: loss 0.11315611004829407\n",
      "batch 5274: loss 0.04768642410635948\n",
      "batch 5275: loss 0.020858168601989746\n",
      "batch 5276: loss 0.010444057174026966\n",
      "batch 5277: loss 0.20783835649490356\n",
      "batch 5278: loss 0.043350204825401306\n",
      "batch 5279: loss 0.14463089406490326\n",
      "batch 5280: loss 0.08582477271556854\n",
      "batch 5281: loss 0.008428942412137985\n",
      "batch 5282: loss 0.08581472188234329\n",
      "batch 5283: loss 0.0666433572769165\n",
      "batch 5284: loss 0.014608469791710377\n",
      "batch 5285: loss 0.05349324271082878\n",
      "batch 5286: loss 0.0045244768261909485\n",
      "batch 5287: loss 0.023503851145505905\n",
      "batch 5288: loss 0.05821497365832329\n",
      "batch 5289: loss 0.007794244214892387\n",
      "batch 5290: loss 0.009231452830135822\n",
      "batch 5291: loss 0.036927174776792526\n",
      "batch 5292: loss 0.005672240164130926\n",
      "batch 5293: loss 0.006782578304409981\n",
      "batch 5294: loss 0.007035566493868828\n",
      "batch 5295: loss 0.06438396126031876\n",
      "batch 5296: loss 0.0797596424818039\n",
      "batch 5297: loss 0.008645662106573582\n",
      "batch 5298: loss 0.05290538817644119\n",
      "batch 5299: loss 0.19168996810913086\n",
      "batch 5300: loss 0.04844438284635544\n",
      "batch 5301: loss 0.051337841898202896\n",
      "batch 5302: loss 0.008857264183461666\n",
      "batch 5303: loss 0.14185118675231934\n",
      "batch 5304: loss 0.015480334870517254\n",
      "batch 5305: loss 0.045502614229917526\n",
      "batch 5306: loss 0.01186711248010397\n",
      "batch 5307: loss 0.030789904296398163\n",
      "batch 5308: loss 0.04431853070855141\n",
      "batch 5309: loss 0.007502582389861345\n",
      "batch 5310: loss 0.07281627506017685\n",
      "batch 5311: loss 0.007681761868298054\n",
      "batch 5312: loss 0.027063902467489243\n",
      "batch 5313: loss 0.04712973162531853\n",
      "batch 5314: loss 0.22692587971687317\n",
      "batch 5315: loss 0.05512691289186478\n",
      "batch 5316: loss 0.06536068022251129\n",
      "batch 5317: loss 0.057029590010643005\n",
      "batch 5318: loss 0.14425140619277954\n",
      "batch 5319: loss 0.053387098014354706\n",
      "batch 5320: loss 0.0223690215498209\n",
      "batch 5321: loss 0.09288021922111511\n",
      "batch 5322: loss 0.0774083212018013\n",
      "batch 5323: loss 0.013497869484126568\n",
      "batch 5324: loss 0.015841258689761162\n",
      "batch 5325: loss 0.009739048779010773\n",
      "batch 5326: loss 0.03497419133782387\n",
      "batch 5327: loss 0.00887479167431593\n",
      "batch 5328: loss 0.04730749875307083\n",
      "batch 5329: loss 0.18982073664665222\n",
      "batch 5330: loss 0.016522567719221115\n",
      "batch 5331: loss 0.02595570497214794\n",
      "batch 5332: loss 0.1056995540857315\n",
      "batch 5333: loss 0.20748938620090485\n",
      "batch 5334: loss 0.1346082091331482\n",
      "batch 5335: loss 0.11605460941791534\n",
      "batch 5336: loss 0.018763650208711624\n",
      "batch 5337: loss 0.055019311606884\n",
      "batch 5338: loss 0.01307898759841919\n",
      "batch 5339: loss 0.030669940635561943\n",
      "batch 5340: loss 0.09865818172693253\n",
      "batch 5341: loss 0.07489895075559616\n",
      "batch 5342: loss 0.08498754352331161\n",
      "batch 5343: loss 0.03006567806005478\n",
      "batch 5344: loss 0.03000832162797451\n",
      "batch 5345: loss 0.11600381880998611\n",
      "batch 5346: loss 0.04290175437927246\n",
      "batch 5347: loss 0.04191960394382477\n",
      "batch 5348: loss 0.03421107307076454\n",
      "batch 5349: loss 0.024602355435490608\n",
      "batch 5350: loss 0.006346812471747398\n",
      "batch 5351: loss 0.03453569486737251\n",
      "batch 5352: loss 0.04288322478532791\n",
      "batch 5353: loss 0.01901414431631565\n",
      "batch 5354: loss 0.021705495193600655\n",
      "batch 5355: loss 0.025504278019070625\n",
      "batch 5356: loss 0.025425521656870842\n",
      "batch 5357: loss 0.014425584115087986\n",
      "batch 5358: loss 0.02579060010612011\n",
      "batch 5359: loss 0.14773467183113098\n",
      "batch 5360: loss 0.035518914461135864\n",
      "batch 5361: loss 0.015372906811535358\n",
      "batch 5362: loss 0.05609209090471268\n",
      "batch 5363: loss 0.02123631350696087\n",
      "batch 5364: loss 0.078908272087574\n",
      "batch 5365: loss 0.01916883885860443\n",
      "batch 5366: loss 0.14355887472629547\n",
      "batch 5367: loss 0.044226083904504776\n",
      "batch 5368: loss 0.016724329441785812\n",
      "batch 5369: loss 0.011879664845764637\n",
      "batch 5370: loss 0.0968046486377716\n",
      "batch 5371: loss 0.08238963037729263\n",
      "batch 5372: loss 0.03042653016746044\n",
      "batch 5373: loss 0.017972510308027267\n",
      "batch 5374: loss 0.006754065398126841\n",
      "batch 5375: loss 0.03266085311770439\n",
      "batch 5376: loss 0.0069469367153942585\n",
      "batch 5377: loss 0.007668962236493826\n",
      "batch 5378: loss 0.07430914044380188\n",
      "batch 5379: loss 0.04163868725299835\n",
      "batch 5380: loss 0.04262319579720497\n",
      "batch 5381: loss 0.11720127612352371\n",
      "batch 5382: loss 0.04670446738600731\n",
      "batch 5383: loss 0.02561378665268421\n",
      "batch 5384: loss 0.01995435729622841\n",
      "batch 5385: loss 0.026817630976438522\n",
      "batch 5386: loss 0.02844964899122715\n",
      "batch 5387: loss 0.06393182277679443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5388: loss 0.01735047809779644\n",
      "batch 5389: loss 0.07532758265733719\n",
      "batch 5390: loss 0.04700238257646561\n",
      "batch 5391: loss 0.013811538927257061\n",
      "batch 5392: loss 0.014669595286250114\n",
      "batch 5393: loss 0.07054777443408966\n",
      "batch 5394: loss 0.020277447998523712\n",
      "batch 5395: loss 0.07851995527744293\n",
      "batch 5396: loss 0.06875786930322647\n",
      "batch 5397: loss 0.055692870169878006\n",
      "batch 5398: loss 0.035018082708120346\n",
      "batch 5399: loss 0.05971524119377136\n",
      "batch 5400: loss 0.015367365442216396\n",
      "batch 5401: loss 0.02884652465581894\n",
      "batch 5402: loss 0.021510111168026924\n",
      "batch 5403: loss 0.12548957765102386\n",
      "batch 5404: loss 0.008313020691275597\n",
      "batch 5405: loss 0.006594356149435043\n",
      "batch 5406: loss 0.07213843613862991\n",
      "batch 5407: loss 0.02876076102256775\n",
      "batch 5408: loss 0.023489542305469513\n",
      "batch 5409: loss 0.05345015972852707\n",
      "batch 5410: loss 0.03022150881588459\n",
      "batch 5411: loss 0.015230881981551647\n",
      "batch 5412: loss 0.05406174436211586\n",
      "batch 5413: loss 0.02229466661810875\n",
      "batch 5414: loss 0.03478442132472992\n",
      "batch 5415: loss 0.10496640205383301\n",
      "batch 5416: loss 0.07733714580535889\n",
      "batch 5417: loss 0.013071274384856224\n",
      "batch 5418: loss 0.04490357264876366\n",
      "batch 5419: loss 0.014599432237446308\n",
      "batch 5420: loss 0.0878184363245964\n",
      "batch 5421: loss 0.005600759759545326\n",
      "batch 5422: loss 0.027473101392388344\n",
      "batch 5423: loss 0.07857709378004074\n",
      "batch 5424: loss 0.028311295434832573\n",
      "batch 5425: loss 0.14999717473983765\n",
      "batch 5426: loss 0.03211699053645134\n",
      "batch 5427: loss 0.009268459863960743\n",
      "batch 5428: loss 0.02448132447898388\n",
      "batch 5429: loss 0.030873171985149384\n",
      "batch 5430: loss 0.048184946179389954\n",
      "batch 5431: loss 0.031870387494564056\n",
      "batch 5432: loss 0.049767885357141495\n",
      "batch 5433: loss 0.028410252183675766\n",
      "batch 5434: loss 0.023382041603326797\n",
      "batch 5435: loss 0.008163750171661377\n",
      "batch 5436: loss 0.030419157817959785\n",
      "batch 5437: loss 0.07337798178195953\n",
      "batch 5438: loss 0.10588192939758301\n",
      "batch 5439: loss 0.006097013130784035\n",
      "batch 5440: loss 0.04959966242313385\n",
      "batch 5441: loss 0.14974403381347656\n",
      "batch 5442: loss 0.02449098229408264\n",
      "batch 5443: loss 0.014973727986216545\n",
      "batch 5444: loss 0.0125128710642457\n",
      "batch 5445: loss 0.0484396293759346\n",
      "batch 5446: loss 0.005259486380964518\n",
      "batch 5447: loss 0.09838155657052994\n",
      "batch 5448: loss 0.02634507417678833\n",
      "batch 5449: loss 0.03427626192569733\n",
      "batch 5450: loss 0.06949996948242188\n",
      "batch 5451: loss 0.029715806245803833\n",
      "batch 5452: loss 0.03321894630789757\n",
      "batch 5453: loss 0.010303644463419914\n",
      "batch 5454: loss 0.010568615980446339\n",
      "batch 5455: loss 0.013374735601246357\n",
      "batch 5456: loss 0.20552638173103333\n",
      "batch 5457: loss 0.050331227481365204\n",
      "batch 5458: loss 0.07785201817750931\n",
      "batch 5459: loss 0.134824737906456\n",
      "batch 5460: loss 0.03324464336037636\n",
      "batch 5461: loss 0.01414080336689949\n",
      "batch 5462: loss 0.003875892609357834\n",
      "batch 5463: loss 0.010605042800307274\n",
      "batch 5464: loss 0.09851009398698807\n",
      "batch 5465: loss 0.03694581985473633\n",
      "batch 5466: loss 0.15311875939369202\n",
      "batch 5467: loss 0.024896297603845596\n",
      "batch 5468: loss 0.08023995906114578\n",
      "batch 5469: loss 0.07154779136180878\n",
      "batch 5470: loss 0.029588719829916954\n",
      "batch 5471: loss 0.03390948101878166\n",
      "batch 5472: loss 0.035937435925006866\n",
      "batch 5473: loss 0.030559193342924118\n",
      "batch 5474: loss 0.03415123000741005\n",
      "batch 5475: loss 0.007136303465813398\n",
      "batch 5476: loss 0.19943033158779144\n",
      "batch 5477: loss 0.15382325649261475\n",
      "batch 5478: loss 0.0261368490755558\n",
      "batch 5479: loss 0.028180204331874847\n",
      "batch 5480: loss 0.027546128258109093\n",
      "batch 5481: loss 0.1562330424785614\n",
      "batch 5482: loss 0.018887894228100777\n",
      "batch 5483: loss 0.042285311967134476\n",
      "batch 5484: loss 0.008828886784613132\n",
      "batch 5485: loss 0.042863376438617706\n",
      "batch 5486: loss 0.08294888585805893\n",
      "batch 5487: loss 0.013059801422059536\n",
      "batch 5488: loss 0.03242520987987518\n",
      "batch 5489: loss 0.04125227406620979\n",
      "batch 5490: loss 0.06311964243650436\n",
      "batch 5491: loss 0.015197278000414371\n",
      "batch 5492: loss 0.049967072904109955\n",
      "batch 5493: loss 0.05376380309462547\n",
      "batch 5494: loss 0.030503490939736366\n",
      "batch 5495: loss 0.06276722997426987\n",
      "batch 5496: loss 0.06072726100683212\n",
      "batch 5497: loss 0.15859200060367584\n",
      "batch 5498: loss 0.0729038417339325\n",
      "batch 5499: loss 0.01788982003927231\n",
      "batch 5500: loss 0.07388409227132797\n",
      "batch 5501: loss 0.06270259618759155\n",
      "batch 5502: loss 0.25174111127853394\n",
      "batch 5503: loss 0.02372695319354534\n",
      "batch 5504: loss 0.042454712092876434\n",
      "batch 5505: loss 0.009931518696248531\n",
      "batch 5506: loss 0.09629591554403305\n",
      "batch 5507: loss 0.08381156623363495\n",
      "batch 5508: loss 0.04407603293657303\n",
      "batch 5509: loss 0.0417061448097229\n",
      "batch 5510: loss 0.007517746649682522\n",
      "batch 5511: loss 0.048380058258771896\n",
      "batch 5512: loss 0.07545361667871475\n",
      "batch 5513: loss 0.03421689569950104\n",
      "batch 5514: loss 0.09365429729223251\n",
      "batch 5515: loss 0.06913942843675613\n",
      "batch 5516: loss 0.05575186759233475\n",
      "batch 5517: loss 0.09471935033798218\n",
      "batch 5518: loss 0.01036397460848093\n",
      "batch 5519: loss 0.013016943819820881\n",
      "batch 5520: loss 0.020568769425153732\n",
      "batch 5521: loss 0.11369075626134872\n",
      "batch 5522: loss 0.035007547587156296\n",
      "batch 5523: loss 0.026817291975021362\n",
      "batch 5524: loss 0.03208913281559944\n",
      "batch 5525: loss 0.041726477444171906\n",
      "batch 5526: loss 0.1042163223028183\n",
      "batch 5527: loss 0.10050536692142487\n",
      "batch 5528: loss 0.07830335199832916\n",
      "batch 5529: loss 0.013186183758080006\n",
      "batch 5530: loss 0.07146518677473068\n",
      "batch 5531: loss 0.013839795254170895\n",
      "batch 5532: loss 0.0883815661072731\n",
      "batch 5533: loss 0.008914045058190823\n",
      "batch 5534: loss 0.011067541316151619\n",
      "batch 5535: loss 0.059591736644506454\n",
      "batch 5536: loss 0.005055481102317572\n",
      "batch 5537: loss 0.10131833702325821\n",
      "batch 5538: loss 0.027283167466521263\n",
      "batch 5539: loss 0.166122168302536\n",
      "batch 5540: loss 0.05466664582490921\n",
      "batch 5541: loss 0.08896386623382568\n",
      "batch 5542: loss 0.011412088759243488\n",
      "batch 5543: loss 0.1141601949930191\n",
      "batch 5544: loss 0.050003089010715485\n",
      "batch 5545: loss 0.03957000747323036\n",
      "batch 5546: loss 0.02221163734793663\n",
      "batch 5547: loss 0.019552400335669518\n",
      "batch 5548: loss 0.008472640998661518\n",
      "batch 5549: loss 0.08652850985527039\n",
      "batch 5550: loss 0.14827477931976318\n",
      "batch 5551: loss 0.04493577778339386\n",
      "batch 5552: loss 0.07241013646125793\n",
      "batch 5553: loss 0.027242109179496765\n",
      "batch 5554: loss 0.04217318072915077\n",
      "batch 5555: loss 0.049350302666425705\n",
      "batch 5556: loss 0.06676573306322098\n",
      "batch 5557: loss 0.06858430057764053\n",
      "batch 5558: loss 0.01325466763228178\n",
      "batch 5559: loss 0.0548517219722271\n",
      "batch 5560: loss 0.041427116841077805\n",
      "batch 5561: loss 0.020536858588457108\n",
      "batch 5562: loss 0.03131749853491783\n",
      "batch 5563: loss 0.061133697628974915\n",
      "batch 5564: loss 0.05278138443827629\n",
      "batch 5565: loss 0.13286754488945007\n",
      "batch 5566: loss 0.13426993787288666\n",
      "batch 5567: loss 0.03788423910737038\n",
      "batch 5568: loss 0.018627185374498367\n",
      "batch 5569: loss 0.012882805429399014\n",
      "batch 5570: loss 0.0039125834591686726\n",
      "batch 5571: loss 0.07362338900566101\n",
      "batch 5572: loss 0.051084671169519424\n",
      "batch 5573: loss 0.035357557237148285\n",
      "batch 5574: loss 0.03003493882715702\n",
      "batch 5575: loss 0.0752122551202774\n",
      "batch 5576: loss 0.07026838511228561\n",
      "batch 5577: loss 0.03885451704263687\n",
      "batch 5578: loss 0.09654393047094345\n",
      "batch 5579: loss 0.01860167272388935\n",
      "batch 5580: loss 0.09016259759664536\n",
      "batch 5581: loss 0.01679264008998871\n",
      "batch 5582: loss 0.01565697230398655\n",
      "batch 5583: loss 0.03058641217648983\n",
      "batch 5584: loss 0.007276329677551985\n",
      "batch 5585: loss 0.01842014119029045\n",
      "batch 5586: loss 0.03222831338644028\n",
      "batch 5587: loss 0.06079062446951866\n",
      "batch 5588: loss 0.02382914535701275\n",
      "batch 5589: loss 0.04931286349892616\n",
      "batch 5590: loss 0.016427315771579742\n",
      "batch 5591: loss 0.03146432340145111\n",
      "batch 5592: loss 0.12336265295743942\n",
      "batch 5593: loss 0.10256493091583252\n",
      "batch 5594: loss 0.017329221591353416\n",
      "batch 5595: loss 0.06478572636842728\n",
      "batch 5596: loss 0.038967616856098175\n",
      "batch 5597: loss 0.06036040186882019\n",
      "batch 5598: loss 0.0167058315128088\n",
      "batch 5599: loss 0.075236976146698\n",
      "batch 5600: loss 0.01848834566771984\n",
      "batch 5601: loss 0.06980466842651367\n",
      "batch 5602: loss 0.017815865576267242\n",
      "batch 5603: loss 0.006208282429724932\n",
      "batch 5604: loss 0.10440386831760406\n",
      "batch 5605: loss 0.00263298861682415\n",
      "batch 5606: loss 0.1274428367614746\n",
      "batch 5607: loss 0.035249341279268265\n",
      "batch 5608: loss 0.11855491995811462\n",
      "batch 5609: loss 0.08614236861467361\n",
      "batch 5610: loss 0.02104371413588524\n",
      "batch 5611: loss 0.12736649811267853\n",
      "batch 5612: loss 0.042741335928440094\n",
      "batch 5613: loss 0.037699632346630096\n",
      "batch 5614: loss 0.03753960132598877\n",
      "batch 5615: loss 0.039819393306970596\n",
      "batch 5616: loss 0.040942929685115814\n",
      "batch 5617: loss 0.008742210455238819\n",
      "batch 5618: loss 0.026911243796348572\n",
      "batch 5619: loss 0.011272079311311245\n",
      "batch 5620: loss 0.032600287348032\n",
      "batch 5621: loss 0.027767950668931007\n",
      "batch 5622: loss 0.053559694439172745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5623: loss 0.01691661961376667\n",
      "batch 5624: loss 0.015019950456917286\n",
      "batch 5625: loss 0.02949177846312523\n",
      "batch 5626: loss 0.09998094290494919\n",
      "batch 5627: loss 0.03722020983695984\n",
      "batch 5628: loss 0.03370256349444389\n",
      "batch 5629: loss 0.09690870344638824\n",
      "batch 5630: loss 0.040230028331279755\n",
      "batch 5631: loss 0.006415148731321096\n",
      "batch 5632: loss 0.055146872997283936\n",
      "batch 5633: loss 0.05692228302359581\n",
      "batch 5634: loss 0.01843654178082943\n",
      "batch 5635: loss 0.11376971751451492\n",
      "batch 5636: loss 0.015736715868115425\n",
      "batch 5637: loss 0.012142731808125973\n",
      "batch 5638: loss 0.013480628840625286\n",
      "batch 5639: loss 0.058514565229415894\n",
      "batch 5640: loss 0.06929200887680054\n",
      "batch 5641: loss 0.14117345213890076\n",
      "batch 5642: loss 0.020022470504045486\n",
      "batch 5643: loss 0.022107014432549477\n",
      "batch 5644: loss 0.026071475818753242\n",
      "batch 5645: loss 0.08602296561002731\n",
      "batch 5646: loss 0.028026530519127846\n",
      "batch 5647: loss 0.17650628089904785\n",
      "batch 5648: loss 0.09164627641439438\n",
      "batch 5649: loss 0.008680311031639576\n",
      "batch 5650: loss 0.004476770292967558\n",
      "batch 5651: loss 0.033475134521722794\n",
      "batch 5652: loss 0.018518390133976936\n",
      "batch 5653: loss 0.09383250772953033\n",
      "batch 5654: loss 0.02747134119272232\n",
      "batch 5655: loss 0.024195803329348564\n",
      "batch 5656: loss 0.016705695539712906\n",
      "batch 5657: loss 0.024497220292687416\n",
      "batch 5658: loss 0.012935597449541092\n",
      "batch 5659: loss 0.025936461985111237\n",
      "batch 5660: loss 0.12367423623800278\n",
      "batch 5661: loss 0.01248715166002512\n",
      "batch 5662: loss 0.010620282962918282\n",
      "batch 5663: loss 0.016143925487995148\n",
      "batch 5664: loss 0.018579483032226562\n",
      "batch 5665: loss 0.01236365083605051\n",
      "batch 5666: loss 0.1179194226861\n",
      "batch 5667: loss 0.10396330803632736\n",
      "batch 5668: loss 0.06226622313261032\n",
      "batch 5669: loss 0.06409091502428055\n",
      "batch 5670: loss 0.02115439623594284\n",
      "batch 5671: loss 0.030137423425912857\n",
      "batch 5672: loss 0.01896040327847004\n",
      "batch 5673: loss 0.03610089048743248\n",
      "batch 5674: loss 0.022969508543610573\n",
      "batch 5675: loss 0.10969677567481995\n",
      "batch 5676: loss 0.01216914877295494\n",
      "batch 5677: loss 0.05339653417468071\n",
      "batch 5678: loss 0.014519480988383293\n",
      "batch 5679: loss 0.10236111283302307\n",
      "batch 5680: loss 0.016787433996796608\n",
      "batch 5681: loss 0.17351466417312622\n",
      "batch 5682: loss 0.06288711726665497\n",
      "batch 5683: loss 0.01603909395635128\n",
      "batch 5684: loss 0.1134723424911499\n",
      "batch 5685: loss 0.02407206781208515\n",
      "batch 5686: loss 0.035972192883491516\n",
      "batch 5687: loss 0.059011753648519516\n",
      "batch 5688: loss 0.03997747600078583\n",
      "batch 5689: loss 0.011466135270893574\n",
      "batch 5690: loss 0.1876748651266098\n",
      "batch 5691: loss 0.07718811184167862\n",
      "batch 5692: loss 0.0421028807759285\n",
      "batch 5693: loss 0.02727099135518074\n",
      "batch 5694: loss 0.03233754262328148\n",
      "batch 5695: loss 0.029001621529459953\n",
      "batch 5696: loss 0.07999113947153091\n",
      "batch 5697: loss 0.06845562160015106\n",
      "batch 5698: loss 0.014601743780076504\n",
      "batch 5699: loss 0.01684790849685669\n",
      "batch 5700: loss 0.009052688255906105\n",
      "batch 5701: loss 0.03056696429848671\n",
      "batch 5702: loss 0.029600588604807854\n",
      "batch 5703: loss 0.1453532725572586\n",
      "batch 5704: loss 0.03719625249505043\n",
      "batch 5705: loss 0.09728160500526428\n",
      "batch 5706: loss 0.016057856380939484\n",
      "batch 5707: loss 0.04693036153912544\n",
      "batch 5708: loss 0.00587430689483881\n",
      "batch 5709: loss 0.04352584108710289\n",
      "batch 5710: loss 0.0457490012049675\n",
      "batch 5711: loss 0.10303257405757904\n",
      "batch 5712: loss 0.007678469642996788\n",
      "batch 5713: loss 0.06011374294757843\n",
      "batch 5714: loss 0.0513809435069561\n",
      "batch 5715: loss 0.05570340156555176\n",
      "batch 5716: loss 0.03540574014186859\n",
      "batch 5717: loss 0.016309354454278946\n",
      "batch 5718: loss 0.03388283774256706\n",
      "batch 5719: loss 0.0734754130244255\n",
      "batch 5720: loss 0.022877981886267662\n",
      "batch 5721: loss 0.10492026060819626\n",
      "batch 5722: loss 0.01698163151741028\n",
      "batch 5723: loss 0.044587984681129456\n",
      "batch 5724: loss 0.023073000833392143\n",
      "batch 5725: loss 0.15330834686756134\n",
      "batch 5726: loss 0.042674627155065536\n",
      "batch 5727: loss 0.04865691065788269\n",
      "batch 5728: loss 0.066783107817173\n",
      "batch 5729: loss 0.02009790763258934\n",
      "batch 5730: loss 0.010972241871058941\n",
      "batch 5731: loss 0.06276369839906693\n",
      "batch 5732: loss 0.07780156284570694\n",
      "batch 5733: loss 0.023049917072057724\n",
      "batch 5734: loss 0.06867004930973053\n",
      "batch 5735: loss 0.047984104603528976\n",
      "batch 5736: loss 0.05680566281080246\n",
      "batch 5737: loss 0.07304263859987259\n",
      "batch 5738: loss 0.06332892924547195\n",
      "batch 5739: loss 0.0806455984711647\n",
      "batch 5740: loss 0.016487043350934982\n",
      "batch 5741: loss 0.06815952807664871\n",
      "batch 5742: loss 0.1294310986995697\n",
      "batch 5743: loss 0.0414753220975399\n",
      "batch 5744: loss 0.06800583750009537\n",
      "batch 5745: loss 0.07802531868219376\n",
      "batch 5746: loss 0.03448425233364105\n",
      "batch 5747: loss 0.03349374979734421\n",
      "batch 5748: loss 0.025285134091973305\n",
      "batch 5749: loss 0.01639765128493309\n",
      "batch 5750: loss 0.08129306882619858\n",
      "batch 5751: loss 0.18700341880321503\n",
      "batch 5752: loss 0.014640948735177517\n",
      "batch 5753: loss 0.08007462322711945\n",
      "batch 5754: loss 0.012728729285299778\n",
      "batch 5755: loss 0.12499101459980011\n",
      "batch 5756: loss 0.08305874466896057\n",
      "batch 5757: loss 0.010865679942071438\n",
      "batch 5758: loss 0.026287121698260307\n",
      "batch 5759: loss 0.03211728855967522\n",
      "batch 5760: loss 0.03202252462506294\n",
      "batch 5761: loss 0.1891402155160904\n",
      "batch 5762: loss 0.19264595210552216\n",
      "batch 5763: loss 0.07924080640077591\n",
      "batch 5764: loss 0.03844983130693436\n",
      "batch 5765: loss 0.009251809678971767\n",
      "batch 5766: loss 0.017206387594342232\n",
      "batch 5767: loss 0.0692206472158432\n",
      "batch 5768: loss 0.04960218816995621\n",
      "batch 5769: loss 0.08210088312625885\n",
      "batch 5770: loss 0.022606128826737404\n",
      "batch 5771: loss 0.041810858994722366\n",
      "batch 5772: loss 0.04710526764392853\n",
      "batch 5773: loss 0.02195814624428749\n",
      "batch 5774: loss 0.09539046883583069\n",
      "batch 5775: loss 0.029617933556437492\n",
      "batch 5776: loss 0.012626845389604568\n",
      "batch 5777: loss 0.009257813915610313\n",
      "batch 5778: loss 0.021181680262088776\n",
      "batch 5779: loss 0.03303578123450279\n",
      "batch 5780: loss 0.16480311751365662\n",
      "batch 5781: loss 0.026996351778507233\n",
      "batch 5782: loss 0.12191184610128403\n",
      "batch 5783: loss 0.08310304582118988\n",
      "batch 5784: loss 0.016606003046035767\n",
      "batch 5785: loss 0.05382223054766655\n",
      "batch 5786: loss 0.008777575567364693\n",
      "batch 5787: loss 0.09869106858968735\n",
      "batch 5788: loss 0.06943240761756897\n",
      "batch 5789: loss 0.030097300186753273\n",
      "batch 5790: loss 0.049695804715156555\n",
      "batch 5791: loss 0.04912165552377701\n",
      "batch 5792: loss 0.02859308198094368\n",
      "batch 5793: loss 0.05089518427848816\n",
      "batch 5794: loss 0.01794428750872612\n",
      "batch 5795: loss 0.008923941291868687\n",
      "batch 5796: loss 0.005677435081452131\n",
      "batch 5797: loss 0.09700740873813629\n",
      "batch 5798: loss 0.012873166240751743\n",
      "batch 5799: loss 0.019994497299194336\n",
      "batch 5800: loss 0.011235659010708332\n",
      "batch 5801: loss 0.004210900980979204\n",
      "batch 5802: loss 0.03300199657678604\n",
      "batch 5803: loss 0.0685134008526802\n",
      "batch 5804: loss 0.024106692522764206\n",
      "batch 5805: loss 0.045455146580934525\n",
      "batch 5806: loss 0.1877342164516449\n",
      "batch 5807: loss 0.028898317366838455\n",
      "batch 5808: loss 0.046261269599199295\n",
      "batch 5809: loss 0.04374066740274429\n",
      "batch 5810: loss 0.02092030458152294\n",
      "batch 5811: loss 0.014571779407560825\n",
      "batch 5812: loss 0.12248867750167847\n",
      "batch 5813: loss 0.021973099559545517\n",
      "batch 5814: loss 0.01820177584886551\n",
      "batch 5815: loss 0.004747733473777771\n",
      "batch 5816: loss 0.05240580439567566\n",
      "batch 5817: loss 0.03625338897109032\n",
      "batch 5818: loss 0.010721266269683838\n",
      "batch 5819: loss 0.05814361572265625\n",
      "batch 5820: loss 0.04278505593538284\n",
      "batch 5821: loss 0.04180838540196419\n",
      "batch 5822: loss 0.026616107672452927\n",
      "batch 5823: loss 0.02062274143099785\n",
      "batch 5824: loss 0.048464711755514145\n",
      "batch 5825: loss 0.05382478982210159\n",
      "batch 5826: loss 0.02549481764435768\n",
      "batch 5827: loss 0.010645177215337753\n",
      "batch 5828: loss 0.062221262603998184\n",
      "batch 5829: loss 0.04942290112376213\n",
      "batch 5830: loss 0.049690160900354385\n",
      "batch 5831: loss 0.0766058936715126\n",
      "batch 5832: loss 0.1260097324848175\n",
      "batch 5833: loss 0.007582644000649452\n",
      "batch 5834: loss 0.030149847269058228\n",
      "batch 5835: loss 0.02626921609044075\n",
      "batch 5836: loss 0.09703776985406876\n",
      "batch 5837: loss 0.03702714294195175\n",
      "batch 5838: loss 0.004715754650533199\n",
      "batch 5839: loss 0.004684374667704105\n",
      "batch 5840: loss 0.013917021453380585\n",
      "batch 5841: loss 0.10241655260324478\n",
      "batch 5842: loss 0.024378955364227295\n",
      "batch 5843: loss 0.04350519925355911\n",
      "batch 5844: loss 0.0380098931491375\n",
      "batch 5845: loss 0.03910498693585396\n",
      "batch 5846: loss 0.022093653678894043\n",
      "batch 5847: loss 0.06647702306509018\n",
      "batch 5848: loss 0.03315145522356033\n",
      "batch 5849: loss 0.2274497002363205\n",
      "batch 5850: loss 0.051959820091724396\n",
      "batch 5851: loss 0.05105135962367058\n",
      "batch 5852: loss 0.009836710058152676\n",
      "batch 5853: loss 0.011180822737514973\n",
      "batch 5854: loss 0.049780283123254776\n",
      "batch 5855: loss 0.05236451327800751\n",
      "batch 5856: loss 0.21768194437026978\n",
      "batch 5857: loss 0.027918025851249695\n",
      "batch 5858: loss 0.058162059634923935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5859: loss 0.06635650247335434\n",
      "batch 5860: loss 0.044807318598032\n",
      "batch 5861: loss 0.031619034707546234\n",
      "batch 5862: loss 0.04561344161629677\n",
      "batch 5863: loss 0.025919174775481224\n",
      "batch 5864: loss 0.0485365055501461\n",
      "batch 5865: loss 0.05704955756664276\n",
      "batch 5866: loss 0.04164555296301842\n",
      "batch 5867: loss 0.015034801326692104\n",
      "batch 5868: loss 0.0717722550034523\n",
      "batch 5869: loss 0.1420058161020279\n",
      "batch 5870: loss 0.008207676000893116\n",
      "batch 5871: loss 0.0892280861735344\n",
      "batch 5872: loss 0.03698015585541725\n",
      "batch 5873: loss 0.04123660549521446\n",
      "batch 5874: loss 0.02604474499821663\n",
      "batch 5875: loss 0.01767832785844803\n",
      "batch 5876: loss 0.0747755616903305\n",
      "batch 5877: loss 0.06325137615203857\n",
      "batch 5878: loss 0.016910558566451073\n",
      "batch 5879: loss 0.009406445547938347\n",
      "batch 5880: loss 0.04169231653213501\n",
      "batch 5881: loss 0.09183676540851593\n",
      "batch 5882: loss 0.0049897292628884315\n",
      "batch 5883: loss 0.20171630382537842\n",
      "batch 5884: loss 0.04530685022473335\n",
      "batch 5885: loss 0.010482053272426128\n",
      "batch 5886: loss 0.039749182760715485\n",
      "batch 5887: loss 0.12135622650384903\n",
      "batch 5888: loss 0.03666188567876816\n",
      "batch 5889: loss 0.04768308997154236\n",
      "batch 5890: loss 0.00974301714450121\n",
      "batch 5891: loss 0.11094053834676743\n",
      "batch 5892: loss 0.029037868604063988\n",
      "batch 5893: loss 0.027035290375351906\n",
      "batch 5894: loss 0.03158750385046005\n",
      "batch 5895: loss 0.029670247808098793\n",
      "batch 5896: loss 0.022286124527454376\n",
      "batch 5897: loss 0.006405689753592014\n",
      "batch 5898: loss 0.012813623063266277\n",
      "batch 5899: loss 0.035314854234457016\n",
      "batch 5900: loss 0.040250781923532486\n",
      "batch 5901: loss 0.07650113105773926\n",
      "batch 5902: loss 0.02841218188405037\n",
      "batch 5903: loss 0.01704363338649273\n",
      "batch 5904: loss 0.015848303213715553\n",
      "batch 5905: loss 0.06046004965901375\n",
      "batch 5906: loss 0.02631746046245098\n",
      "batch 5907: loss 0.006369975861161947\n",
      "batch 5908: loss 0.020086245611310005\n",
      "batch 5909: loss 0.005262033082544804\n",
      "batch 5910: loss 0.019134556874632835\n",
      "batch 5911: loss 0.021290654316544533\n",
      "batch 5912: loss 0.047060277312994\n",
      "batch 5913: loss 0.11906230449676514\n",
      "batch 5914: loss 0.025367001071572304\n",
      "batch 5915: loss 0.05094308778643608\n",
      "batch 5916: loss 0.19160926342010498\n",
      "batch 5917: loss 0.06497456878423691\n",
      "batch 5918: loss 0.05508036911487579\n",
      "batch 5919: loss 0.11785759031772614\n",
      "batch 5920: loss 0.038201723247766495\n",
      "batch 5921: loss 0.04317111521959305\n",
      "batch 5922: loss 0.03252914175391197\n",
      "batch 5923: loss 0.01756247878074646\n",
      "batch 5924: loss 0.011637759394943714\n",
      "batch 5925: loss 0.0964566096663475\n",
      "batch 5926: loss 0.06640242785215378\n",
      "batch 5927: loss 0.040950316935777664\n",
      "batch 5928: loss 0.030933264642953873\n",
      "batch 5929: loss 0.13096967339515686\n",
      "batch 5930: loss 0.088426873087883\n",
      "batch 5931: loss 0.06990773230791092\n",
      "batch 5932: loss 0.10547365248203278\n",
      "batch 5933: loss 0.09109476208686829\n",
      "batch 5934: loss 0.030734147876501083\n",
      "batch 5935: loss 0.10918334126472473\n",
      "batch 5936: loss 0.10941635817289352\n",
      "batch 5937: loss 0.006652758456766605\n",
      "batch 5938: loss 0.02355370484292507\n",
      "batch 5939: loss 0.03885762020945549\n",
      "batch 5940: loss 0.014458231627941132\n",
      "batch 5941: loss 0.048191118985414505\n",
      "batch 5942: loss 0.014547120779752731\n",
      "batch 5943: loss 0.11360826343297958\n",
      "batch 5944: loss 0.02701333537697792\n",
      "batch 5945: loss 0.12033814191818237\n",
      "batch 5946: loss 0.006368081551045179\n",
      "batch 5947: loss 0.06003114581108093\n",
      "batch 5948: loss 0.01611274667084217\n",
      "batch 5949: loss 0.08898606896400452\n",
      "batch 5950: loss 0.0629763975739479\n",
      "batch 5951: loss 0.1104021966457367\n",
      "batch 5952: loss 0.030074240639805794\n",
      "batch 5953: loss 0.02421633154153824\n",
      "batch 5954: loss 0.04260646179318428\n",
      "batch 5955: loss 0.0068331146612763405\n",
      "batch 5956: loss 0.008511146530508995\n",
      "batch 5957: loss 0.008247851394116879\n",
      "batch 5958: loss 0.034653808921575546\n",
      "batch 5959: loss 0.06119668856263161\n",
      "batch 5960: loss 0.053840890526771545\n",
      "batch 5961: loss 0.025562742725014687\n",
      "batch 5962: loss 0.14313532412052155\n",
      "batch 5963: loss 0.02637442946434021\n",
      "batch 5964: loss 0.012112567201256752\n",
      "batch 5965: loss 0.20188124477863312\n",
      "batch 5966: loss 0.028298087418079376\n",
      "batch 5967: loss 0.05138067156076431\n",
      "batch 5968: loss 0.0336688868701458\n",
      "batch 5969: loss 0.09154205769300461\n",
      "batch 5970: loss 0.027275366708636284\n",
      "batch 5971: loss 0.029950816184282303\n",
      "batch 5972: loss 0.06442131847143173\n",
      "batch 5973: loss 0.025409050285816193\n",
      "batch 5974: loss 0.037069227546453476\n",
      "batch 5975: loss 0.05007835105061531\n",
      "batch 5976: loss 0.036952726542949677\n",
      "batch 5977: loss 0.023848194628953934\n",
      "batch 5978: loss 0.03027866967022419\n",
      "batch 5979: loss 0.04243156686425209\n",
      "batch 5980: loss 0.013798842206597328\n",
      "batch 5981: loss 0.04093734547495842\n",
      "batch 5982: loss 0.018513167276978493\n",
      "batch 5983: loss 0.03631623089313507\n",
      "batch 5984: loss 0.0691518783569336\n",
      "batch 5985: loss 0.025201553478837013\n",
      "batch 5986: loss 0.012470371089875698\n",
      "batch 5987: loss 0.017175812274217606\n",
      "batch 5988: loss 0.024160325527191162\n",
      "batch 5989: loss 0.07967746257781982\n",
      "batch 5990: loss 0.03806896507740021\n",
      "batch 5991: loss 0.03046160377562046\n",
      "batch 5992: loss 0.051577627658843994\n",
      "batch 5993: loss 0.02643761970102787\n",
      "batch 5994: loss 0.12407419085502625\n",
      "batch 5995: loss 0.017808539792895317\n",
      "batch 5996: loss 0.016688626259565353\n",
      "batch 5997: loss 0.04020340368151665\n",
      "batch 5998: loss 0.01425488106906414\n",
      "batch 5999: loss 0.013668694533407688\n"
     ]
    }
   ],
   "source": [
    "# 從data loader中隨機取一批訓練資料\n",
    "# num_batches為batches的數量\n",
    "num_batches = int(data_loader.num_train_data // batch_size * num_epochs)\n",
    "# Epoch這是指當所有資料都被用來訓練類神經網路一次\n",
    "for batch_index in range(num_batches):\n",
    "    X, y = data_loader.get_batch(batch_size)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X)\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        print(f\"batch {batch_index}: loss {loss.numpy()}\")\n",
    "    grads = tape.gradient(loss, model.variables)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82102b31",
   "metadata": {},
   "source": [
    "## 模型的評估 \n",
    "* 使用 **tf.keras.metrics** 中的 **SparseCategoricalAccuracy** 評估器來評估模型在測試集上的性能，該評估器能夠對模型預測的結果與真實結果進行比較，並輸出預測正確的樣本數佔總樣本數的比例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43113163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "test accuracy: 0.9725000262260437\n"
     ]
    }
   ],
   "source": [
    "sparse_catgorical_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "num_batches = int(data_loader.num_test_data // batch_size)\n",
    "for batch_index in range(num_batches):\n",
    "    start_index, end_index = batch_index * batch_size, (batch_index + 1) * batch_size\n",
    "    y_pred = model.predict(data_loader.test_data[start_index: end_index])\n",
    "    sparse_catgorical_accuracy.update_state(y_true=data_loader.test_label[start_index: end_index], y_pred=y_pred)\n",
    "print(f\"test accuracy: {sparse_catgorical_accuracy.result()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78816fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
